{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š ××“×¨×™×š ××§×™×£ ×œ× ×™×ª×•×— ×¡×“×¨×•×ª ×–××Ÿ ×¢× Polars\n",
    "\n",
    "## ×¤×¨×§ 9: Time Series Analysis + Forecasting\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‹ ×‘×¨×•×›×™× ×”×‘××™×!\n",
    "\n",
    "××“×¨×™×š ×–×” ×™×¢×–×•×¨ ×œ×›× ×œ×œ××•×“ ×›×™×¦×“ ×œ×¢×‘×•×“ ×¢× ×¡×“×¨×•×ª ×–××Ÿ (Time Series) ×‘×××¦×¢×•×ª ×¡×¤×¨×™×™×ª **Polars**.\n",
    "\n",
    "### ğŸ¯ ××” × ×œ××“ ×‘××“×¨×™×š ×–×”?\n",
    "\n",
    "1. **×¢×‘×•×“×” ×¢× ×ª××¨×™×›×™× ×•×©×¢×•×ª** - ×”××¨×”, ×¤×™×¨×•×§, ×•×¡×™× ×•×Ÿ\n",
    "2. **×—×œ×•× ×•×ª ××ª×’×œ×’×œ×™× (Rolling Windows)** - ×—×™×©×•×‘ ×××•×¦×¢×™× × ×¢×™×\n",
    "3. **×“×’×™××ª ×™×ª×¨ ×•×ª×ª-×“×’×™××” (Resampling)** - ×©×™× ×•×™ ×¨×–×•×œ×•×¦×™×™×ª ×”×–××Ÿ\n",
    "4. **×—×™×–×•×™ ×¡×“×¨×•×ª ×–××Ÿ (Forecasting)** - ×—×™×–×•×™ ×¢× Functime ğŸ”®\n",
    "\n",
    "### ğŸ“š ×ª×•×›×Ÿ ×¢× ×™×™× ×™×\n",
    "\n",
    "- [1. ×”×›× ×” - ×˜×¢×™× ×ª × ×ª×•× ×™×](#section-1)\n",
    "- [2. ×¢×‘×•×“×” ×¢× ×ª××¨×™×›×™× ×•×©×¢×•×ª](#section-2)\n",
    "- [3. ×—×œ×•× ×•×ª ××ª×’×œ×’×œ×™× (Rolling Windows)](#section-3)\n",
    "- [4. ×˜×›× ×™×§×•×ª ×“×’×™××” ××—×“×© (Resampling)](#section-4)\n",
    "- [5. ×—×™×–×•×™ ×¡×“×¨×•×ª ×–××Ÿ (Forecasting)](#section-5)\n",
    "- [6. ×ª×¨×’×™×œ×™× ××™× ×˜×¨××§×˜×™×‘×™×™×](#section-6)\n",
    "- [7. ×¡×™×›×•× ×•×˜×™×¤×™×](#section-7)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-1'></a>\n",
    "## 1. ğŸš€ ×”×›× ×” - ×˜×¢×™× ×ª × ×ª×•× ×™×\n",
    "\n",
    "× ×ª×—×™×œ ×‘×˜×¢×™× ×ª ×§×•×‘×¥ CSV ×©××›×™×œ × ×ª×•× ×™ ××–×’ ××•×•×™×¨ ××˜×•×¨×•× ×˜×•."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×™×‘×•× ×”×¡×¤×¨×™×™×”\n",
    "%pip install -U hvplot\n",
    "%pip install \"scipy<1.8.0\"\n",
    "import polars as pl\n",
    "\n",
    "# ×˜×¢×™× ×ª ×”× ×ª×•× ×™× ×›-LazyFrame\n",
    "lf = pl.scan_csv('../data/toronto_weather.csv')\n",
    "\n",
    "# ×”×¦×’×ª 5 ×”×©×•×¨×•×ª ×”×¨××©×•× ×•×ª\n",
    "lf.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ¡ï¸ ×”××¨×ª ×˜××¤×¨×˜×•×¨×” ××§×œ×•×•×™×Ÿ ×œ×¦×œ×–×™×•×¡"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×” ×œ×¦×œ×–×™×•×¡\n",
    "lf = lf.with_columns(\n",
    "    (pl.col('temperature') - 273.15).round(2).alias('temperature')\n",
    ")\n",
    "\n",
    "# ×‘×“×™×§×ª ×”×ª×•×¦××”\n",
    "lf.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-2'></a>\n",
    "## 2. ğŸ“… ×¢×‘×•×“×” ×¢× ×ª××¨×™×›×™× ×•×©×¢×•×ª\n",
    "\n",
    "### × ×™×ª×•×— ×ª××¨×™×›×™× ××•×˜×•××˜×™"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×˜×¢×™× ×” ×¢× × ×™×ª×•×— ×ª××¨×™×›×™× ××•×˜×•××˜×™\n",
    "lf_date_parsed = pl.scan_csv('../data/toronto_weather.csv', try_parse_dates=True)\n",
    "\n",
    "# ×”×¦×’×ª ×”× ×ª×•× ×™×\n",
    "lf_date_parsed.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×”××¨×ª ×ª××¨×™×›×™× ×™×“× ×™×ª"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×” ×™×“× ×™×ª ×©×œ ×¢××•×“×ª datetime\n",
    "lf = lf.with_columns(\n",
    "    pl.col('datetime').str.to_datetime()\n",
    ")\n",
    "\n",
    "lf.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×¤×™×¨×•×§ ×ª××¨×™×›×™× ×œ×¨×›×™×‘×™×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×¤×™×¨×•×§ ×”×ª××¨×™×š ×œ×¨×›×™×‘×™×\n",
    "(\n",
    "    lf\n",
    "    .select(\n",
    "        'datetime',\n",
    "        pl.col('datetime').dt.year().alias('year'),\n",
    "        pl.col('datetime').dt.month().alias('month'),\n",
    "        pl.col('datetime').dt.day().alias('day'),\n",
    "        pl.col('datetime').dt.time().alias('time')\n",
    "    )\n",
    "    .head().collect()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×¡×™× ×•×Ÿ ×œ×¤×™ ×ª××¨×™×›×™×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# ×¡×™× ×•×Ÿ ×œ×©× ×ª 2017, ×¨×§ ×‘×©×¢×•×ª ×”×‘×•×§×¨ (×¢×“ 12:00)\n",
    "filtered_lf = (\n",
    "    lf\n",
    "    .filter(\n",
    "        pl.col('datetime').dt.date().is_between(\n",
    "            datetime(2017, 1, 1),\n",
    "            datetime(2017, 12, 31)\n",
    "        ),\n",
    "        pl.col('datetime').dt.hour() < 12\n",
    "    )\n",
    ")\n",
    "\n",
    "filtered_lf.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-3'></a>\n",
    "## 3. ğŸ“ˆ ×—×œ×•× ×•×ª ××ª×’×œ×’×œ×™× (Rolling Windows)\n",
    "\n",
    "### ×××•×¦×¢ × ×¢ ×¤×©×•×˜"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×××•×¦×¢ × ×¢ ×©×œ 3 ×©×¢×•×ª ×¢×œ ×”×˜××¤×¨×˜×•×¨×”\n",
    "(\n",
    "    lf\n",
    "    .select(\n",
    "        'datetime',\n",
    "        'temperature',\n",
    "        pl.col('temperature').rolling_mean(3).alias('3hr_rolling_avg')\n",
    "    )\n",
    "    .head()\n",
    "    .collect()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×××•×¦×¢×™× ×™×•××™×™×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×—×™×©×•×‘ ×××•×¦×¢ ×˜××¤×¨×˜×•×¨×” ×™×•××™\n",
    "daily_avg_temperature_lf = (\n",
    "    lf\n",
    "    .select(\n",
    "        pl.col('datetime').dt.date().alias('date'),\n",
    "        'temperature'\n",
    "    )\n",
    "    .group_by('date', maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col('temperature').mean().alias('daily_avg_temp')\n",
    "    )\n",
    ")\n",
    "\n",
    "daily_avg_temperature_lf.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×¡×˜×˜×™×¡×˜×™×§×•×ª ××ª×’×œ×’×œ×•×ª"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×—×™×©×•×‘ ×××•×¦×¢, ××™× ×™××•× ×•××§×¡×™××•× × ×¢×™× ×©×œ 3 ×™××™×\n",
    "(\n",
    "    daily_avg_temperature_lf\n",
    "    .select(\n",
    "        'date',\n",
    "        'daily_avg_temp',\n",
    "        pl.col('daily_avg_temp').rolling_mean(3).alias('3day_rolling_avg'),\n",
    "        pl.col('daily_avg_temp').rolling_min(3).alias('3day_rolling_min'),\n",
    "        pl.col('daily_avg_temp').rolling_max(3).alias('3day_rolling_max')\n",
    "    )\n",
    "    .head()\n",
    "    .collect()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-4'></a>\n",
    "## 4. â±ï¸ ×˜×›× ×™×§×•×ª ×“×’×™××” ××—×“×© (Resampling)\n",
    "\n",
    "### ×ª×ª-×“×’×™××” (Downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×“×’×™××” ××—×“×© ×œ×©×‘×•×¢×•×ª\n",
    "(\n",
    "    lf\n",
    "    .set_sorted('datetime')\n",
    "    .group_by_dynamic(\n",
    "        'datetime',\n",
    "        every='1w'\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col('humidity').mean().round(1)\n",
    "    )\n",
    "    .head(10)\n",
    "    .collect()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×“×’×™××ª ×™×ª×¨ (Upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×“×’×™××ª ×™×ª×¨ - × ×ª×•× ×™× ×›×œ 30 ×“×§×•×ª\n",
    "upsampled_df = (\n",
    "    lf\n",
    "    .set_sorted('datetime')\n",
    "    .collect()\n",
    "    .upsample(\n",
    "        time_column='datetime',\n",
    "        every='30m',\n",
    "        maintain_order=True\n",
    "    )\n",
    "    .select(\n",
    "        'datetime',\n",
    "        pl.col('humidity')\n",
    "    )\n",
    ")\n",
    "\n",
    "upsampled_df.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ××™× ×˜×¨×¤×•×œ×¦×™×”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ××™×œ×•×™ ×”×¢×¨×›×™× ×”×—×¡×¨×™× ×¢× ××™× ×˜×¨×¤×•×œ×¦×™×”\n",
    "(\n",
    "    upsampled_df\n",
    "    .with_columns(\n",
    "        pl.col('humidity').interpolate()\n",
    "    )\n",
    "    .head(10)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-5'></a>\n",
    "## 5. ğŸ”® ×—×™×–×•×™ ×¡×“×¨×•×ª ×–××Ÿ ×¢× Functime\n",
    "\n",
    "### ××”×• Time Series Forecasting?\n",
    "\n",
    "**×—×™×–×•×™ ×¡×“×¨×•×ª ×–××Ÿ** ×”×•× ×ª×”×œ×™×š ×©×œ ×—×™×–×•×™ ×¢×¨×›×™× ×¢×ª×™×“×™×™× ×¢×œ ×‘×¡×™×¡ × ×ª×•× ×™× ×”×™×¡×˜×•×¨×™×™×.\n",
    "\n",
    "### ××” ×–×” Functime?\n",
    "\n",
    "**Functime** ×”×™× ×¡×¤×¨×™×™×” ××ª×§×“××ª ×œ×—×™×–×•×™ ×¡×“×¨×•×ª ×–××Ÿ ×©×¤×•×ª×—×” ×‘××™×•×—×“ ×œ×¢×‘×•×“ ×¢× **Polars**.\n",
    "\n",
    "**×™×ª×¨×•× ×•×ª:**\n",
    "- âš¡ **××”×™×¨×•×ª** - ××•×¤×˜×™××™×–×¦×™×” ××œ××” ×œ-Polars\n",
    "- ğŸ¯ **×¤×©×˜×•×ª** - API × ×§×™ ×•×§×œ ×œ×©×™××•×©\n",
    "- ğŸ”§ **×’××™×©×•×ª** - ××’×•×•×Ÿ ××•×“×œ×™× ×•×˜×›× ×™×§×•×ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸš€ ×”×›× ×ª ×”× ×ª×•× ×™×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×˜×¢×™× ×ª × ×ª×•× ×™ ×˜××¤×¨×˜×•×¨×•×ª ×”×™×¡×˜×•×¨×™×•×ª\n",
    "lf_hist = pl.scan_csv('../data/historical_temperatures.csv', try_parse_dates=True)\n",
    "\n",
    "# ×”×¦×’×ª ×“×•×’××”\n",
    "lf_hist.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×¨×©×™××ª ×”×¢×¨×™×\n",
    "lf_hist.select('city').unique().sort('city').collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª 3 ×©×•×¨×•×ª ×¨××©×•× ×•×ª ×œ×›×œ ×¢×™×¨\n",
    "lf_hist.group_by('city').head(3).collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š ×¦×‘×™×¨×” ×—×•×“×©×™×ª"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×§×‘×œ×ª ×©××•×ª ×”×¢××•×“×•×ª\n",
    "# time_col, entity_col, value_col = lf_hist.collect_schema().names()\n",
    "cols = lf_hist.collect().columns\n",
    "if len(cols) < 3:\n",
    "    raise ValueError(\"expected at least 3 columns after .collect()\")\n",
    "time_col, entity_col, value_col = cols[:3]\n",
    "print(f\"×¢××•×“×•×ª: {time_col}, {entity_col}, {value_col}\")\n",
    "\n",
    "# ×¦×‘×™×¨×” ×—×•×“×©×™×ª + ×”××¨×” ×œ×¦×œ×–×™×•×¡\n",
    "y = (\n",
    "    lf_hist\n",
    "    .group_by_dynamic(\n",
    "        time_col,\n",
    "        every='1mo',\n",
    "        group_by=entity_col,\n",
    "    )\n",
    "    .agg(\n",
    "        (pl.col('temperature').mean() - 273.15).round(1),\n",
    "    )\n",
    ")\n",
    "\n",
    "y.group_by('city').head(3).collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python\n",
    "# Monkeypatch scipy.signal.ricker if missing (run this before importing functime)\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    import scipy.signal as _signal\n",
    "except Exception:\n",
    "    raise\n",
    "\n",
    "if not hasattr(_signal, \"ricker\"):\n",
    "    def ricker(points, a):\n",
    "        # lightweight Ricker (Mexican hat) approximation compatible with old scipy API:\n",
    "        # inputs: points (int), a (float width)\n",
    "        t = np.arange(points) - (points - 1.0) / 2.0\n",
    "        xsq = (t / a) ** 2\n",
    "        return (1 - xsq) * np.exp(-xsq / 2.0)\n",
    "    _signal.ricker = ricker\n",
    "\n",
    "# Now import functime (or call your create_train_test_sets)\n",
    "from functime.cross_validation import train_test_split\n",
    "# ... proceed to call create_train_test_sets(...) as before### ğŸ¯ ×¤×™×¦×•×œ ×œ× ×ª×•× ×™ ××™××•×Ÿ ×•×‘×“×™×§×”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# python\n",
    "# Monkeypatch scipy.signal.ricker if missing (run this before importing functime)\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    import scipy.signal as _signal\n",
    "except Exception:\n",
    "    raise\n",
    "\n",
    "if not hasattr(_signal, \"ricker\"):\n",
    "    def ricker(points, a):\n",
    "        # lightweight Ricker (Mexican hat) approximation compatible with old scipy API:\n",
    "        # inputs: points (int), a (float width)\n",
    "        t = np.arange(points) - (points - 1.0) / 2.0\n",
    "        xsq = (t / a) ** 2\n",
    "        return (1 - xsq) * np.exp(-xsq / 2.0)\n",
    "    _signal.ricker = ricker\n",
    "\n",
    "# Now import functime (or call your create_train_test_sets)\n",
    "from functime.cross_validation import train_test_split\n",
    "# ... proceed to call create_train_test_sets(...) as before"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functime.cross_validation import train_test_split\n",
    "\n",
    "# ×¤×™×¦×•×œ\n",
    "test_size = 3\n",
    "X = y.select(entity_col, time_col)\n",
    "y_train, y_test = (\n",
    "    y\n",
    "    .select(entity_col, time_col, value_col)\n",
    "    .pipe(train_test_split(test_size))\n",
    ")\n",
    "X_train, X_test = X.pipe(train_test_split(test_size))\n",
    "\n",
    "print(f\"Train: {y_train.collect().shape[0]} ×©×•×¨×•×ª\")\n",
    "print(f\"Test: {y_test.collect().shape[0]} ×©×•×¨×•×ª\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤– ××™××•×Ÿ ××•×“×œ"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# python\n",
    "# Patch `functime.conversion` to avoid Polars zero-copy restriction.\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import functime.conversion as conv\n",
    "\n",
    "def _df_to_ndarray(df: pl.DataFrame, n_groups=None) -> np.ndarray:\n",
    "    cols = list(df.columns)[2:]\n",
    "    n_rows = df.height\n",
    "    n_cols = len(cols)\n",
    "    X = np.empty((n_rows, n_cols), dtype=np.float32)\n",
    "    for i, col in enumerate(cols):\n",
    "        series = df.get_column(col)\n",
    "        arr = series.to_numpy(zero_copy_only=False)\n",
    "        X[:, i] = np.asarray(arr, dtype=np.float32)\n",
    "    return X\n",
    "\n",
    "def _X_to_numpy(X: pl.DataFrame) -> np.ndarray:\n",
    "    df = (\n",
    "        X.lazy()\n",
    "        .select(pl.col(X.columns[2:]).cast(pl.Float32))\n",
    "        .select(\n",
    "            pl.when(pl.all().is_infinite() | pl.all().is_nan())\n",
    "            .then(None)\n",
    "            .otherwise(pl.all())\n",
    "            .keep_name()\n",
    "        )\n",
    "        .fill_null(strategy=\"mean\")\n",
    "        .collect(streaming=True)\n",
    "    )\n",
    "    return _df_to_ndarray(df)\n",
    "\n",
    "def _y_to_numpy(y: pl.DataFrame) -> np.ndarray:\n",
    "    ser = (\n",
    "        y.lazy()\n",
    "        .select(pl.col(y.columns[-1]).cast(pl.Float32))\n",
    "        .select(\n",
    "            pl.when(pl.all().is_infinite() | pl.all().is_nan())\n",
    "            .then(None)\n",
    "            .otherwise(pl.all())\n",
    "            .keep_name()\n",
    "        )\n",
    "        .fill_null(strategy=\"mean\")\n",
    "        .collect(streaming=True)\n",
    "        .get_column(y.columns[-1])\n",
    "    )\n",
    "    arr = ser.to_numpy(zero_copy_only=False)\n",
    "    return np.asarray(arr, dtype=np.float32)\n",
    "\n",
    "# Apply patches\n",
    "conv.df_to_ndarray = _df_to_ndarray\n",
    "conv.X_to_numpy = _X_to_numpy\n",
    "conv.y_to_numpy = _y_to_numpy\n",
    "\n",
    "# Now safe to call forecasting code (run this before calling `forecaster.fit`)# Patch functime conversion to avoid Polars zero-copy restriction.\n",
    "# Run this before importing/using functime.forecasting or calling forecaster.fit.\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# Import the module to patch (module may already be loaded)\n",
    "import functime.conversion as conv\n",
    "\n",
    "def _df_to_ndarray(df, n_groups=None):\n",
    "    # keep same signature as original; build a NumPy (float32) matrix\n",
    "    cols = list(df.columns)[2:]\n",
    "    n_rows = df.height\n",
    "    n_cols = len(cols)\n",
    "    X = np.empty((n_rows, n_cols), dtype=np.float32)\n",
    "    for i, col in enumerate(cols):\n",
    "        series = df.get_column(col)\n",
    "        # allow copying if zero-copy isn't possible\n",
    "        arr = series.to_numpy(zero_copy_only=False)\n",
    "        X[:, i] = np.asarray(arr, dtype=np.float32)\n",
    "    return X\n",
    "\n",
    "# Apply patch\n",
    "conv.df_to_ndarray = _df_to_ndarray\n",
    "\n",
    "# Now import and use the forecaster as before\n",
    "from functime.forecasting import linear_model\n",
    "\n",
    "# ×™×¦×™×¨×ª ×”××•×“×œ\n",
    "forecaster = linear_model(lags=24, freq='1mo')\n",
    "# forecaster.fit(y=y_train)  # safe to call now\n",
    "\n",
    "# ××™××•×Ÿ\n",
    "forecaster.fit(y=y_train)\n",
    "\n",
    "# ×—×™×–×•×™\n",
    "y_pred = forecaster.predict(fh=test_size)\n",
    "\n",
    "print(\"×—×™×–×•×™ ×”×•×©×œ×!\")\n",
    "y_pred.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š ×”×¢×¨×›×ª ×“×™×•×§"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functime.metrics import mase\n",
    "\n",
    "# ×—×™×©×•×‘ ×“×™×•×§\n",
    "scores = mase(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_train=y_train\n",
    ")\n",
    "\n",
    "print(\"×¦×™×•× ×™ MASE:\")\n",
    "print(scores)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ˆ ×•×™×–×•××œ×™×–×¦×™×”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×’×¨×£ ×”× ×ª×•× ×™× ×”×××™×ª×™×™×\n",
    "actual_viz = (\n",
    "    y.collect()\n",
    "    .plot.line(\n",
    "        x='datetime',\n",
    "        y='temperature',\n",
    "        by='city',\n",
    "        subplots=True\n",
    "    )\n",
    "    .cols(2)\n",
    ")\n",
    "\n",
    "# ×’×¨×£ ×”×—×™×–×•×™×™×\n",
    "pred_viz = (\n",
    "    y_pred\n",
    "    .plot.line(\n",
    "        x='datetime',\n",
    "        y='temperature',\n",
    "        by='city',\n",
    "        subplots=True\n",
    "    )\n",
    "    .cols(2)\n",
    ")\n",
    "\n",
    "# ×©×™×œ×•×‘\n",
    "actual_viz * pred_viz"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ Feature Engineering ××ª×§×“×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functime.seasonality import add_calendar_effects\n",
    "\n",
    "# ×‘× ×” ××ª ×”×ª×›×•× ×•×ª\n",
    "y_features_base = (\n",
    "    lf_hist\n",
    "    .group_by_dynamic(\n",
    "        time_col,\n",
    "        every='1mo',\n",
    "        group_by=entity_col,\n",
    "    )\n",
    "    .agg([\n",
    "        (pl.col('temperature').mean() - 273.15).round(1).alias('temp_mean'),\n",
    "        pl.col(value_col).mean().alias('value_mean'),\n",
    "        pl.col(value_col).std().alias('value_std'),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# ×”×•×¡×£ calendar effects - ×©×™× ×œ×‘ ×©×–×” ××—×–×™×¨ Transformer!\n",
    "transformer = add_calendar_effects(['month'])\n",
    "\n",
    "# ×”×—×œ ××ª ×”-Transformer\n",
    "y_features = transformer(y_features_base)  # ××• transformer.transform(y_features_base)\n",
    "\n",
    "# ×¢×›×©×™×• ××¤×©×¨ ×œ×”×©×ª××©\n",
    "y_features.head().collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ×¡×™×›×•× - ×—×™×–×•×™\n",
    "\n",
    "**×œ××“× ×•:**\n",
    "- âœ… ××”×• ×—×™×–×•×™ ×¡×“×¨×•×ª ×–××Ÿ\n",
    "- âœ… ×”×›× ×ª × ×ª×•× ×™× ×œ×—×™×–×•×™\n",
    "- âœ… ×¤×™×¦×•×œ ×›×¨×•× ×•×œ×•×’×™ train/test\n",
    "- âœ… ××™××•×Ÿ ××•×“×œ Linear ×¢× Lags\n",
    "- âœ… ×”×¢×¨×›×ª ×“×™×•×§ ×¢× MASE\n",
    "- âœ… ×•×™×–×•××œ×™×–×¦×™×”\n",
    "- âœ… Feature Engineering\n",
    "\n",
    "**ğŸ’¡ ××•×“×œ×™× × ×•×¡×¤×™×:**\n",
    "```python\n",
    "from functime.forecasting import (\n",
    "    linear_model,\n",
    "    lightgbm,  # ××•××œ×¥!\n",
    "    xgboost,\n",
    "    knn,\n",
    "    catboost\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-6'></a>\n",
    "## 6. ğŸ“ ×ª×¨×’×™×œ×™× ××™× ×˜×¨××§×˜×™×‘×™×™×\n",
    "\n",
    "### ×ª×¨×’×™×œ 1: ×¡×™× ×•×Ÿ ×•×¤×™×¨×•×§ ×ª××¨×™×›×™× â­\n",
    "\n",
    "**××©×™××”:** ×¡× ×Ÿ ×œ×©× ×ª 2015, ×”×•×¡×£ ×¢××•×“×ª ×™×•× ×‘×©×‘×•×¢, ×•×—×©×‘ ×××•×¦×¢ ×œ×›×œ ×™×•×."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×§×•×“ ×©×œ×š ×›××Ÿ:\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×ª×¨×’×™×œ 2: ×××•×¦×¢ × ×¢ â­â­\n",
    "\n",
    "**××©×™××”:** ×—×©×‘ ×××•×¦×¢×™× × ×¢×™× ×©×œ 7 ×•-30 ×™××™× ×•×¦×•×¨ ×’×¨×£."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×§×•×“ ×©×œ×š ×›××Ÿ:\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ×ª×¨×’×™×œ 3: ×—×™×–×•×™ ×¢× LightGBM â­â­â­â­\n",
    "\n",
    "**××©×™××”:** ×××Ÿ ××•×“×œ LightGBM ×‘××§×•× Linear ×•×—×–×” 6 ×—×•×“×©×™×."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×§×•×“ ×©×œ×š ×›××Ÿ:\n",
    "# from functime.forecasting import lightgbm\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section-7'></a>\n",
    "## 7. ğŸ“š ×¡×™×›×•× ×•×˜×™×¤×™×\n",
    "\n",
    "### ğŸ¯ ××” ×œ××“× ×•?\n",
    "\n",
    "#### 1. ×¢×‘×•×“×” ×¢× ×ª××¨×™×›×™×\n",
    "- âœ… ×˜×¢×™× ×” ××•×˜×•××˜×™×ª ×¢× `try_parse_dates`\n",
    "- âœ… ×¤×™×¨×•×§ ×œ×¨×›×™×‘×™×\n",
    "- âœ… ×¡×™× ×•×Ÿ ×œ×¤×™ ×˜×•×•×—×™×\n",
    "\n",
    "#### 2. ×—×œ×•× ×•×ª ××ª×’×œ×’×œ×™×\n",
    "- âœ… `rolling_mean`, `rolling_min`, `rolling_max`\n",
    "- âœ… ×©×™×˜×•×ª ×©×•× ×•×ª\n",
    "- âœ… ×•×™×–×•××œ×™×–×¦×™×”\n",
    "\n",
    "#### 3. Resampling\n",
    "- âœ… Downsampling ×¢× `group_by_dynamic`\n",
    "- âœ… Upsampling ×¢× `upsample`\n",
    "- âœ… ××™× ×˜×¨×¤×•×œ×¦×™×”\n",
    "\n",
    "#### 4. ×—×™×–×•×™ ğŸ”®\n",
    "- âœ… ××™××•×Ÿ ××•×“×œ×™×\n",
    "- âœ… ×”×¢×¨×›×ª ×“×™×•×§\n",
    "- âœ… Feature Engineering\n",
    "\n",
    "### ğŸ’¡ 10 ×˜×™×¤×™× ×—×©×•×‘×™×\n",
    "\n",
    "1. **×ª××™×“ ×‘×“×•×§ ×¡×•×’×™ × ×ª×•× ×™×**\n",
    "2. **×”×©×ª××© ×‘-set_sorted()** ×œ×¤× ×™ ×¤×¢×•×œ×•×ª ×–××Ÿ\n",
    "3. **LazyFrame vs DataFrame** - ×“×¢ ××ª×™ ×œ×”×©×ª××©\n",
    "4. **×‘×“×•×§ ×¢× head() ×§×•×“×**\n",
    "5. **prefer built-in functions**\n",
    "6. **×•×™×–×•××œ×™×–×¦×™×”** - ×ª××™×“\n",
    "7. **maintain_order=True** ×‘group_by\n",
    "8. **min_periods=1** ×œ×× ×™×¢×ª nulls\n",
    "9. **×¤×¦×œ ×›×¨×•× ×•×œ×•×’×™×ª** ×‘×—×™×–×•×™\n",
    "10. **×ª×¢×“ ××ª ×”×§×•×“** ×©×œ×š\n",
    "\n",
    "### ğŸ“– ××©××‘×™× × ×•×¡×¤×™×\n",
    "\n",
    "- **Polars:** https://pola-rs.github.io/polars/\n",
    "- **Functime:** https://docs.functime.ai/\n",
    "- **Discord:** https://discord.gg/4UfP5cfBE7\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ ×¡×™×™××ª×!\n",
    "\n",
    "×›×œ ×”×›×‘×•×“! ×¢×›×©×™×• ××ª× ×™×•×“×¢×™× ×œ×¢×‘×•×“ ×¢× ×¡×“×¨×•×ª ×–××Ÿ ×‘-Polars **×•××¤×™×œ×• ×œ×—×–×•×ª ××ª ×”×¢×ª×™×“**! ğŸ”®\n",
    "\n",
    "**×‘×”×¦×œ×—×”!** ğŸŒŸ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
