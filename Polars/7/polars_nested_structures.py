#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
××“×¨×™×š ××§×™×£ ×œ×¢×‘×•×“×” ×¢× ××‘× ×™ × ×ª×•× ×™× ××§×•× × ×™× ×‘-Polars
=====================================================

××—×‘×¨: × ×•×¦×¨ ××•×˜×•××˜×™×ª
×ª××¨×™×š: 2025
×ª×™××•×¨: ×§×•×“ Python ××•×›×Ÿ ×œ×”×¨×¦×” ×œ×¢×‘×•×“×” ×¢× Lists, Structs ×•-JSON ×‘-Polars

×“×¨×™×©×•×ª:
    pip install polars

×©×™××•×©:
    python polars_nested_structures.py
"""

import polars as pl
import warnings
warnings.filterwarnings('ignore')


def print_section(title):
    """×”×“×¤×¡×ª ×›×•×ª×¨×ª ××“×•×¨"""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}\n")


def load_data(csv_path='../data/us_videos.csv'):
    """
    ×˜×¢×™× ×ª × ×ª×•× ×™ YouTube
    
    Args:
        csv_path (str): × ×ª×™×‘ ×œ×§×•×‘×¥ CSV
        
    Returns:
        pl.DataFrame: DataFrame ×¢× ×”× ×ª×•× ×™×
    """
    print_section("ğŸ“Š ×˜×¢×™× ×ª ×”× ×ª×•× ×™×")
    
    # ×˜×¢×™× ×ª ×”× ×ª×•× ×™×
    df = pl.read_csv(csv_path, try_parse_dates=True)
    
    # ×”××¨×ª ×¢××•×“×ª ×”×ª××¨×™×›×™×
    df = df.with_columns(
        pl.col("trending_date").str.to_date(format="%y.%d.%m")
    )
    
    print(f"âœ… × ×˜×¢× ×• {df.height:,} ×©×•×¨×•×ª ×•-{df.width} ×¢××•×“×•×ª")
    print(f"\nğŸ” 5 ×”×©×•×¨×•×ª ×”×¨××©×•× ×•×ª:")
    print(df.head())
    
    return df


def demo_creating_lists(df):
    """×”×“×’××ª ×™×¦×™×¨×ª ×¨×©×™××•×ª"""
    print_section("ğŸ“ 1. ×™×¦×™×¨×ª ×¨×©×™××•×ª (Creating Lists)")
    
    # ×“×¨×š 1: ×¤×™×¦×•×œ ××—×¨×•×–×•×ª
    print("ğŸ”¹ ×“×¨×š 1: ×¤×™×¦×•×œ ××—×¨×•×–×•×ª")
    print("-" * 50)
    result = df.select(
        'tags',
        pl.col('tags').str.split('|').alias('tags_list')
    ).head()
    print(result)
    
    # ×“×¨×š 2: ×¦×‘×™×¨×ª ×¢×¨×›×™×
    print("\nğŸ”¹ ×“×¨×š 2: ×¦×‘×™×¨×ª ×¢×¨×›×™×")
    print("-" * 50)
    videos_by_date = (
        df
        .group_by('trending_date')
        .agg(pl.col('video_id'))
        .sort('trending_date', descending=True)
    ).head()
    print(videos_by_date)
    
    # ×“×¨×š 3: ××™×—×•×“ ×¢××•×“×•×ª
    print("\nğŸ”¹ ×“×¨×š 3: ××™×—×•×“ ×¢××•×“×•×ª")
    print("-" * 50)
    engagement = df.select(
        pl.concat_list(
            pl.col('views'),
            pl.col('likes'),
            pl.col('dislikes'),
            pl.col('comment_count')
        ).alias('engagement_metrics')
    ).head()
    print(engagement)


def demo_aggregating_lists(df):
    """×”×“×’××ª ×¦×‘×™×¨×ª ××œ×× ×˜×™× ×‘×¨×©×™××•×ª"""
    print_section("ğŸ§® 2. ×¦×‘×™×¨×ª ××œ×× ×˜×™× ×‘×¨×©×™××•×ª")
    
    # ×¦×‘×™×¨×ª × ×ª×•× ×™×
    agg_df = (
        df
        .group_by('trending_date')
        .agg('views', 'likes', 'dislikes', 'comment_count')
        .sort('trending_date', descending=True)
    )
    
    # ×¤×¢×•×œ×•×ª ×¦×‘×™×¨×”
    print("ğŸ”¹ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¢×œ ×”×¦×¤×™×•×ª")
    print("-" * 50)
    stats = agg_df.select(
        'trending_date',
        pl.col('views').list.min().alias('min_views'),
        pl.col('views').list.max().alias('max_views'),
        pl.col('views').list.mean().alias('avg_views'),
        pl.col('likes').list.max().alias('max_likes'),
        pl.col('dislikes').list.mean().alias('avg_dislikes'),
        pl.col('comment_count').list.sum().alias('total_comments')
    ).head()
    print(stats)
    
    # ××™×—×•×“ ×œ××—×¨×•×–×ª
    print("\nğŸ”¹ ××™×—×•×“ ×©××•×ª ×¢×¨×•×¦×™×")
    print("-" * 50)
    channels = (
        df
        .group_by('trending_date')
        .agg(pl.col('channel_title'))
        .with_columns(
            pl.col('channel_title').list.join(', ').alias('all_channels')
        )
        .select('trending_date', 'all_channels')
        .sort('trending_date', descending=True)
    ).head(3)
    print(channels)
    
    # ×¡×¤×™×¨×ª ××œ×× ×˜×™×
    print("\nğŸ”¹ ××¡×¤×¨ ×¡×¨×˜×•× ×™× ×˜×¨× ×“×™×™× ×œ×™×•×")
    print("-" * 50)
    counts = agg_df.select(
        'trending_date',
        pl.col('views').list.len().alias('num_trending_videos')
    ).head()
    print(counts)


def demo_accessing_elements(df):
    """×”×“×’××ª ×’×™×©×” ×•×‘×—×™×¨×ª ××œ×× ×˜×™×"""
    print_section("ğŸ¯ 3. ×’×™×©×” ×•×‘×—×™×¨×ª ××œ×× ×˜×™×")
    
    # ×”×›× ×ª × ×ª×•× ×™×
    trending_dates_by_channel = (
        df
        .group_by('channel_title')
        .agg('trending_date')
        .with_columns(
            pl.col('trending_date').list.sort()
        )
    )
    
    # ××œ×× ×˜×™× ×¨××©×•× ×™× ×•××—×¨×•× ×™×
    print("ğŸ”¹ ×ª××¨×™×›×™× ×¨××©×•× ×™× ×•××—×¨×•× ×™×")
    print("-" * 50)
    first_last = trending_dates_by_channel.with_columns(
        pl.col('trending_date').list.first().alias('first_trending_date'),
        pl.col('trending_date').list.last().alias('last_trending_date')
    ).head()
    print(first_last)
    
    # ×’×™×©×” ×œ××œ×× ×˜ ×¡×¤×¦×™×¤×™
    print("\nğŸ”¹ ×”××œ×× ×˜ ×”×©××™× ×™")
    print("-" * 50)
    eighth = trending_dates_by_channel.with_columns(
        pl.col('trending_date').list.get(7, null_on_oob=True).alias('8th_element')
    ).head()
    print(eighth)
    
    # ×—×™×ª×•×š
    print("\nğŸ”¹ ×“×•×’×××•×ª ×—×™×ª×•×š")
    print("-" * 50)
    sliced = trending_dates_by_channel.select(
        'trending_date',
        pl.col('trending_date').list.slice(0, 2).alias('first_2'),
        pl.col('trending_date').list.slice(-3, 1).alias('3rd_from_end'),
        pl.col('trending_date').list.slice(7).alias('from_8th_onward')
    ).head()
    print(sliced)
    
    # gather
    print("\nğŸ”¹ ×‘×—×™×¨×” ××•×ª×××ª (Gather)")
    print("-" * 50)
    gathered = trending_dates_by_channel.select(
        'trending_date',
        pl.col('trending_date').list.gather([0, -1]).alias('first_and_last'),
        pl.col('trending_date').list.gather([0, 10], null_on_oob=True).alias('first_and_11th')
    ).head()
    print(gathered)


def demo_applying_logic(df):
    """×”×“×’××ª ×”×—×œ×ª ×œ×•×’×™×§×” ×¢×œ ××œ×× ×˜×™×"""
    print_section("âš™ï¸ 4. ×”×—×œ×ª ×œ×•×’×™×§×” ×¢×œ ××œ×× ×˜×™×")
    
    # ×”×›× ×ª × ×ª×•× ×™×
    agg_df = (
        df
        .group_by('trending_date')
        .agg('views', 'channel_title')
    )
    
    # ×”××¨×” ×œ××•×ª×™×•×ª ×’×“×•×œ×•×ª
    print("ğŸ”¹ ×”××¨×” ×œ××•×ª×™×•×ª ×’×“×•×œ×•×ª")
    print("-" * 50)
    uppercase = (
        agg_df
        .select(
            pl.col('channel_title').list.head(2),
            pl.col('channel_title')
            .list.eval(pl.element().str.to_uppercase())
            .list.head(2)
            .alias('channel_uppercase')
        )
    ).head()
    print(uppercase)
    
    # ×“×™×¨×•×’
    print("\nğŸ”¹ ×“×™×¨×•×’ ×¦×¤×™×•×ª")
    print("-" * 50)
    ranked = agg_df.select(
        'trending_date',
        'views',
        pl.col('views')
        .list.eval(pl.element().rank('dense', descending=True))
        .alias('views_rank')
    ).head()
    print(ranked)
    
    # ×—×™×©×•×‘×™× ××•×¨×›×‘×™×
    print("\nğŸ”¹ ×¤×¢×¨ ××”××§×¡×™××•×")
    print("-" * 50)
    diff = ranked.select(
        'views',
        pl.col('views')
        .list.eval(pl.element().max() - pl.element())
        .alias('gap_to_max')
    ).head()
    print(diff)
    
    # ×¤×¢×•×œ×•×ª ×§×‘×•×¦×•×ª
    print("\nğŸ”¹ ×¤×¢×•×œ×•×ª ×§×‘×•×¦×•×ª")
    print("-" * 50)
    set_ops = ranked.with_columns(
        pl.col('views_rank').list.slice(0, 2).alias('top_2_ranks'),
        pl.col('views_rank').list.slice(-2, 2).alias('bottom_2_ranks')
    ).select(
        'top_2_ranks',
        'bottom_2_ranks',
        pl.col('top_2_ranks').list.set_intersection('bottom_2_ranks').alias('intersection'),
        pl.col('top_2_ranks').list.set_union('bottom_2_ranks').alias('union'),
        pl.col('top_2_ranks').list.set_difference('bottom_2_ranks').alias('difference')
    ).head()
    print(set_ops)


def demo_structs_and_json():
    """×”×“×’××ª ×¢×‘×•×“×” ×¢× Structs ×•-JSON"""
    print_section("ğŸ—ï¸ 5. ×¢×‘×•×“×” ×¢× Structs ×•-JSON")
    
    # ×˜×¢×™× ×ª × ×ª×•× ×™ JSON
    print("ğŸ”¹ ×˜×¢×™× ×ª × ×ª×•× ×™ JSON")
    print("-" * 50)
    try:
        ga_df = pl.read_json('../data/ga_20170801.json')
        cols = ['visitId', 'date', 'totals', 'trafficSource', 'customDimensions', 'channelGrouping']
        ga_df = ga_df.select(cols)
        
        print(f"âœ… × ×˜×¢× ×• {ga_df.height:,} ×‘×™×§×•×¨×™×")
        print(ga_df.head(3))
        
        # ×™×¦×™×¨×ª struct
        print("\nğŸ”¹ ×™×¦×™×¨×ª Struct")
        print("-" * 50)
        with_struct = ga_df.with_columns(
            pl.struct('visitId', 'date', 'channelGrouping').alias('visit_info')
        )
        print(with_struct.select('visitId', 'date', 'channelGrouping', 'visit_info').head(3))
        
        # ×¤×ª×™×—×ª struct
        print("\nğŸ”¹ ×¤×ª×™×—×ª Struct (Unnesting)")
        print("-" * 50)
        unnested = (
            with_struct
            .select('visit_info')
            .unnest('visit_info')
        ).head(3)
        print(unnested)
        
        # ×’×™×©×” ×œ×©×“×”
        print("\nğŸ”¹ ×’×™×©×” ×œ×©×“×” ×‘-Struct")
        print("-" * 50)
        field_access = with_struct.select(
            'visit_info',
            pl.col('visit_info').struct.field('channelGrouping').alias('channel')
        ).head(3)
        print(field_access)
        
        # ×”××¨×” ×œ-JSON
        print("\nğŸ”¹ ×”××¨×” ×œ-JSON ×•×—×–×¨×”")
        print("-" * 50)
        json_conv = (
            ga_df
            .select(
                pl.col('totals').struct.json_encode().alias('totals_json'),
                pl.col('totals').struct.json_encode().str.json_decode().alias('totals_decoded')
            )
        ).head(3)
        print(json_conv)
        
    except Exception as e:
        print(f"âš ï¸ ×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×§×•×‘×¥ ×”-JSON: {e}")
        print("   ×× × ×•×“× ×©×”×§×•×‘×¥ '../data/ga_20170801.json' ×§×™×™×")


def run_all_demos():
    """×”×¨×¦×ª ×›×œ ×”×”×“×’××•×ª"""
    print("\n" + "="*70)
    print("  ğŸ» ××“×¨×™×š ××§×™×£: ×¢×‘×•×“×” ×¢× ××‘× ×™ × ×ª×•× ×™× ××§×•× × ×™× ×‘-Polars")
    print("="*70)
    print(f"\nğŸ“¦ ×’×¨×¡×ª Polars: {pl.__version__}")
    
    try:
        # ×˜×¢×™× ×ª × ×ª×•× ×™×
        df = load_data()
        
        # ×”×“×’××•×ª
        demo_creating_lists(df)
        demo_aggregating_lists(df)
        demo_accessing_elements(df)
        demo_applying_logic(df)
        demo_structs_and_json()
        
        # ×¡×™×›×•×
        print_section("ğŸ‰ ×¡×™×›×•×")
        print("âœ… ×›×œ ×”×”×“×’××•×ª ×”×•×©×œ××• ×‘×”×¦×œ×—×”!")
        print("\nğŸ’¡ ×˜×™×¤×™×:")
        print("  - ×”×©×ª××© ×‘-null_on_oob=True ×œ×× ×™×¢×ª ×©×’×™××•×ª")
        print("  - ×”×¢×“×£ ×¤×¢×•×œ×” ××—×ª ×¢×œ ×¤× ×™ ×¤×¢×•×œ×•×ª ××¨×•×‘×•×ª")
        print("  - ×”×©×ª××© ×‘-glimpse() ×œ×‘×“×™×§×ª ×˜×™×¤×•×¡×™×")
        print("\nğŸ“š ××©××‘×™× × ×•×¡×¤×™×:")
        print("  - https://pola-rs.github.io/polars/")
        print("  - https://github.com/pola-rs/polars")
        
    except FileNotFoundError:
        print("\nâŒ ×©×’×™××”: ×œ× × ××¦× ×§×•×‘×¥ ×”× ×ª×•× ×™×!")
        print("   ×× × ×•×“× ×©×”×§×•×‘×¥ '../data/us_videos.csv' ×§×™×™×")
    except Exception as e:
        print(f"\nâŒ ×©×’×™××” ×œ× ×¦×¤×•×™×”: {e}")


if __name__ == "__main__":
    run_all_demos()
