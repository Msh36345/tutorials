{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# π“ PySpark - Χ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ CSV Χ-DataFrame\n",
    "[PySpark Read CSV file into DataFrame](https://sparkbyexamples.com/pyspark/pyspark-read-csv-file-into-dataframe/)\n",
    "## ΧΧ‘Χ•Χ\n",
    "\n",
    "Χ§Χ¨Χ™ΧΧ Χ§Χ‘Χ¦Χ™ CSV ΧΧΧ‘Χ Χ” DataFrame ΧΧ•Χ‘Χ Χ” Χ”Χ•Χ¤Χ›Χ ΧΧ§ΧΧ” Χ•Χ™ΧΆΧ™ΧΧ” ΧΆΧ PySpark DataFrame API. Χ‘ΧΧΧ¦ΧΆΧ•Χ ΧΧ•Χ“Χ Χ”ΧΧ—Χ©Χ•Χ‘ Χ”ΧΧ‘Χ•Χ–Χ¨ Χ©Χ PySpark, ΧΧ©ΧΧΧ©Χ™Χ Χ™Χ›Χ•ΧΧ™Χ ΧΧΆΧ‘Χ“ ΧΧΆΧ¨Χ›Χ™ Χ ΧΧ•Χ Χ™Χ ΧΆΧ¦Χ•ΧΧ™Χ Χ©Χ CSV Χ‘ΧΧ”Χ™Χ¨Χ•Χ Χ‘Χ¨Χ§Χ™Χ, ΧΧ¤ΧΧ•Χ— ΧΧ•Χ‘Χ Χ•Χ Χ—Χ©Χ•Χ‘Χ•Χ Χ•ΧΧ”ΧΧ™Χ¥ ΧΧ ΧΧ”ΧΧ™Χ›Χ™ Χ§Χ‘ΧΧ Χ”Χ”Χ—ΧΧΧ•Χ.\n",
    "\n",
    "Χ‘Χ™Χ ΧΧ ΧΧΧ” ΧΆΧ•Χ‘Χ“ ΧΆΧ Χ’Χ™Χ’Χ”Χ‘Χ™Χ™ΧΧ™Χ ΧΧ• Χ¤ΧΧ”Χ‘Χ™Χ™ΧΧ™Χ Χ©Χ Χ ΧΧ•Χ Χ™Χ, Χ©Χ™ΧΧ•Χ‘ Χ”-CSV Χ©Χ PySpark ΧΧ¦Χ™ΧΆ Χ’Χ™Χ©Χ” Χ’ΧΧ™Χ©Χ” Χ•Χ Χ™ΧΧ Χ ΧΧ”Χ¨Χ—Χ‘Χ” ΧΧ Χ™ΧΧ•Χ— Χ ΧΧ•Χ Χ™Χ, Χ”ΧΧΆΧ¦Χ™ΧΧ” ΧΧ¨Χ’Χ•Χ Χ™Χ ΧΧ Χ¦Χ ΧΧ ΧΧΧ•Χ Χ”Χ¤Χ•ΧΧ Χ¦Χ™ΧΧ Χ©Χ Χ”Χ Χ›Χ΅Χ™Χ Χ©ΧΧ”Χ.\n",
    "\n",
    "### π― Χ Χ§Χ•Χ“Χ•Χ ΧΧ¤ΧΧ—:\n",
    "\n",
    "- PySpark ΧΧ•ΧΧ Χ‘Χ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ CSV ΧΆΧ pipe, Χ¤Χ΅Χ™Χ§, tab, Χ¨Χ•Χ•Χ— ΧΧ• Χ›Χ ΧΧ• ΧΧ¤Χ¨Χ™Χ“ ΧΧ—Χ¨\n",
    "- PySpark Χ§Χ•Χ¨Χ Χ§Χ‘Χ¦Χ™ CSV Χ‘ΧΧ§Χ‘Χ™Χ, ΧΧ•Χ Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ΅Χ¤Χ¨ Χ¦ΧΧΧ™ executor ΧΧ”ΧΧ™Χ¥ ΧΧ Χ§ΧΧ™ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ\n",
    "- PySpark Χ™Χ›Χ•Χ ΧΧ”Χ΅Χ™Χ§ ΧΧ•ΧΧ•ΧΧΧ™Χ ΧΧ Χ΅Χ›Χ™ΧΧ Χ§Χ‘Χ¦Χ™ CSV, Χ•ΧΧ‘ΧΧ ΧΧ Χ”Χ¦Χ•Χ¨Χ Χ‘Χ”Χ’Χ“Χ¨Χ Χ΅Χ›Χ™ΧΧ” Χ™Χ“Χ Χ™Χ Χ‘ΧΧ§Χ¨Χ™Χ Χ¨Χ‘Χ™Χ\n",
    "- ΧΧΧ©ΧΧΧ©Χ™Χ Χ™Χ© Χ’ΧΧ™Χ©Χ•Χ ΧΧ”Χ’Χ“Χ™Χ¨ Χ΅Χ›Χ™ΧΧ•Χ ΧΧ•ΧΧΧΧ•Χ ΧΧ™Χ©Χ™Χ ΧΧ§Χ‘Χ¦Χ™ CSV, ΧΧ•Χ Χ¦Χ™Χ•Χ Χ΅Χ•Χ’Χ™ Χ ΧΧ•Χ Χ™Χ Χ•Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ ΧΧ¤Χ™ Χ”Χ¦Χ•Χ¨Χ\n",
    "- PySpark ΧΧ¦Χ™ΧΆ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΧΧ™Χ¤Χ•Χ Χ‘Χ›Χ•ΧΧ¨Χ•Χ Χ‘Χ§Χ‘Χ¦Χ™ CSV, Χ•ΧΧΧ¤Χ©Χ¨ ΧΧΧ©ΧΧΧ©Χ™Χ ΧΧ“ΧΧ’ ΧΆΧ Χ›Χ•ΧΧ¨Χ•Χ ΧΧ• ΧΧ”ΧΧ™Χ™Χ—Χ΅ ΧΧΧ™Χ”Χ Χ›Χ©Χ•Χ¨Χ•Χ Χ ΧΧ•Χ Χ™Χ\n",
    "- ΧΧ΅Χ¤Χ§ ΧΧ Χ’Χ Χ•Χ Χ™ ΧΧ™Χ¤Χ•Χ Χ‘Χ©Χ’Χ™ΧΧ•Χ Χ—Χ–Χ§Χ™Χ ΧΧ”ΧΧΧ•Χ“Χ“Χ•Χ ΧΆΧ Χ§Χ‘Χ¦Χ™ CSV Χ¤Χ’Χ•ΧΧ™Χ ΧΧ• ΧΧ ΧΧ§Χ™Χ Χ™Χ, Χ•ΧΧ‘ΧΧ™Χ— Χ©ΧΧΧ•Χ Χ ΧΧ•Χ Χ™Χ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Χ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ CSV Χ-PySpark DataFrame\n",
    "\n",
    "Χ›Χ“Χ™ ΧΧ§Χ¨Χ•Χ Χ§Χ•Χ‘Χ¥ CSV Χ-PySpark DataFrame, Χ”Χ©ΧΧΧ© Χ‘-`csv(\"path\")` ΧΧ”-DataFrameReader. Χ©Χ™ΧΧ” Χ–Χ• ΧΧ§Χ‘ΧΧ Χ ΧΧ™Χ‘ Χ§Χ•Χ‘Χ¥ Χ›Χ¤Χ¨ΧΧΧ¨.\n",
    "\n",
    "Χ›ΧΧ©Χ¨ ΧΧ©ΧΧΧ©Χ™Χ Χ‘-format(\"csv\"), Χ™Χ© ΧΧ¦Χ™Χ™Χ ΧΧ§Χ•Χ¨Χ•Χ Χ ΧΧ•Χ Χ™Χ Χ›ΧΧ• `csv` ΧΧ• `org.apache.spark.sql.csv`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ™Χ™Χ‘Χ•Χ Χ”Χ΅Χ¤Χ¨Χ™Χ•Χ Χ”Χ Χ“Χ¨Χ©Χ•Χ\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Χ™Χ¦Χ™Χ¨Χ SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Χ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ CSV\n",
    "df = spark.read.csv(\"../data/zipcodes.csv\")\n",
    "# df.printSchema()\n",
    "df.show(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΧΧ—ΧΧ•Χ¤Χ™Χ, Χ Χ™ΧΧ ΧΧ”Χ©ΧΧΧ© Χ‘Χ¤Χ•Χ Χ§Χ¦Χ™Χ” `format()` Χ™Χ—Χ“ ΧΆΧ Χ©Χ™ΧΧ `load()` ΧΧ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ JSON:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# -- ΧΧ• --\n",
    "# df = spark.read.format(\"csv\") \\\n",
    "#     .load(\"../data/zipcodes.csv\")\n",
    "\n",
    "# -- ΧΧ• --\n",
    "# df = spark.read.format(\"org.apache.spark.sql.csv\") \\\n",
    "#     .load(\"../data/zipcodes.csv\")\n",
    "# df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χ“Χ•Χ’ΧΧ” Χ–Χ• Χ§Χ•Χ¨Χ ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ ΧΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ DataFrame `\"_c0\"` ΧΆΧ‘Χ•Χ¨ Χ”ΧΆΧΧ•Χ“Χ” Χ”Χ¨ΧΧ©Χ•Χ Χ” Χ•-`\"_c1\"` ΧΆΧ‘Χ•Χ¨ Χ”Χ©Χ Χ™Χ™Χ” Χ•Χ›Χ Χ”ΧΧΧ”. Χ•Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ Χ΅Χ•Χ’ Χ”Χ ΧΧ•Χ Χ™Χ ΧΆΧ‘Χ•Χ¨ Χ›Χ Χ”ΧΆΧΧ•Χ“Χ•Χ ΧΧΧ•Χ¤Χ Χ›-String.\n",
    "\n",
    "### Χ¤ΧΧ:\n",
    "```\n",
    "root\n",
    " |-- _c0: string (nullable = true)\n",
    " |-- _c1: string (nullable = true)\n",
    " |-- _c2: string (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Χ©Χ™ΧΧ•Χ© Χ‘Χ¨Χ©Χ•ΧΧ Header ΧΆΧ‘Χ•Χ¨ Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ\n",
    "\n",
    "ΧΧ Χ™Χ© ΧΧ header ΧΆΧ Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ Χ‘Χ§Χ•Χ‘Χ¥ Χ”Χ§ΧΧ Χ©ΧΧ, ΧΆΧΧ™Χ ΧΧ¦Χ™Χ™Χ Χ‘ΧΧ¤Χ•Χ¨Χ© `True` ΧΧΧ¤Χ©Χ¨Χ•Χ header Χ‘ΧΧΧ¦ΧΆΧ•Χ `option(\"header\",True)`. ΧΧ™ Χ¦Χ™Χ•Χ Χ©Χ Χ–Χ”, Χ”-API ΧΧΧ™Χ™Χ—Χ΅ ΧΧ”Χ›Χ•ΧΧ¨Χ Χ›Χ¨Χ©Χ•ΧΧ Χ ΧΧ•Χ Χ™Χ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ header ΧΧ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ\n",
    "df2 = spark.read.option(\"header\", True) \\\n",
    "    .csv(\"../data/zipcodes.csv\")\n",
    "df2.show(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χ›Χ¤Χ™ Χ©Χ”Χ•Χ–Χ›Χ¨ Χ§Χ•Χ“Χ ΧΧ›Χ, PySpark Χ§Χ•Χ¨Χ ΧΧ Χ›Χ Χ”ΧΆΧΧ•Χ“Χ•Χ Χ›-string (StringType) Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ. ΧΧ΅Χ‘Χ™Χ¨ Χ‘Χ΅ΧΆΧ™Χ¤Χ™Χ ΧΧΧ•Χ—Χ¨Χ™Χ Χ™Χ•ΧΧ¨ Χ›Χ™Χ¦Χ“ ΧΧ§Χ¨Χ•Χ ΧΧ Χ”Χ΅Χ›Χ™ΧΧ” (inferSchema) ΧΧ¨Χ©Χ•ΧΧ Χ”Χ›Χ•ΧΧ¨Χ Χ•ΧΧ’Χ–Χ•Χ¨ ΧΧ Χ΅Χ•Χ’ Χ”ΧΆΧΧ•Χ“Χ” Χ‘Χ”ΧΧ‘Χ΅Χ΅ ΧΆΧ Χ”Χ ΧΧ•Χ Χ™Χ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Χ§Χ¨Χ™ΧΧ ΧΧ΅Χ¤Χ¨ Χ§Χ‘Χ¦Χ™ CSV\n",
    "\n",
    "Χ›Χ“Χ™ ΧΧ§Χ¨Χ•Χ ΧΧ΅Χ¤Χ¨ Χ§Χ‘Χ¦Χ™ CSV Χ‘Χ• Χ–ΧΧ Χ™Χ Χ-PySpark DataFrame, Χ›Χ ΧΧ—Χ“ ΧΧ•Χ¤Χ¨Χ“ Χ‘Χ¤Χ΅Χ™Χ§, Χ Χ™ΧΧ ΧΧ™Χ¦Χ•Χ¨ Χ¨Χ©Χ™ΧΧ” Χ©Χ Χ ΧΧ™Χ‘Χ™ Χ§Χ‘Χ¦Χ™Χ Χ•ΧΧ”ΧΆΧ‘Χ™Χ¨ ΧΧ•ΧΧ” ΧΧ©Χ™ΧΧ `spark.read.csv()`.\n",
    "```\n",
    "# Χ§Χ¨Χ™ΧΧ ΧΧ΅Χ¤Χ¨ Χ§Χ‘Χ¦Χ™Χ\n",
    "df = spark.read.csv(\"path/file1.csv,path/file2.csv,path/file3.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Χ§Χ¨Χ™ΧΧ Χ›Χ Χ”Χ§Χ‘Χ¦Χ™Χ Χ‘ΧΧ™Χ§Χ™Χ™Χ”\n",
    "\n",
    "Χ›Χ“Χ™ ΧΧ§Χ¨Χ•Χ ΧΧ Χ›Χ Χ§Χ‘Χ¦Χ™ Χ”-JSON ΧΧΧ™Χ§Χ™Χ™Χ” Χ-PySpark DataFrame Χ‘Χ• Χ–ΧΧ Χ™Χ, Χ”Χ©ΧΧΧ© Χ‘-`spark.read.json(\"directory_path\")`, Χ›ΧΧ©Χ¨ `\"directory_path\"` ΧΧ¦Χ‘Χ™ΧΆ ΧΆΧ Χ”ΧΧ™Χ§Χ™Χ™Χ” Χ”ΧΧ›Χ™ΧΧ” ΧΧ Χ§Χ‘Χ¦Χ™ Χ”-JSON. PySpark ΧΧΆΧ‘Χ“ ΧΧ•ΧΧ•ΧΧΧ™Χ ΧΧ Χ›Χ Χ§Χ‘Χ¦Χ™ Χ”-JSON Χ‘ΧΧ™Χ§Χ™Χ™Χ”.\n",
    "```\n",
    "# Χ§Χ¨Χ™ΧΧ Χ›Χ Χ§Χ‘Χ¦Χ™ JSON ΧΧΧ™Χ§Χ™Χ™Χ”\n",
    "df = spark.read.csv(\"Folder path\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ CSV\n",
    "\n",
    "PySpark CSV dataset ΧΧ΅Χ¤Χ§ ΧΧ΅Χ¤Χ¨ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΧΆΧ‘Χ•Χ“Χ” ΧΆΧ Χ§Χ‘Χ¦Χ™ CSV. ΧΧ”ΧΧ Χ›ΧΧ” ΧΧ”ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ”Χ—Χ©Χ•Χ‘Χ•Χ Χ‘Χ™Χ•ΧΧ¨ Χ”ΧΧ•Χ΅Χ‘Χ¨Χ•Χ ΧΆΧ Χ“Χ•Χ’ΧΧΧ•Χ.\n",
    "\n",
    "Χ Χ™ΧΧ ΧΧ©Χ¨Χ©Χ¨ option() ΧΧ©Χ™ΧΧ•Χ© Χ‘ΧΧ΅Χ¤Χ¨ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΧ• ΧΧ”Χ©ΧΧΧ© Χ‘Χ©Χ™ΧΧ” Χ”Χ—ΧΧ•Χ¤Χ™Χ options().\n",
    "```\n",
    "# ΧΧ—Χ‘Χ™Χ¨\n",
    "options(self, key, value)  # Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ Χ‘Χ•Χ“Χ“Χ\n",
    "options(self, **options)   # Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ΅Χ¤Χ¨ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 delimiter (ΧΧ¤Χ¨Χ™Χ“)\n",
    "\n",
    "ΧΧ¤Χ©Χ¨Χ•Χ `delimiter` ΧΧ©ΧΧ©Χ ΧΧ¦Χ™Χ•Χ ΧΧ• Χ”ΧΧ¤Χ¨Χ™Χ“ Χ©Χ Χ”ΧΆΧΧ•Χ“Χ” Χ‘Χ§Χ•Χ‘Χ¥ Χ”-CSV. Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ, Χ–Χ”Χ• **comma (,)** ΧΧ Χ Χ™ΧΧ ΧΧ”Χ’Χ“Χ™Χ¨ ΧΧ•ΧΧ• ΧΧ›Χ ΧΧ• Χ›Χ’Χ•Χ pipe(|), tab (\\t), space."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ delimiter\n",
    "df3 = spark.read.options(delimiter=',') \\\n",
    "    .csv(\"../data/zipcodes.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 inferSchema\n",
    "\n",
    "Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ, ΧΧ¤Χ©Χ¨Χ•Χ `inferSchema` ΧΧ•Χ’Χ“Χ¨Χ Χ-`False`. Χ›ΧΧ©Χ¨ ΧΧ•Χ’Χ“Χ¨ Χ-`True`, Spark Χ§Χ•Χ‘ΧΆ ΧΧ•ΧΧ•ΧΧΧ™Χ ΧΧ Χ΅Χ•Χ’Χ™ Χ ΧΧ•Χ Χ™ Χ”ΧΆΧΧ•Χ“Χ•Χ Χ‘Χ”ΧΧ‘Χ΅Χ΅ ΧΆΧ Χ ΧΧ•Χ Χ™ Χ”Χ§ΧΧ. Χ©Χ™Χ ΧΧ‘ Χ©Χ–Χ” Χ“Χ•Χ¨Χ© Χ§Χ¨Χ™ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ Χ¤ΧΆΧ Χ Χ•Χ΅Χ¤Χ Χ›Χ“Χ™ ΧΧ”Χ΅Χ™Χ§ ΧΧ Χ”Χ΅Χ›Χ™ΧΧ”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©Χ™ΧΧ•Χ© Χ‘-inferSchema Χ•-delimiter\n",
    "df4 = spark.read.options(inferSchema='True', delimiter=',') \\\n",
    "    .csv(\"../data/zipcodes.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΆΧ key-value pair:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ”Χ’Χ“Χ¨Χ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ§Χ¨Χ™ΧΧ”\n",
    "options = {\n",
    "    \"inferSchema\": \"True\",\n",
    "    \"delimiter\": \",\"\n",
    "}\n",
    "\n",
    "# Χ§Χ¨Χ™ΧΧ Χ§Χ•Χ‘Χ¥ CSV ΧΆΧ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΧ•Χ’Χ“Χ¨Χ•Χ\n",
    "df4 = spark.read.options(**options).csv(\"../data/zipcodes.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΧΧ—ΧΧ•Χ¤Χ™Χ, Χ Χ™ΧΧ Χ’Χ ΧΧ›ΧΧ•Χ‘ ΧΧ Χ–Χ” ΧΆΧ Χ™Χ“Χ™ Χ©Χ¨Χ©Χ•Χ¨ Χ©Χ™ΧΧ `option()`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©Χ¨Χ©Χ•Χ¨ ΧΧ΅Χ¤Χ¨ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ\n",
    "df4 = spark.read.option(\"inferSchema\", True) \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .csv(\"../data/zipcodes.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 header\n",
    "\n",
    "ΧΧ¤Χ©Χ¨Χ•Χ Χ–Χ• ΧΧ©ΧΧ©Χ ΧΧ§Χ¨Χ™ΧΧ Χ”Χ©Χ•Χ¨Χ” Χ”Χ¨ΧΧ©Χ•Χ Χ” Χ©Χ Χ§Χ•Χ‘Χ¥ Χ”-CSV Χ›Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ. Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ Χ”ΧΆΧ¨Χ Χ©Χ ΧΧ¤Χ©Χ¨Χ•Χ Χ–Χ• Χ”Χ•Χ `False`, Χ•Χ›Χ Χ΅Χ•Χ’Χ™ Χ”ΧΆΧΧ•Χ“Χ•Χ ΧΧ Χ™Χ—Χ™Χ Χ©Χ”Χ string."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ header\n",
    "df3 = spark.read.options(header='True', inferSchema='True', delimiter=',') \\\n",
    "    .csv(\"../data/zipcodes.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 quotes\n",
    "\n",
    "Χ›ΧΧ©Χ¨ Χ™Χ© ΧΧ ΧΆΧΧ•Χ“Χ” ΧΆΧ ΧΧ¤Χ¨Χ™Χ“ Χ©ΧΧ©ΧΧ© ΧΧ¤Χ™Χ¦Χ•Χ Χ”ΧΆΧΧ•Χ“Χ•Χ, Χ”Χ©ΧΧΧ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ `quotes` Χ›Χ“Χ™ ΧΧ¦Χ™Χ™Χ ΧΧ ΧΧ• Χ”ΧΧ¨Χ›ΧΧ•Χ, Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ Χ–Χ” `\"` Χ•Χ”ΧΧ¤Χ¨Χ™Χ“Χ™Χ Χ‘ΧΧ•Χ Χ”ΧΧ¨Χ›ΧΧ•Χ ΧΧΧΆΧΧΧ™Χ ΧΧ‘Χ Χ‘ΧΧΧ¦ΧΆΧ•Χ ΧΧ¤Χ©Χ¨Χ•Χ Χ–Χ• Χ Χ™ΧΧ ΧΧ”Χ’Χ“Χ™Χ¨ Χ›Χ ΧΧ•."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df4 = (spark.read.options(quote='\"')\n",
    "       .csv(\"../data/zipcodes.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 nullValues\n",
    "\n",
    "Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ `nullValues` Χ‘-PySpark Χ Χ™ΧΧ ΧΧ¦Χ™Χ™Χ ΧΧ—Χ¨Χ•Χ–Χ•Χ ΧΧ•ΧΧΧΧ•Χ ΧΧ™Χ©Χ™Χ Χ©Χ¦Χ¨Χ™Χ›Χ•Χ ΧΧ”Χ™Χ—Χ©Χ‘ Χ›ΧΆΧ¨Χ›Χ™ null Χ‘ΧΧ”ΧΧ ΧΧ”ΧΧ™Χ Χ§ΧΧ™ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ. ΧΧ“Χ•Χ’ΧΧ”, ΧΧ Χ‘Χ¨Χ¦Χ•Χ Χ ΧΧ©Χ§Χ•Χ Χ©Χ“Χ” ΧΆΧ ΧΆΧ¨Χ `\"N/A\"` Χ›-null Χ‘-DataFrame."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df4 = (spark.read.options(nullValues='N/A')\n",
    "       .csv(\"../data/zipcodes.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 dateFormat\n",
    "\n",
    "ΧΧ¤Χ©Χ¨Χ•Χ `dateFormat` ΧΧ©ΧΧ©Χ ΧΧ¦Χ™Χ•Χ ΧΧ Χ”Χ¤Χ•Χ¨ΧΧ Χ©Χ ΧΆΧΧ•Χ“Χ•Χ ΧΧΧ¨Χ™Χ ΧΧ• timestamp Χ‘Χ ΧΧ•Χ Χ™ Χ”Χ§ΧΧ. ΧΧ¤Χ©Χ¨Χ•Χ Χ–Χ• ΧΧΧ¤Χ©Χ¨Χ Χ-PySpark ΧΧ ΧΧ— Χ Χ›Χ•Χ ΧΧ—Χ¨Χ•Χ–Χ•Χ ΧΧΧ¨Χ™Χ ΧΧ• timestamp ΧΧ΅Χ•Χ’Χ™ Χ”Χ ΧΧ•Χ Χ™Χ Χ”ΧΧΧΧ™ΧΧ™Χ Χ©ΧΧ”Χ. ΧΧ•ΧΧ Χ‘Χ›Χ Χ”Χ¤Χ•Χ¨ΧΧΧ™Χ Χ©Χ java.text.SimpleDateFormat.\n",
    "\n",
    "**Χ”ΧΆΧ¨Χ”:** ΧΧΧ‘Χ“ Χ”ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΧΆΧ™Χ, PySpark CSV API ΧΧ•ΧΧ Χ’Χ Χ‘ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ¨Χ‘Χ•Χ ΧΧ—Χ¨Χ•Χ, ΧΧ Χ ΧΆΧ™Χ™Χ Χ‘Χ›ΧΧ‘Χ” Χ–Χ• ΧΧ¤Χ¨ΧΧ™Χ."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df4 = (spark.read.options(dateFormat='dd-MM-yyyy')\n",
    "       .csv(\"../data/zipcodes.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Χ¦Χ™Χ•Χ Χ΅Χ›Χ™ΧΧ” ΧΧ•ΧΧΧΧ ΧΧ™Χ©Χ™Χ\n",
    "\n",
    "Χ§Χ¨Χ™ΧΧ Χ§Χ‘Χ¦Χ™ CSV ΧΆΧ Χ΅Χ›Χ™ΧΧ” ΧΧ•ΧΧΧΧ ΧΧ™Χ©Χ™Χ Χ‘-PySpark Χ›Χ•ΧΧΧ Χ”Χ’Χ“Χ¨Χ” ΧΧ¤Χ•Χ¨Χ©Χ Χ©Χ Χ”Χ΅Χ›Χ™ΧΧ” ΧΧ¤Χ Χ™ ΧΧΆΧ™Χ Χ Χ”Χ ΧΧ•Χ Χ™Χ. Χ Χ™ΧΧ ΧΧ”Χ’Χ“Χ™Χ¨ ΧΧ Χ”Χ΅Χ›Χ™ΧΧ” ΧΆΧ‘Χ•Χ¨ Χ§Χ•Χ‘Χ¥ Χ”-CSV ΧΆΧ Χ™Χ“Χ™ Χ¦Χ™Χ•Χ Χ©ΧΧ•Χ Χ”ΧΆΧΧ•Χ“Χ•Χ Χ•Χ΅Χ•Χ’Χ™ Χ”Χ ΧΧ•Χ Χ™Χ Χ‘ΧΧΧ¦ΧΆΧ•Χ ΧΧ—ΧΧ§Χ•Χ StructType Χ•-StructField. ΧΧΧ• ΧΧ”ΧΧ•Χ“Χ•Χ `pyspark.sql.types`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ™Χ™Χ‘Χ•ΧΧ™Χ\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "\n",
    "# Χ©Χ™ΧΧ•Χ© Χ‘Χ΅Χ›Χ™ΧΧ” ΧΧ•ΧΧΧΧ\n",
    "schema = StructType() \\\n",
    "    .add(\"RecordNumber\", IntegerType(), True) \\\n",
    "    .add(\"Zipcode\", IntegerType(), True) \\\n",
    "    .add(\"ZipCodeType\", StringType(), True) \\\n",
    "    .add(\"City\", StringType(), True) \\\n",
    "    .add(\"State\", StringType(), True) \\\n",
    "    .add(\"LocationType\", StringType(), True) \\\n",
    "    .add(\"Lat\", DoubleType(), True) \\\n",
    "    .add(\"Long\", DoubleType(), True) \\\n",
    "    .add(\"Xaxis\", IntegerType(), True) \\\n",
    "    .add(\"Yaxis\", DoubleType(), True) \\\n",
    "    .add(\"Zaxis\", DoubleType(), True) \\\n",
    "    .add(\"WorldRegion\", StringType(), True) \\\n",
    "    .add(\"Country\", StringType(), True) \\\n",
    "    .add(\"LocationText\", StringType(), True) \\\n",
    "    .add(\"Location\", StringType(), True) \\\n",
    "    .add(\"Decommisioned\", BooleanType(), True) \\\n",
    "    .add(\"TaxReturnsFiled\", StringType(), True) \\\n",
    "    .add(\"EstimatedPopulation\", IntegerType(), True) \\\n",
    "    .add(\"TotalWages\", IntegerType(), True) \\\n",
    "    .add(\"Notes\", StringType(), True)\n",
    "\n",
    "df_with_schema = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"../data/zipcodes.csv\")\n",
    "df_with_schema.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χ©Χ™ΧΧ•Χ© Χ‘Χ΅Χ›Χ™ΧΧ” ΧΧ•ΧΧΧΧ ΧΧ™Χ©Χ™Χ ΧΧ΅Χ¤Χ§ Χ’ΧΧ™Χ©Χ•Χ Χ‘ΧΧ™Χ¤Χ•Χ Χ‘Χ§Χ‘Χ¦Χ™ CSV ΧΆΧ Χ΅Χ•Χ’Χ™ Χ ΧΧ•Χ Χ™Χ Χ΅Χ¤Χ¦Χ™Χ¤Χ™Χ™Χ ΧΧ• Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ, Χ•ΧΧ‘ΧΧ™Χ— Χ©Χ”-DataFrame ΧΧ™Χ™Χ¦Χ’ Χ‘ΧΧ“Χ•Χ™Χ§ ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ Χ‘Χ”ΧΧΧ ΧΧ“Χ¨Χ™Χ©Χ•Χ Χ”ΧΧ©ΧΧΧ©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ Χ©Χ DataFrame\n",
    "\n",
    "ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ Χ©Χ PySpark DataFrame Χ›Χ•ΧΧΧ•Χ Χ”Χ—ΧΧ Χ¤ΧΆΧ•ΧΧ•Χ Χ©Χ•Χ Χ•Χ ΧΧΧ¤ΧΆΧ•Χ Χ”Χ ΧΧ•Χ Χ™Χ Χ‘ΧΧ•Χ DataFrame. ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ ΧΧΧ• Χ›Χ•ΧΧΧ•Χ:\n",
    "\n",
    "1. **Χ Χ™Χ§Χ•Χ™ Χ ΧΧ•Χ Χ™Χ (Data Cleaning)**: Χ Χ™ΧΧ ΧΧ”Χ©ΧΧΧ© Χ‘ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ ΧΧ Χ™Χ§Χ•Χ™ Χ”Χ ΧΧ•Χ Χ™Χ ΧΆΧ Χ™Χ“Χ™ ΧΧ™Χ¤Χ•Χ Χ‘ΧΆΧ¨Χ›Χ™Χ Χ—Χ΅Χ¨Χ™Χ, Χ΅Χ™Χ Χ•Χ Χ©Χ•Χ¨Χ•Χ ΧΧ Χ¨ΧΧ•Χ•Χ ΧΧ™Χ•Χ ΧΧ• ΧΧ™Χ§Χ•Χ Χ—Χ•Χ΅Χ¨ ΧΆΧ§Χ‘Χ™Χ•Χ Χ‘Χ ΧΧ•Χ Χ™Χ.\n",
    "\n",
    "2. **Χ”ΧΆΧ©Χ¨Χ Χ ΧΧ•Χ Χ™Χ (Data Enrichment)**: Χ Χ™ΧΧ ΧΧ”ΧΆΧ©Χ™Χ¨ ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ ΧΆΧ Χ™Χ“Χ™ Χ”Χ•Χ΅Χ¤Χ ΧΆΧΧ•Χ“Χ•Χ Χ—Χ“Χ©Χ•Χ, Χ¦Χ‘Χ™Χ¨Χ ΧΧ™Χ“ΧΆ ΧΧ• Χ¦Χ™Χ¨Χ•Χ£ ΧΆΧ datasets ΧΧ—Χ¨Χ™Χ Χ›Χ“Χ™ ΧΧ΅Χ¤Χ§ Χ”Χ§Χ©Χ¨ ΧΧ• ΧΧ•Χ‘Χ Χ•Χ Χ Χ•Χ΅Χ¤Χ•Χ.\n",
    "\n",
    "3. **ΧΆΧ™Χ¦Χ•Χ‘ Χ ΧΧ•Χ Χ™Χ (Data Formatting)**: ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ ΧΧΧ¤Χ©Χ¨Χ•Χ ΧΧΆΧ¦Χ‘ ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ Χ‘Χ¦Χ•Χ¨Χ” Χ¨Χ¦Χ•Χ™Χ”, Χ›Χ’Χ•Χ Χ”ΧΧ¨Χ Χ΅Χ•Χ’Χ™ Χ ΧΧ•Χ Χ™Χ, Χ©Χ™Χ Χ•Χ™ Χ©Χ ΧΆΧΧ•Χ“Χ•Χ ΧΧ• Χ”Χ—ΧΧ Χ¤Χ•Χ¨ΧΧ ΧΧ•ΧΧΧ ΧΆΧ ΧΆΧ¨Χ›Χ™Χ.\n",
    "\n",
    "4. **Χ¦Χ‘Χ™Χ¨Χ Χ ΧΧ•Χ Χ™Χ (Data Aggregation)**: Χ¦Χ‘Χ™Χ¨Χ Χ”Χ ΧΧ•Χ Χ™Χ ΧΧΧ¤Χ©Χ¨Χ ΧΧ΅Χ›Χ ΧΧ™Χ“ΧΆ, ΧΧ—Χ©Χ‘ Χ΅ΧΧΧ™Χ΅ΧΧ™Χ§Χ•Χ ΧΧ• ΧΧ§Χ‘Χ¥ Χ ΧΧ•Χ Χ™Χ ΧΆΧ Χ‘Χ΅Χ™Χ΅ Χ§Χ¨Χ™ΧΧ¨Χ™Χ•Χ Χ™Χ Χ΅Χ¤Χ¦Χ™Χ¤Χ™Χ™Χ.\n",
    "\n",
    "5. **Χ”Χ Χ“Χ΅Χ Χ¤Χ™Χ¦'Χ¨Χ™Χ (Feature Engineering)**: ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ ΧΧ©ΧΧ©Χ•Χ ΧΧΆΧΧ™Χ Χ§Χ¨Χ•Χ‘Χ•Χ Χ‘Χ”Χ Χ“Χ΅Χ Χ¤Χ™Χ¦'Χ¨Χ™Χ ΧΧ™Χ¦Χ™Χ¨Χ Χ¤Χ™Χ¦'Χ¨Χ™Χ Χ—Χ“Χ©Χ™Χ ΧΧ• Χ©Χ™Χ Χ•Χ™ Χ§Χ™Χ™ΧΧ™Χ ΧΧ©Χ™Χ¤Χ•Χ¨ Χ‘Χ™Χ¦Χ•ΧΆΧ™ Χ”ΧΧ•Χ“Χ Χ‘ΧΧ©Χ™ΧΧ•Χ machine learning.\n",
    "\n",
    "6. **Χ—Χ§Χ¨ Χ ΧΧ•Χ Χ™Χ (Data Exploration)**: ΧΧ¨Χ Χ΅Χ¤Χ•Χ¨ΧΧ¦Χ™Χ•Χ ΧΧΧ¤Χ©Χ¨Χ•Χ Χ Χ™ΧΧ•Χ— Χ—Χ§Χ¨Χ Χ™ Χ©Χ Χ ΧΧ•Χ Χ™Χ ΧΆΧ Χ™Χ“Χ™ ΧΆΧ™Χ¦Χ•Χ‘ ΧΧ—Χ“Χ© Χ©Χ Χ”Χ ΧΧ•Χ Χ™Χ, Χ—Χ™ΧΧ•Χ¥ ΧΧ-Χ§Χ‘Χ•Χ¦Χ•Χ Χ©Χ ΧΆΧ Χ™Χ™Χ ΧΧ• Χ•Χ™Χ–Χ•ΧΧΧ™Χ–Χ¦Χ™Χ” Χ©Χ ΧΧ‘Χ Χ™Χ•Χ Χ›Χ“Χ™ ΧΧ”Χ©Χ™Χ’ ΧΧ•Χ‘Χ Χ•Χ ΧΧ’Χ‘Χ™ Χ”dataset.\n",
    "\n",
    "ΧΆΧ™Χ™Χ Χ‘-PySpark Transformations ΧΧ“Χ•Χ’ΧΧΧ•Χ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Χ›ΧΧ™Χ‘Χ PySpark DataFrame ΧΧ§Χ•Χ‘Χ¥ CSV\n",
    "\n",
    "Χ›Χ“Χ™ ΧΧ›ΧΧ•Χ‘ PySpark DataFrame ΧΧ§Χ•Χ‘Χ¥ CSV, Χ Χ™ΧΧ ΧΧ”Χ©ΧΧΧ© Χ‘Χ©Χ™ΧΧ `write.csv()` Χ”ΧΧ΅Χ•Χ¤Χ§Χ ΧΆΧ Χ™Χ“Χ™ DataFrame API. Χ©Χ™ΧΧ” Χ–Χ• ΧΧ•Χ§Χ—Χ Χ ΧΧ™Χ‘ Χ›ΧΧ¨Χ’Χ•ΧΧ Χ, Χ›ΧΧ©Χ¨ Χ§Χ•Χ‘Χ¥ Χ”-CSV Χ™Χ™Χ©ΧΧ¨.\n",
    "\n",
    "Χ‘ΧΧ•Χ¤Χ ΧΧ•Χ¤Χ¦Χ™Χ•Χ ΧΧ™, Χ Χ™ΧΧ ΧΧ¦Χ™Χ™Χ Χ¤Χ¨ΧΧΧ¨Χ™Χ Χ Χ•Χ΅Χ¤Χ™Χ Χ›Χ’Χ•Χ Χ”ΧΧ¤Χ¨Χ™Χ“, Χ”Χ›ΧΧΧ header Χ•ΧΧ ΧΧ“Χ¨Χ•Χ΅ Χ§Χ‘Χ¦Χ™Χ Χ§Χ™Χ™ΧΧ™Χ. Χ›Χ Χ Χ™ΧΧ ΧΧΆΧ©Χ•Χ Χ–ΧΧ:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©ΧΧ™Χ¨Χ DataFrame ΧΧ§Χ•Χ‘Χ¥ CSV\n",
    "df.write.option(\"header\", True) \\\n",
    "    .csv(\"tmp/01_csv/zipcodes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`option(\"header\", True)`: Χ–Χ” ΧΧ¦Χ™Χ™Χ ΧΧ¤Χ©Χ¨Χ•Χ ΧΧ¤ΧΆΧ•ΧΧ Χ”Χ›ΧΧ™Χ‘Χ”. Χ‘ΧΧ§Χ¨Χ” Χ–Χ”, Χ–Χ” ΧΧ’Χ“Χ™Χ¨ ΧΧ ΧΧ¤Χ©Χ¨Χ•Χ Χ”-header Χ-True, ΧΧ” Χ©ΧΧ¦Χ‘Χ™ΧΆ ΧΆΧ Χ›Χ Χ©Χ§Χ•Χ‘Χ¥ Χ”-CSV Χ¦Χ¨Χ™Χ ΧΧ›ΧΧ•Χ Χ©Χ•Χ¨Χ header ΧΆΧ Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ\n",
    "\n",
    "Χ›ΧΧ©Χ¨ Χ›Χ•ΧΧ‘Χ™Χ DataFrame ΧΧ§Χ‘Χ¦Χ™ CSV Χ‘-PySpark, Χ Χ™ΧΧ ΧΧ¦Χ™Χ™Χ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ©Χ•Χ Χ•Χ Χ›Χ“Χ™ ΧΧ”ΧΧΧ™Χ ΧΧ™Χ©Χ™Χ ΧΧ Χ”Χ¤ΧΧ. ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ ΧΧΧ• Χ Χ™ΧΧ ΧΧ”Χ’Χ“Χ™Χ¨ Χ‘ΧΧΧ¦ΧΆΧ•Χ Χ©Χ™ΧΧ `option()` Χ©Χ ΧΧ—ΧΧ§Χ DataFrameWriter. Χ”Χ Χ” Χ›Χ™Χ¦Χ“ ΧΧ”Χ©ΧΧΧ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ›ΧΧ™Χ‘Χ” ΧΆΧ Χ§Χ•Χ‘Χ¥ CSV:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ©Χ™ΧΧ•Χ© Χ‘ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ›ΧΧ™Χ‘Χ”\n",
    "df2.write.options(header='True', delimiter=',') \\\n",
    "    .csv(\"tmp/01_csv/zipcodes2\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΧΧ”ΧΧ Χ›ΧΧ” ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ Χ¤Χ•Χ¦Χ•Χ:\n",
    "\n",
    "1. **header**: ΧΧ¦Χ™Χ™Χ ΧΧ ΧΧ›ΧΧ•Χ Χ©Χ•Χ¨Χ header ΧΆΧ Χ©ΧΧ•Χ ΧΆΧΧ•Χ“Χ•Χ Χ‘Χ§Χ•Χ‘Χ¥ Χ”-CSV. Χ“Χ•Χ’ΧΧ”: `option(\"header\", \"true\")`.\n",
    "\n",
    "2. **delimiter**: ΧΧ¦Χ™Χ™Χ ΧΧ Χ”ΧΧ¤Χ¨Χ™Χ“ ΧΧ©Χ™ΧΧ•Χ© Χ‘Χ™Χ Χ”Χ©Χ“Χ•Χ Χ‘Χ§Χ•Χ‘Χ¥ Χ”-CSV. Χ“Χ•Χ’ΧΧ”: `option(\"delimiter\", \",\")`.\n",
    "\n",
    "3. **quote**: ΧΧ¦Χ™Χ™Χ ΧΧ ΧΧ• Χ”ΧΧ¨Χ›ΧΧ•Χ ΧΧ©Χ™ΧΧ•Χ© ΧΆΧ‘Χ•Χ¨ Χ©Χ“Χ•Χ Χ‘Χ§Χ•Χ‘Χ¥ Χ”-CSV. Χ“Χ•Χ’ΧΧ”: `option(\"quote\", \"\\\"\")`.\n",
    "\n",
    "4. **escape**: ΧΧ¦Χ™Χ™Χ ΧΧ ΧΧ• Χ”-escape ΧΧ©Χ™ΧΧ•Χ© Χ‘Χ§Χ•Χ‘Χ¥ Χ”-CSV. Χ“Χ•Χ’ΧΧ”: `option(\"escape\", \"\\\\\\\\\")` (Χ©Χ™ΧΧ• ΧΧ‘ ΧΧΧ• Χ”-backslash Χ”Χ›Χ¤Χ•Χ).\n",
    "\n",
    "5. **nullValue**: ΧΧ¦Χ™Χ™Χ ΧΧ Χ”ΧΧ—Χ¨Χ•Χ–Χ ΧΧ™Χ™Χ¦Χ•Χ’ ΧΆΧ¨Χ›Χ™ null Χ‘Χ§Χ•Χ‘Χ¥ Χ”-CSV. Χ“Χ•Χ’ΧΧ”: `option(\"nullValue\", \"NA\")`.\n",
    "\n",
    "6. **dateFormat**: ΧΧ¦Χ™Χ™Χ ΧΧ Χ”Χ¤Χ•Χ¨ΧΧ ΧΧ©Χ™ΧΧ•Χ© ΧΧΆΧΧ•Χ“Χ•Χ ΧΧΧ¨Χ™Χ. Χ“Χ•Χ’ΧΧ”: `option(\"dateFormat\", \"yyyy-MM-dd\")`.\n",
    "\n",
    "7. **mode**: ΧΧ¦Χ™Χ™Χ ΧΧ ΧΧ¦Χ‘ Χ”Χ›ΧΧ™Χ‘Χ” ΧΆΧ‘Χ•Χ¨ Χ”Χ¤ΧΧ. ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ›Χ•ΧΧΧ•Χ \"overwrite\", \"append\", \"ignore\" Χ•-\"error\". Χ“Χ•Χ’ΧΧ”: `option(\"mode\", \"overwrite\")`.\n",
    "\n",
    "8. **compression**: ΧΧ¦Χ™Χ™Χ ΧΧ Χ§Χ•Χ“Χ§ Χ”Χ“Χ—Χ™Χ΅Χ” ΧΧ©Χ™ΧΧ•Χ© ΧΆΧ‘Χ•Χ¨ Χ§Χ•Χ‘Χ¥ Χ”Χ¤ΧΧ. Χ“Χ•Χ’ΧΧ”: `option(\"compression\", \"gzip\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ΧΧ¦Χ‘Χ™ Χ©ΧΧ™Χ¨Χ” (Saving modes)\n",
    "\n",
    "Χ‘-PySpark, Χ›ΧΧ©Χ¨ Χ©Χ•ΧΧ¨Χ™Χ DataFrames ΧΧΧ—Χ΅Χ•Χ Χ—Χ™Χ¦Χ•Χ Χ™ Χ›ΧΧ• ΧΧΆΧ¨Χ›Χ•Χ Χ§Χ‘Χ¦Χ™Χ ΧΧ• ΧΧ΅Χ“Χ™ Χ ΧΧ•Χ Χ™Χ, Χ Χ™ΧΧ ΧΧ¦Χ™Χ™Χ ΧΧ¦Χ‘Χ™ Χ©ΧΧ™Χ¨Χ” Χ©Χ•Χ Χ™Χ Χ›Χ“Χ™ ΧΧ©ΧΧ•Χ Χ‘Χ”ΧΧ Χ”Χ’Χ•Χ Χ‘ΧΧ§Χ¨Χ” Χ©ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ Χ›Χ‘Χ¨ Χ§Χ™Χ™Χ. ΧΧ¦Χ‘Χ™ Χ”Χ©ΧΧ™Χ¨Χ” Χ›Χ•ΧΧΧ™Χ:\n",
    "\n",
    "1. **Append**: ΧΧ•Χ΅Χ™Χ£ ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ ΧΧ ΧΧ•Χ Χ™Χ Χ”Χ§Χ™Χ™ΧΧ™Χ Χ‘ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“. ΧΧ ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ ΧΧ Χ§Χ™Χ™Χ, Χ”Χ•Χ Χ™Χ•Χ¦Χ¨ Χ—Χ“Χ©.\n",
    "\n",
    "2. **Overwrite**: Χ“Χ•Χ¨Χ΅ ΧΧ Χ”Χ ΧΧ•Χ Χ™Χ Χ‘ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ ΧΧ Χ”Χ•Χ Χ›Χ‘Χ¨ Χ§Χ™Χ™Χ. ΧΧ ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ ΧΧ Χ§Χ™Χ™Χ, Χ”Χ•Χ Χ™Χ•Χ¦Χ¨ Χ—Χ“Χ©.\n",
    "\n",
    "3. **Ignore**: ΧΧΧΆΧΧ ΧΧ”Χ¤ΧΆΧ•ΧΧ” Χ•ΧΧ ΧΆΧ•Χ©Χ” Χ›ΧΧ•Χ ΧΧ ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ Χ›Χ‘Χ¨ Χ§Χ™Χ™Χ. ΧΧ ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ ΧΧ Χ§Χ™Χ™Χ, Χ”Χ•Χ Χ™Χ•Χ¦Χ¨ Χ—Χ“Χ©.\n",
    "\n",
    "4. **Error ΧΧ• ErrorIfExists**: Χ–Χ•Χ¨Χ§ Χ©Χ’Χ™ΧΧ” Χ•Χ Χ›Χ©Χ Χ‘Χ¤ΧΆΧ•ΧΧ” ΧΧ ΧΧ™Χ§Χ•Χ Χ”Χ™ΧΆΧ“ Χ›Χ‘Χ¨ Χ§Χ™Χ™Χ. Χ–Χ• Χ”Χ”ΧΧ Χ”Χ’Χ•Χ Χ›Χ‘Χ¨Χ™Χ¨Χ ΧΧ—Χ“Χ ΧΧ ΧΧ Χ¦Χ•Χ™Χ ΧΧ¦Χ‘ Χ©ΧΧ™Χ¨Χ”.\n",
    "\n",
    "ΧΧ¦Χ‘Χ™ Χ©ΧΧ™Χ¨Χ” ΧΧΧ• ΧΧ΅Χ¤Χ§Χ™Χ Χ’ΧΧ™Χ©Χ•Χ Χ•Χ©ΧΧ™ΧΧ” ΧΆΧ Χ”ΧΧ•Χ¤Χ Χ©Χ‘Χ• Χ”Χ ΧΧ•Χ Χ™Χ Χ Χ©ΧΧ¨Χ™Χ Χ•ΧΧΧ•Χ¤ΧΧ™Χ Χ‘ΧΧ¨Χ—Χ™Χ©Χ™Χ Χ©Χ•Χ Χ™Χ, Χ•ΧΧ‘ΧΧ™Χ—Χ™Χ Χ©ΧΧΧ•Χ Χ ΧΧ•Χ Χ™Χ Χ•ΧΆΧ§Χ‘Χ™Χ•Χ Χ‘Χ–Χ¨ΧΧ™ ΧΆΧ‘Χ•Χ“Χ” Χ©Χ ΧΆΧ™Χ‘Χ•Χ“ Χ ΧΧ•Χ Χ™Χ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Χ“Χ•Χ’ΧΧ” ΧΆΧ saveMode\n",
    "df2.write.mode(\"overwrite\").csv(\"tmp/01_csv/zipcodes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. π“ Χ“Χ•Χ’ΧΧ” ΧΧΧΧ” Χ©Χ PySpark Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import col, array_contains\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"../data/zipcodes.csv\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df2 = spark.read.option(\"header\", True) \\\n",
    "    .csv(\"../data/zipcodes.csv\")\n",
    "df2.printSchema()\n",
    "\n",
    "df3 = spark.read.options(header='True', delimiter=',') \\\n",
    "    .csv(\"../data/zipcodes.csv\")\n",
    "df3.printSchema()\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"RecordNumber\", IntegerType(), True) \\\n",
    "    .add(\"Zipcode\", IntegerType(), True) \\\n",
    "    .add(\"ZipCodeType\", StringType(), True) \\\n",
    "    .add(\"City\", StringType(), True) \\\n",
    "    .add(\"State\", StringType(), True) \\\n",
    "    .add(\"LocationType\", StringType(), True) \\\n",
    "    .add(\"Lat\", DoubleType(), True) \\\n",
    "    .add(\"Long\", DoubleType(), True) \\\n",
    "    .add(\"Xaxis\", IntegerType(), True) \\\n",
    "    .add(\"Yaxis\", DoubleType(), True) \\\n",
    "    .add(\"Zaxis\", DoubleType(), True) \\\n",
    "    .add(\"WorldRegion\", StringType(), True) \\\n",
    "    .add(\"Country\", StringType(), True) \\\n",
    "    .add(\"LocationText\", StringType(), True) \\\n",
    "    .add(\"Location\", StringType(), True) \\\n",
    "    .add(\"Decommisioned\", BooleanType(), True) \\\n",
    "    .add(\"TaxReturnsFiled\", StringType(), True) \\\n",
    "    .add(\"EstimatedPopulation\", IntegerType(), True) \\\n",
    "    .add(\"TotalWages\", IntegerType(), True) \\\n",
    "    .add(\"Notes\", StringType(), True)\n",
    "\n",
    "df_with_schema = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"../data/zipcodes.csv\")\n",
    "df_with_schema.printSchema()\n",
    "\n",
    "df2.write.option(\"header\", True) \\\n",
    "    .csv(\"tmp/01_csv/zipcodes3\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. π“ Χ΅Χ™Χ›Χ•Χ:\n",
    "\n",
    "ΧΧ΅Χ™Χ›Χ•Χ, Χ§Χ¨Χ™ΧΧ Χ§Χ‘Χ¦Χ™ CSV ΧΧ”Χ“Χ™Χ΅Χ§ Χ‘ΧΧΧ¦ΧΆΧ•Χ PySpark ΧΧ¦Χ™ΧΆΧ” Χ’Χ™Χ©Χ” Χ¨Χ‘-ΧΧ›ΧΧ™ΧΧ™Χ Χ•Χ™ΧΆΧ™ΧΧ” ΧΧ§ΧΧ™ΧΧ” Χ•ΧΆΧ™Χ‘Χ•Χ“ Χ ΧΧ•Χ Χ™Χ. Χ‘ΧΧΧΧ¨ Χ–Χ”, ΧΧΧ“Χ ΧΧ Χ”Χ—Χ©Χ™Χ‘Χ•Χ Χ©Χ Χ¦Χ™Χ•Χ ΧΧ¤Χ©Χ¨Χ•Χ™Χ•Χ Χ›Χ’Χ•Χ Χ΅Χ›Χ™ΧΧ”, ΧΧ¤Χ¨Χ™Χ“ Χ•ΧΧ™Χ¤Χ•Χ Χ‘header Χ›Χ“Χ™ ΧΧ”Χ‘ΧΧ™Χ— Χ™Χ¦Χ™Χ¨Χ DataFrame ΧΧ“Χ•Χ™Χ§Χ. Χ‘Χ Χ•Χ΅Χ£, ΧΧΧ“Χ ΧΧ§Χ¨Χ•Χ Χ§Χ•Χ‘Χ¥ CSV ΧΧ΅Χ¤Χ¨ Χ§Χ‘Χ¦Χ™ csv, Χ›Χ Χ”Χ§Χ‘Χ¦Χ™Χ ΧΧΧ™Χ§Χ™Χ™Χ” e.t.c\n",
    "\n",
    "### π’΅ ΧΧΧ™Χ“Χ” ΧΧ”Χ Χ”!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π“ ΧΧΧΧ¨Χ™Χ Χ§Χ©Χ•Χ¨Χ™Χ\n",
    "\n",
    "- [Dynamic way of doing ETL through Pyspark](https://sparkbyexamples.com)\n",
    "- [PySpark cache() Explained](https://sparkbyexamples.com)\n",
    "- [PySpark Write to CSV File](https://sparkbyexamples.com)\n",
    "- [PySpark repartition() β€“ Explained with Examples](https://sparkbyexamples.com)\n",
    "- [PySpark Create RDD with Examples](https://sparkbyexamples.com)\n",
    "- [PySpark printSchema() to String or JSON](https://sparkbyexamples.com)\n",
    "- [PySpark SparkContext Explained](https://sparkbyexamples.com)\n",
    "- [PySpark createOrReplaceTempView() Explained](https://sparkbyexamples.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π”— ΧΧ§Χ•Χ¨Χ•Χ:\n",
    "\n",
    "- [Databricks read CSV](https://docs.databricks.com/)\n",
    "- [PySpark CSV library](https://spark.apache.org/docs/latest/api/python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
