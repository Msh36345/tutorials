{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "#  驻拽爪转 JSON -PySpark - 专 拽祝\n",
    "[PySpark JSON Functions with Examples](https://sparkbyexamples.com/pyspark/pyspark-json-functions-with-examples/)\n",
    "## \n",
    "\n",
    "-PySpark, 驻拽爪转 JSON 驻砖专转 注 注 转 JSON 转 DataFrames. 驻拽爪转  注专转  转 (parse), 转驻注 抓 转 注转  专转 JSON. 转 砖转砖 驻拽爪转   专转 JSON  Struct, 住 Map 注.\n",
    "\n",
    "专  住拽专 转 驻拽爪转 驻爪转 转专 注 注 JSON 注 转 -Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  驻拽爪转 JSON -PySpark\n",
    "\n",
    "| 驻拽爪 | 转专 |\n",
    "|---------|-------|\n",
    "| **from_json()** | 专 专转 JSON  Struct  Map |\n",
    "| **to_json()** | 专 注转 住 MapType  Struct 专转 JSON |\n",
    "| **json_tuple()** | 爪转  注转 JSON 爪专转 注转 砖转 |\n",
    "| **get_json_object()** | 爪转 专转 JSON 注 住住 转 注转 JSON |\n",
    "| **schema_of_json()** | 爪专转 专转 住 专转 JSON |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  专转 住\n",
    "\n",
    "专砖转,  转 住驻专转 专砖转 爪专 SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "# 爪专转 SparkSession\n",
    "spark = SparkSession.builder.appName('PySpark-JSON-Functions').getOrCreate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  爪专转 DataFrame 注 注  专转 JSON\n",
    "\n",
    "  转 驻拽爪转 JSON, 爪专 DataFrame 注 注  专转 JSON:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 专转 专转 JSON\n",
    "jsonString = '{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}'\n",
    "\n",
    "# 爪专转 DataFrame\n",
    "df = spark.createDataFrame(data = [(1, jsonString)], schema = [\"id\", \"value\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 爪转 DataFrame\n",
    "df.show(truncate=False)\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#  驻拽爪转 JSON - 转 注砖转\n",
    "\n",
    "注转 注专 注  转 驻拽爪转 JSON 注 转."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1锔 from_json() - 专转 专转 JSON -Map  Struct\n",
    "\n",
    "驻拽爪 `from_json()` 砖砖转 专转 专转 JSON  Struct  Map.\n",
    "\n",
    "  专 专转 JSON  驻转-注专 住 Map:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 专转 注转 专转 JSON 住 Map\n",
    "from pyspark.sql.types import MapType, StringType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "df2 = df.withColumn(\"value\", from_json(df.value, MapType(StringType(), StringType())))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 爪转 住\n",
    "df2.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 爪转 转\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2锔 to_json() - 专转 Map  Struct 专转 JSON\n",
    "\n",
    "驻拽爪 `to_json()` 砖砖转 专转 注转 DataFrame 住 MapType  Struct 专转 JSON.\n",
    "\n",
    " 砖转砖 -df2 砖爪专  拽转:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import to_json, col\n",
    "\n",
    "# 专 专 专转 JSON\n",
    "df2.withColumn(\"value\", to_json(col(\"value\"))).show(truncate=False)\n",
    "df2.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3锔 json_tuple() - 抓  注转 JSON\n",
    "\n",
    "驻拽爪 `json_tuple()` 砖砖转 砖转  抓  注转 JSON 爪专转 转爪 注转 砖转:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import json_tuple\n",
    "\n",
    "# 抓 砖转 住驻爪驻 -JSON\n",
    "df.select(\n",
    "    col(\"id\"),\n",
    "    json_tuple(col(\"value\"), \"Zipcode\", \"ZipCodeType\", \"City\")\n",
    ").toDF(\"id\", \"Zipcode\", \"ZipCodeType\", \"City\").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4锔 get_json_object() - 抓 注专 注 住住 转 JSON\n",
    "\n",
    "驻拽爪 `get_json_object()` 砖砖转 抓 专转 JSON 注 住住 转 (path) 注转 JSON.\n",
    "\n",
    "驻拽爪 砖转砖转 转专 JSONPath ( `$.key`):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import get_json_object\n",
    "\n",
    "# 抓 注专 住驻爪驻 爪注转 转 JSON\n",
    "df.select(\n",
    "    col(\"id\"),\n",
    "    get_json_object(col(\"value\"), \"$.ZipCodeType\").alias(\"ZipCodeType\")\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5锔 schema_of_json() - 爪专转 专转 住\n",
    "\n",
    "驻拽爪 `schema_of_json()` 砖砖转 爪专转 专转 住 专转 JSON.\n",
    "\n",
    " 砖砖 砖专 转 专爪 转 转  砖 转 JSON 驻 :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import schema_of_json, lit\n",
    "\n",
    "# 爪专转 专转 住 -JSON\n",
    "schemaStr = spark.range(1) \\\n",
    "    .select(schema_of_json(lit(\n",
    "        '{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}'\n",
    "    ))) \\\n",
    "    .collect()[0][0]\n",
    "\n",
    "print(schemaStr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  住\n",
    "\n",
    "专   注 驻拽爪转 砖转 注 注 JSON -PySpark:\n",
    "\n",
    "###  驻拽爪转 专转:\n",
    "\n",
    "1. **from_json()** - 专 专转 JSON  Struct  Map, 驻砖专转 砖 转 转 JSON\n",
    "\n",
    "2. **to_json()** - 专 注转 MapType  Struct 专 专转 JSON, 砖砖 爪 转\n",
    "\n",
    "3. **json_tuple()** - 爪转 住驻专 砖转 -转 -JSON 爪专转 注转 砖转, 注 转专 抓 砖转 \n",
    "\n",
    "4. **get_json_object()** - 爪转 注专  -JSON 爪注转 转 JSONPath, 砖 砖 砖转 拽\n",
    "\n",
    "5. **schema_of_json()** -  转 转 住 砖 转 JSON, 住  专转 住转 转\n",
    "\n",
    "###  驻 砖:\n",
    "\n",
    "- 砖转砖 -`from_json()` 砖专 转 爪专 注 注 转 JSON \n",
    "- `json_tuple()` 注 转专 -`get_json_object()` 砖专 爪 住驻专 砖转\n",
    "- 砖转砖 -`schema_of_json()`  转 转  砖 转 JSON  专\n",
    "- 驻拽爪转 JSON 驻转 转 拽  专\n",
    "\n",
    "###  砖砖 驻爪:\n",
    "\n",
    "- 拽专转 拽爪 JSON\n",
    "- 注  驻专 JSON\n",
    "- 注 注 APIs 砖专 JSON\n",
    "- 专住驻专爪 砖 转  驻专 砖\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  拽砖专 拽专转 住驻\n",
    "\n",
    "### 专 拽砖专:\n",
    "- [PySpark Parse JSON from String Column | TEXT File](https://sparkbyexamples.com/pyspark/pyspark-parse-json-from-string-column-text-file/)\n",
    "- [PySpark Read JSON file into DataFrame](https://sparkbyexamples.com/pyspark/pyspark-read-json-file-into-dataframe/)\n",
    "- [PySpark Read Multiple Lines (multiline) JSON File](https://sparkbyexamples.com/pyspark/pyspark-read-multiple-line-json-file/)\n",
    "- [PySpark String Functions with Examples](https://sparkbyexamples.com/pyspark/pyspark-string-functions-with-examples/)\n",
    "- [PySpark SQL Date and Timestamp Functions](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/)\n",
    "- [PySpark Aggregate Functions with Examples](https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/)\n",
    "\n",
    "### 拽专 专:\n",
    "- [PySpark JSON Functions with Examples - Spark By Examples](https://sparkbyexamples.com/pyspark/pyspark-json-functions-with-examples/)\n",
    "\n",
    "---\n",
    "\n",
    "##   !\n",
    "\n",
    "**Happy Learning!** \n",
    "\n",
    "*专  转专 注专 注专转 转 [SparkByExamples.com](https://sparkbyexamples.com)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
