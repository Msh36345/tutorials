{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸ“… ×¤×•× ×§×¦×™×•×ª Date ×•-Timestamp ×‘-PySpark - ××“×¨×™×š ××§×™×£\n",
    "[PySpark SQL Date and Timestamp Functions](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/)\n",
    "## ××‘×•×\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª Date ×•-Timestamp ×‘-PySpark × ×ª××›×•×ª ×‘-DataFrame ×•×‘×©××™×œ×ª×•×ª SQL ×•×”×Ÿ ×¢×•×‘×“×•×ª ×‘××•×¤×Ÿ ×“×•××” ×œ-SQL ××¡×•×¨×ª×™. ×ª××¨×™×š ×•×–××Ÿ ×”× ×—×©×•×‘×™× ×××•×“ ×× ××ª×” ××©×ª××© ×‘-PySpark ×¢×‘×•×¨ ETL.\n",
    "\n",
    "×¨×•×‘ ×”×¤×•× ×§×¦×™×•×ª ×”×œ×œ×• ××§×‘×œ×•×ª ×§×œ×˜ ×›×¡×•×’ Date, ×¡×•×’ Timestamp ××• String. ×× ××©×ª××©×™× ×‘××—×¨×•×–×ª, ×”×™× ×¦×¨×™×›×” ×œ×”×™×•×ª ×‘×¤×•×¨××˜ ×‘×¨×™×¨×ª ××—×“×œ ×©× ×™×ª×Ÿ ×œ×”××™×¨ ×œ-date.\n",
    "\n",
    "### ğŸ“Œ ×¤×•×¨××˜×™× ×©×œ ×‘×¨×™×¨×ª ××—×“×œ:\n",
    "- **DateType**: `yyyy-MM-dd`\n",
    "- **TimestampType**: `yyyy-MM-dd HH:mm:ss.SSSS`\n",
    "\n",
    "**×—×©×•×‘:** ×× ×”×§×œ×˜ ×”×•× ××—×¨×•×–×ª ×©×œ× × ×™×ª×Ÿ ×œ×”××™×¨ ×œ-Date ××• Timestamp, ×”×¤×•× ×§×¦×™×” ×ª×—×–×™×¨ `null`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ×”×’×“×¨×ª ×”×¡×‘×™×‘×”\n",
    "\n",
    "×¨××©×™×ª, × ×™×™×‘× ××ª ×”×¡×¤×¨×™×•×ª ×”× ×“×¨×•×©×•×ª ×•× ×™×¦×•×¨ SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('PySpark-Date-Timestamp-Functions') \\\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×™×¦×™×¨×ª DataFrame ×œ×“×•×’××”\n",
    "\n",
    "× ×™×¦×•×¨ DataFrame ×¤×©×•×˜ ×¢× ×¢××•×“×ª ×ª××¨×™×›×™×:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª × ×ª×•× ×™× ×œ×“×•×’××”\n",
    "data = [[\"1\", \"2020-02-01\"], [\"2\", \"2019-03-01\"], [\"3\", \"2021-03-01\"]]\n",
    "df = spark.createDataFrame(data, [\"id\", \"input\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª ×”× ×ª×•× ×™×\n",
    "df.show()\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“… ×¤×•× ×§×¦×™×•×ª Date (×ª××¨×™×š)\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××œ×• ×¤×•×¢×œ×•×ª ×¢×œ ×ª××¨×™×›×™× ×‘×œ×‘×“."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ current_date() - ×”×ª××¨×™×š ×”× ×•×›×—×™\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ××ª ×”×ª××¨×™×š ×”× ×•×›×—×™ ×©×œ ×”××¢×¨×›×ª. ×›×‘×¨×™×¨×ª ××—×“×œ, ×”×ª××¨×™×š ×™×•×—×–×¨ ×‘×¤×•×¨××˜ `yyyy-MM-dd`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# current_date()\n",
    "df.select(current_date().alias(\"current_date\")).show(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ date_format() - ×¢×™×¦×•×‘ ×ª××¨×™×š\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×× ×ª×—×ª ×ª××¨×™×š ×•×××™×¨×” ××•×ª×• ××¤×•×¨××˜ ××—×“ ×œ××—×¨.\n",
    "\n",
    "×‘×“×•×’××” ×”×‘××” × ××™×¨ ×-`yyyy-MM-dd` ×œ-`MM-dd-yyyy`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# date_format()\n",
    "df.select(\n",
    "    col(\"input\"),\n",
    "    date_format(col(\"input\"), \"MM-dd-yyyy\").alias(\"date_format\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ to_date() - ×”××¨×” ×œ×¡×•×’ DateType\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×××™×¨×” ××—×¨×•×–×ª ×‘×¤×•×¨××˜ ×ª××¨×™×š ×œ×¡×•×’ DateType.\n",
    "\n",
    "PySpark ×ª×•××š ×‘×›×œ ×”×¤×•×¨××˜×™× ×”× ×ª××›×™× ×‘-Java DateTimeFormatter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# to_date()\n",
    "df.select(\n",
    "    col(\"input\"),\n",
    "    to_date(col(\"input\"), \"yyyy-MM-dd\").alias(\"to_date\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ datediff() - ×”×¤×¨×© ×‘×™×Ÿ ×ª××¨×™×›×™×\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ××ª ×”×”×¤×¨×© ×‘×™××™× ×‘×™×Ÿ ×©× ×™ ×ª××¨×™×›×™×:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# datediff()\n",
    "df.select(\n",
    "    col(\"input\"),\n",
    "    datediff(current_date(), col(\"input\")).alias(\"datediff\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ months_between() - ×”×¤×¨×© ×‘×—×•×“×©×™×\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ××ª ××¡×¤×¨ ×”×—×•×“×©×™× ×‘×™×Ÿ ×©× ×™ ×ª××¨×™×›×™×:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# months_between()\n",
    "df.select(\n",
    "    col(\"input\"),\n",
    "    months_between(current_date(), col(\"input\")).alias(\"months_between\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ trunc() - ×§×™×¦×•×¥ ×ª××¨×™×š\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××§×¦×¦×ª ×ª××¨×™×š ×œ×™×—×™×“×” ××¡×•×™××ª (×—×•×“×©, ×©× ×” ×•×›×•'):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# trunc()\n",
    "df.select(\n",
    "    col(\"input\"),\n",
    "    trunc(col(\"input\"), \"Month\").alias(\"Month_Trunc\"),\n",
    "    trunc(col(\"input\"), \"Year\").alias(\"Year_Trunc\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ add_months(), date_add(), date_sub() - ×”×•×¡×¤×” ×•×”×¤×—×ª×”\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××œ×• ××•×¡×™×¤×•×ª ××• ××¤×—×™×ª×•×ª ×—×•×“×©×™× ×•×™××™× ××ª××¨×™×š × ×ª×•×Ÿ:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# add_months(), date_add(), date_sub()\n",
    "df.select(\n",
    "    col(\"input\"),\n",
    "    add_months(col(\"input\"), 3).alias(\"add_months\"),\n",
    "    add_months(col(\"input\"), -3).alias(\"sub_months\"),\n",
    "    date_add(col(\"input\"), 4).alias(\"date_add\"),\n",
    "    date_sub(col(\"input\"), 4).alias(\"date_sub\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ year(), month(), next_day(), weekofyear()\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ×œ×—×™×œ×•×¥ ×—×œ×§×™× ××ª××¨×™×š:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.select(\n",
    "    col(\"input\"),\n",
    "    year(col(\"input\")).alias(\"year\"),\n",
    "    month(col(\"input\")).alias(\"month\"),\n",
    "    next_day(col(\"input\"), \"Sunday\").alias(\"next_day\"),\n",
    "    weekofyear(col(\"input\")).alias(\"weekofyear\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ dayofweek(), dayofmonth(), dayofyear()\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ×œ×—×™×œ×•×¥ ×™×•× ×‘×©×‘×•×¢, ×—×•×“×© ×•×©× ×”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.select(\n",
    "    col(\"input\"),\n",
    "    dayofweek(col(\"input\")).alias(\"dayofweek\"),\n",
    "    dayofmonth(col(\"input\")).alias(\"dayofmonth\"),\n",
    "    dayofyear(col(\"input\")).alias(\"dayofyear\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# â° ×¤×•× ×§×¦×™×•×ª Timestamp (×—×•×ª××ª ×–××Ÿ)\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××œ×• ×¤×•×¢×œ×•×ª ×¢×œ ×¢×¨×›×™ timestamp (×ª××¨×™×š + ×©×¢×”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ ×™×¦×™×¨×ª × ×ª×•× ×™ Timestamp ×œ×“×•×’××”\n",
    "\n",
    "× ×™×¦×•×¨ DataFrame ×—×“×© ×¢× × ×ª×•× ×™ timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª × ×ª×•× ×™× ×¢× timestamp\n",
    "data2 = [\n",
    "    [\"1\", \"02-01-2020 11 01 19 06\"],\n",
    "    [\"2\", \"03-01-2019 12 01 19 406\"],\n",
    "    [\"3\", \"03-01-2021 12 01 19 406\"]\n",
    "]\n",
    "df2 = spark.createDataFrame(data2, [\"id\", \"input\"])\n",
    "df2.show(truncate=False)\n",
    "df2.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ current_timestamp() - ×—×•×ª××ª ×–××Ÿ × ×•×›×—×™×ª\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ××ª ×”×ª××¨×™×š ×•×”×–××Ÿ ×”× ×•×›×—×™ ×©×œ ×”××¢×¨×›×ª ×‘×¤×•×¨××˜ `yyyy-MM-dd HH:mm:ss`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# current_timestamp()\n",
    "df2.select(current_timestamp().alias(\"current_timestamp\")).show(1, truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ to_timestamp() - ×”××¨×” ×œ-Timestamp\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×××™×¨×” ××—×¨×•×–×ª timestamp ×œ×¡×•×’ Timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# to_timestamp()\n",
    "df2.select(\n",
    "    col(\"input\"),\n",
    "    to_timestamp(col(\"input\"), \"MM-dd-yyyy HH mm ss SSS\").alias(\"to_timestamp\")\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£3ï¸âƒ£ hour(), minute(), second() - ×—×™×œ×•×¥ ×¨×›×™×‘×™ ×–××Ÿ\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××œ×• ××—×œ×¦×•×ª ××ª ×”×©×¢×”, ×”×“×§×” ×•×”×©× ×™×™×” ×-timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª × ×ª×•× ×™ timestamp ×¢× ×¤×•×¨××˜ ×ª×§×™×Ÿ\n",
    "data3 = [\n",
    "    [\"1\", \"2020-02-01 11:01:19.06\"],\n",
    "    [\"2\", \"2019-03-01 12:01:19.406\"],\n",
    "    [\"3\", \"2021-03-01 12:01:19.406\"]\n",
    "]\n",
    "df3 = spark.createDataFrame(data3, [\"id\", \"input\"])\n",
    "\n",
    "# ×—×™×œ×•×¥ ×©×¢×”, ×“×§×” ×•×©× ×™×™×”\n",
    "df3.select(\n",
    "    col(\"input\"),\n",
    "    hour(col(\"input\")).alias(\"hour\"),\n",
    "    minute(col(\"input\")).alias(\"minute\"),\n",
    "    second(col(\"input\")).alias(\"second\")\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ ×¡×™×›×•×\n",
    "\n",
    "×‘××“×¨×™×š ×–×” ×œ××“× ×• ×¢×œ ×¤×•× ×§×¦×™×•×ª Date ×•-Timestamp ×”×©×•× ×•×ª ×‘-PySpark:\n",
    "\n",
    "### ğŸ“… ×¤×•× ×§×¦×™×•×ª Date:\n",
    "- **current_date()** - ×”×ª××¨×™×š ×”× ×•×›×—×™\n",
    "- **date_format()** - ×¢×™×¦×•×‘ ×ª××¨×™×š\n",
    "- **to_date()** - ×”××¨×” ×œ×¡×•×’ DateType\n",
    "- **datediff()** - ×”×¤×¨×© ×‘×™××™×\n",
    "- **months_between()** - ×”×¤×¨×© ×‘×—×•×“×©×™×\n",
    "- **trunc()** - ×§×™×¦×•×¥ ×ª××¨×™×š\n",
    "- **add_months(), date_add(), date_sub()** - ×”×•×¡×¤×” ×•×”×¤×—×ª×”\n",
    "- **year(), month(), quarter()** - ×—×™×œ×•×¥ ×¨×›×™×‘×™×\n",
    "- **dayofweek(), dayofmonth(), dayofyear()** - ××™×“×¢ ×¢×œ ×™×•×\n",
    "- **weekofyear(), last_day(), next_day()** - ×¤×•× ×§×¦×™×•×ª × ×•×¡×¤×•×ª\n",
    "\n",
    "### â° ×¤×•× ×§×¦×™×•×ª Timestamp:\n",
    "- **current_timestamp()** - ×—×•×ª××ª ×–××Ÿ × ×•×›×—×™×ª\n",
    "- **to_timestamp()** - ×”××¨×” ×œ-Timestamp\n",
    "- **hour(), minute(), second()** - ×—×™×œ×•×¥ ×¨×›×™×‘×™ ×–××Ÿ\n",
    "- **date_trunc()** - ×§×™×¦×•×¥ timestamp\n",
    "\n",
    "### ğŸ’¡ ×˜×™×¤×™× ×—×©×•×‘×™×:\n",
    "\n",
    "1. **×¤×•×¨××˜×™×**: ×”×›×¨ ××ª ×”×¤×•×¨××˜×™× ×”×¡×˜× ×“×¨×˜×™×™× - `yyyy-MM-dd` ×œ×ª××¨×™×›×™× ×•-`yyyy-MM-dd HH:mm:ss.SSSS` ×œ-timestamps\n",
    "\n",
    "2. **×‘×™×¦×•×¢×™×**: ×”×©×ª××© ×ª××™×“ ×‘×¤×•× ×§×¦×™×•×ª ×”××•×‘× ×•×ª ×‘××§×•× UDF - ×”×Ÿ ×‘×˜×•×—×•×ª ×™×•×ª×¨, ××˜×¤×œ×•×ª ×‘-null ×•××”×™×¨×•×ª ×™×•×ª×¨\n",
    "\n",
    "3. **Null values**: ×¤×•× ×§×¦×™×•×ª ××œ×• ××—×–×™×¨×•×ª null ×× ×”×§×œ×˜ ×œ× ×ª×§×™×Ÿ\n",
    "\n",
    "4. **ETL**: ×¤×•× ×§×¦×™×•×ª ××œ×• ×§×¨×™×˜×™×•×ª ×œ×¢×‘×•×“×ª ETL ×¢× × ×ª×•× ×™ ×–××Ÿ\n",
    "\n",
    "5. **Java DateTimeFormatter**: ×›×œ ×”×¤×•×¨××˜×™× ×”× ×ª××›×™× ×‘-Java ×–××™× ×™× ×‘-PySpark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ×§×™×©×•×¨×™× ×•××§×•×¨×•×ª × ×•×¡×¤×™×\n",
    "\n",
    "### ××××¨×™× ×§×©×•×¨×™×:\n",
    "- [PySpark - How to Get Current Date & Timestamp](https://sparkbyexamples.com/pyspark/pyspark-current-date-timestamp/)\n",
    "- [PySpark to_date() - Convert Timestamp to Date](https://sparkbyexamples.com/pyspark/pyspark-to-date-convert-timestamp-to-date/)\n",
    "- [PySpark to_timestamp() - Convert String to Timestamp type](https://sparkbyexamples.com/spark/pyspark-to-timestamp-convert-string-to-timestamp-type/)\n",
    "- [PySpark date_format() - Convert Date to String format](https://sparkbyexamples.com/pyspark/pyspark-date-format-convert-date-to-string-format/)\n",
    "- [Pyspark to_date() vs date_format()](https://sparkbyexamples.com/pyspark/pyspark-to_date-vs-date_format/)\n",
    "- [How to Create a PySpark DataFrame with a Timestamp Column for a Date Range?](https://sparkbyexamples.com/pyspark/create-a-pyspark-dataframe-with-a-timestamp-column-for-a-date-range/)\n",
    "\n",
    "### ×ª×™×¢×•×“ × ×•×¡×£:\n",
    "- [Java DateTimeFormatter Documentation](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/time/format/DateTimeFormatter.html)\n",
    "\n",
    "### ××§×•×¨ ×”××“×¨×™×š:\n",
    "- [PySpark SQL Date and Timestamp Functions - Spark By Examples](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ ×œ××™×“×” ××”× ×”!\n",
    "\n",
    "**Happy Learning!** ğŸš€\n",
    "\n",
    "*××“×¨×™×š ×–×” ×ª×•×¨×’× ×•× ×¢×¨×š ×‘×¢×‘×¨×™×ª ××ª×•×š [SparkByExamples.com](https://sparkbyexamples.com)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
