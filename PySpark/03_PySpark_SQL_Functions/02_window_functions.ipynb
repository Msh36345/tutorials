{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸªŸ ×¤×•× ×§×¦×™×•×ª Window ×‘-PySpark - ××“×¨×™×š ××§×™×£\n",
    "[PySpark Window Functions](https://sparkbyexamples.com/pyspark/pyspark-window-functions/)\n",
    "## ××‘×•×\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª Window ×‘-PySpark ××©××©×•×ª ×œ×—×™×©×•×‘ ×ª×•×¦××•×ª ×›××• ×“×™×¨×•×’ (rank), ××¡×¤×¨ ×©×•×¨×” (row number) ×•×¢×•×“, ×¢×œ ×¤× ×™ ×˜×•×•×— ×©×œ ×©×•×¨×•×ª ×§×œ×˜. ×¤×•× ×§×¦×™×•×ª ××œ×• ×©×™××•×©×™×•×ª ×××•×“ ×›××©×¨ ××‘×¦×¢×™× ×¤×¢×•×œ×•×ª ××’×¨×’×¦×™×” ×‘××¡×’×¨×ª ×—×œ×•×Ÿ (window frame) ×¡×¤×¦×™×¤×™ ×¢×œ ×¢××•×“×•×ª DataFrame.\n",
    "\n",
    "### ğŸ¯ ××”×Ÿ ×¤×•× ×§×¦×™×•×ª Window?\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª Window ×¤×•×¢×œ×•×ª ×¢×œ ×§×‘×•×¦×” ×©×œ ×©×•×¨×•×ª (×›××• frame, partition) ×•××—×–×™×¨×•×ª ×¢×¨×š ×‘×•×“×“ ×¢×‘×•×¨ ×›×œ ×©×•×¨×ª ×§×œ×˜. ×”×Ÿ ×××¤×©×¨×•×ª:\n",
    "- ×—×™×©×•×‘ ×¡×›×•××™× ××¦×˜×‘×¨×™× (running totals)\n",
    "- ×—×™×©×•×‘ ×××•×¦×¢×™× × ×¢×™× (moving averages)\n",
    "- ×–×™×”×•×™ ×¢×¨×›×™× ×§×™×¦×•× ×™×™× ×‘×ª×•×š ×§×‘×•×¦×•×ª ××©× ×”\n",
    "- ×“×™×¨×•×’ ×•××¡×¤×•×¨ ×©×•×¨×•×ª\n",
    "\n",
    "### âš¡ ×™×ª×¨×•× ×•×ª ×¢×œ ×¤× ×™ UDF:\n",
    "\n",
    "- **×‘×˜×™×—×•×ª ×‘×–××Ÿ ×§×•××¤×™×œ×¦×™×”** - ×¤×•× ×§×¦×™×•×ª ××•×‘× ×•×ª ×‘×˜×•×—×•×ª ×™×•×ª×¨\n",
    "- **×˜×™×¤×•×œ ×‘-null** - ××˜×¤×œ×•×ª ×‘×¢×¨×›×™ null ×‘××•×¤×Ÿ ××•×˜×•××˜×™\n",
    "- **×‘×™×¦×•×¢×™×** - ××”×™×¨×•×ª ××©××¢×•×ª×™×ª ×-UDF ××•×ª×× ××™×©×™×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ×¡×•×’×™ ×¤×•× ×§×¦×™×•×ª Window\n",
    "\n",
    "PySpark ×ª×•××š ×‘×©×œ×•×©×” ×¡×•×’×™× ×¢×™×§×¨×™×™× ×©×œ ×¤×•× ×§×¦×™×•×ª window:\n",
    "\n",
    "### 1ï¸âƒ£ **×¤×•× ×§×¦×™×•×ª ×“×™×¨×•×’ (Ranking Functions)**\n",
    "- `row_number()` - ××¡×¤×¨ ×©×•×¨×” ×¡×“×¨×ª×™\n",
    "- `rank()` - ×“×™×¨×•×’ ×¢× ×¤×¢×¨×™×\n",
    "- `dense_rank()` - ×“×™×¨×•×’ ×œ×œ× ×¤×¢×¨×™×\n",
    "- `percent_rank()` - ×“×™×¨×•×’ ××—×•×–×™\n",
    "- `ntile(n)` - ×—×œ×•×§×” ×œ-n ×§×‘×•×¦×•×ª\n",
    "\n",
    "### 2ï¸âƒ£ **×¤×•× ×§×¦×™×•×ª ×× ×œ×™×˜×™×•×ª (Analytic Functions)**\n",
    "- `cume_dist()` - ×”×ª×¤×œ×’×•×ª ××¦×˜×‘×¨×ª\n",
    "- `lag()` - ×’×™×©×” ×œ×©×•×¨×” ×§×•×“××ª\n",
    "- `lead()` - ×’×™×©×” ×œ×©×•×¨×” ×”×‘××”\n",
    "\n",
    "### 3ï¸âƒ£ **×¤×•× ×§×¦×™×•×ª ××’×¨×’×¦×™×” (Aggregate Functions)**\n",
    "- `sum()`, `avg()`, `min()`, `max()`, `count()` ×•×¢×•×“\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ×”×’×“×¨×ª ×”×¡×‘×™×‘×”\n",
    "\n",
    "×¨××©×™×ª, × ×™×™×‘× ××ª ×”×¡×¤×¨×™×•×ª ×”× ×“×¨×•×©×•×ª ×•× ×™×¦×•×¨ SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder.appName('PySpark-Window-Functions').getOrCreate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×™×¦×™×¨×ª DataFrame ×œ×“×•×’××”\n",
    "\n",
    "× ×™×¦×•×¨ DataFrame ×¢× × ×ª×•× ×™ ×¢×•×‘×“×™× ×©×™×©××© ××•×ª× ×• ×œ×”×“×’××ª ×¤×•× ×§×¦×™×•×ª Window:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×’×“×¨×ª × ×ª×•× ×™×\n",
    "simpleData = (\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    ")\n",
    "\n",
    "columns = [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema=columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª ×”×¡×›×™××”\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª ×”× ×ª×•× ×™×\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸªŸ ×”×’×“×¨×ª Window Specification\n",
    "\n",
    "×œ×¤× ×™ ×©× ×©×ª××© ×‘×¤×•× ×§×¦×™×•×ª window, ×¢×œ×™× ×• ×œ×”×’×“×™×¨ ××ª ×”-window specification.\n",
    "\n",
    "×–×” ×›×•×œ×œ:\n",
    "- **partitionBy()** - ×—×œ×•×§×” ×œ×§×‘×•×¦×•×ª\n",
    "- **orderBy()** - ××™×•×Ÿ ×‘×ª×•×š ×›×œ ×§×‘×•×¦×”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# ×”×’×“×¨×ª window: ×—×œ×•×§×” ×œ×¤×™ ××—×œ×§×”, ××™×•×Ÿ ×œ×¤×™ ××©×›×•×¨×ª\n",
    "windowSpec = Window.partitionBy(\"department\").orderBy(\"salary\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ† ×¤×•× ×§×¦×™×•×ª ×“×™×¨×•×’ (Ranking Functions)\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××œ×• ××§×¦×•×ª ××¡×¤×¨×™× ×¡×“×¨×ª×™×™× ×œ×©×•×¨×•×ª DataFrame ×¢×œ ×‘×¡×™×¡ ×§×¨×™×˜×¨×™×•× ×™× ××•×’×“×¨×™×."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ row_number() - ××¡×¤×¨ ×©×•×¨×”\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××§×¦×” ××¡×¤×¨ ×©×•×¨×” ×¡×“×¨×ª×™ ×™×™×—×•×“×™, ××ª×—×™×œ ×-1, ×œ×›×œ ×©×•×¨×” ×‘×ª×•×š partition:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# row_number()\n",
    "df.withColumn(\"row_number\", row_number().over(windowSpec)).show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ rank() - ×“×™×¨×•×’ ×¢× ×¤×¢×¨×™×\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××¡×¤×§×ª ×“×™×¨×•×’ ×œ×ª×•×¦××” ×‘×ª×•×š partition. ×¤×•× ×§×¦×™×” ×–×• ××©××™×¨×” ×¤×¢×¨×™× ×‘×“×™×¨×•×’ ×›××©×¨ ×™×© ×¢×¨×›×™× ×–×”×™×:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import rank\n",
    "\n",
    "# rank()\n",
    "df.withColumn(\"rank\", rank().over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ dense_rank() - ×“×™×¨×•×’ ×œ×œ× ×¤×¢×¨×™×\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×“×•××” ×œ-`rank()` ××š ×œ×œ× ×¤×¢×¨×™× ×‘×“×™×¨×•×’:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "\n",
    "# dense_rank()\n",
    "df.withColumn(\"dense_rank\", dense_rank().over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ percent_rank() - ×“×™×¨×•×’ ××—×•×–×™\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ××ª ×”×“×™×¨×•×’ ×”××—×•×–×™ ×©×œ ×©×•×¨×•×ª ×‘×ª×•×š partition:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import percent_rank\n",
    "\n",
    "# percent_rank()\n",
    "df.withColumn(\"percent_rank\", percent_rank().over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ntile() - ×—×œ×•×§×” ×œ×§×‘×•×¦×•×ª\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×œ×§×ª ××ª ×”×©×•×¨×•×ª ×œ-n ×§×‘×•×¦×•×ª ×©×•×•×ª (××• ×›××¢×˜ ×©×•×•×ª):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import ntile\n",
    "\n",
    "# ntile() - ×—×œ×•×§×” ×œ-2 ×§×‘×•×¦×•×ª\n",
    "df.withColumn(\"ntile\", ntile(2).over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“Š ×¤×•× ×§×¦×™×•×ª ×× ×œ×™×˜×™×•×ª (Analytic Functions)\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××œ×• ××¡×¤×§×•×ª ×’×™×©×” ×œ×¢×¨×›×™× ××©×•×¨×•×ª ××—×¨×•×ª ××• ××—×©×‘×•×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ cume_dist() - ×”×ª×¤×œ×’×•×ª ××¦×˜×‘×¨×ª\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ××—×©×‘×ª ××ª ×”×”×ª×¤×œ×’×•×ª ×”××¦×˜×‘×¨×ª ×©×œ ×¢×¨×š ×‘×ª×•×š partition:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import cume_dist\n",
    "\n",
    "# cume_dist()\n",
    "df.withColumn(\"cume_dist\", cume_dist().over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ lag() - ×’×™×©×” ×œ×©×•×¨×” ×§×•×“××ª\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×××¤×©×¨×ª ×’×™×©×” ×œ×¢×¨×š ××”×©×•×¨×” ×”×§×•×“××ª ×‘×ª×•×š partition:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import lag\n",
    "\n",
    "# lag() - ×’×™×©×” ×œ×©×•×¨×” ×©× ×™×™×” ×œ×¤× ×™\n",
    "df.withColumn(\"lag\", lag(\"salary\", 2).over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ lead() - ×’×™×©×” ×œ×©×•×¨×” ×”×‘××”\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×××¤×©×¨×ª ×’×™×©×” ×œ×¢×¨×š ××”×©×•×¨×” ×”×‘××” ×‘×ª×•×š partition:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import lead\n",
    "\n",
    "# lead() - ×’×™×©×” ×œ×©×•×¨×” ×©× ×™×™×” ××—×¨×™\n",
    "df.withColumn(\"lead\", lead(\"salary\", 2).over(windowSpec)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ˆ ×¤×•× ×§×¦×™×•×ª ××’×¨×’×¦×™×” (Aggregate Window Functions)\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª ××’×¨×’×¦×™×” ×—×•×©×‘×•×ª ×¢×¨×›×™× ××¦×˜×‘×¨×™× ×‘×ª×•×š partitions ××•×’×“×¨×™×.\n",
    "\n",
    "**×©×™× ×œ×‘:** ×›××©×¨ ×¢×•×‘×“×™× ×¢× ×¤×•× ×§×¦×™×•×ª ××’×¨×’×¦×™×”, ××™×Ÿ ×¦×•×¨×š ×‘-`orderBy` clause."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, avg, sum, min, max\n",
    "\n",
    "# ×”×’×“×¨×ª window ×œ××’×¨×’×¦×™×” (×œ×œ× orderBy)\n",
    "windowSpecAgg = Window.partitionBy(\"department\")\n",
    "\n",
    "# ×—×™×©×•×‘ ××’×¨×’×¦×™×•×ª ×œ×›×œ ××—×œ×§×”\n",
    "df.withColumn(\"row\", row_number().over(windowSpec)) \\\n",
    "    .withColumn(\"avg\", avg(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "    .withColumn(\"sum\", sum(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "    .withColumn(\"min\", min(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "    .withColumn(\"max\", max(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "    .where(col(\"row\") == 1).select(\"department\", \"avg\", \"sum\", \"min\", \"max\") \\\n",
    "    .show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ ×¡×™×›×•×\n",
    "\n",
    "×‘××“×¨×™×š ×–×” ×œ××“× ×• ×¢×œ ×¤×•× ×§×¦×™×•×ª Window ×”×©×•× ×•×ª ×‘-PySpark:\n",
    "\n",
    "### ğŸ† ×¤×•× ×§×¦×™×•×ª ×“×™×¨×•×’:\n",
    "- **row_number()** - ××¡×¤×•×¨ ×™×™×—×•×“×™ ×œ×›×œ ×©×•×¨×”\n",
    "- **rank()** - ×“×™×¨×•×’ ×¢× ×¤×¢×¨×™× ×‘×¢×¨×›×™× ×–×”×™×\n",
    "- **dense_rank()** - ×“×™×¨×•×’ ×œ×œ× ×¤×¢×¨×™×\n",
    "- **percent_rank()** - ×“×™×¨×•×’ ×›××—×•×– (0-1)\n",
    "- **ntile(n)** - ×—×œ×•×§×” ×œ-n ×§×‘×•×¦×•×ª ×©×•×•×ª\n",
    "\n",
    "### ğŸ“Š ×¤×•× ×§×¦×™×•×ª ×× ×œ×™×˜×™×•×ª:\n",
    "- **cume_dist()** - ×”×ª×¤×œ×’×•×ª ××¦×˜×‘×¨×ª (0-1)\n",
    "- **lag()** - ×’×™×©×” ×œ×¢×¨×›×™× ××©×•×¨×•×ª ×§×•×“××•×ª\n",
    "- **lead()** - ×’×™×©×” ×œ×¢×¨×›×™× ××©×•×¨×•×ª ×¢×ª×™×“×™×•×ª\n",
    "\n",
    "### ğŸ“ˆ ×¤×•× ×§×¦×™×•×ª ××’×¨×’×¦×™×”:\n",
    "- **sum(), avg(), min(), max()** - ×—×™×©×•×‘×™× ××¦×˜×‘×¨×™×\n",
    "- × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×›×œ ×¤×•× ×§×¦×™×•×ª ×”××’×¨×’×¦×™×” ×”×¡×˜× ×“×¨×˜×™×•×ª\n",
    "\n",
    "### ğŸ’¡ ×¢×§×¨×•× ×•×ª ×—×©×•×‘×™×:\n",
    "\n",
    "1. **Window Specification**: ×ª××™×“ ×”×’×“×¨ `partitionBy()` ×œ×× ×™×¢×ª ×”×¢×‘×¨×ª ×›×œ ×”× ×ª×•× ×™× ×œ-partition ××—×“\n",
    "\n",
    "2. **orderBy**: × ×“×¨×© ×œ×¤×•× ×§×¦×™×•×ª ×“×™×¨×•×’ ×•×× ×œ×™×˜×™×•×ª, ××•×¤×¦×™×•× ×œ×™ ×œ××’×¨×’×¦×™×”\n",
    "\n",
    "3. **×‘×™×¦×•×¢×™×**: ×”×©×ª××© ×‘×¤×•× ×§×¦×™×•×ª Window ×‘××§×•× UDF - ×”×Ÿ ×™×¢×™×œ×•×ª ××©××¢×•×ª×™×ª\n",
    "\n",
    "4. **××§×¨×™ ×©×™××•×© × ×¤×•×¦×™×**:\n",
    "   - ××¦×™××ª Top N ×‘×›×œ ×§×‘×•×¦×”\n",
    "   - ×—×™×©×•×‘ ×××•×¦×¢×™× × ×¢×™×\n",
    "   - ×”×©×•×•××” ×‘×™×Ÿ ×©×•×¨×•×ª ×¡××•×›×•×ª\n",
    "   - ×—×™×©×•×‘ ×¡×›×•××™× ××¦×˜×‘×¨×™×\n",
    "   - ×“×™×¨×•×’ ×¢×•×‘×“×™×/××•×¦×¨×™×/×œ×§×•×—×•×ª\n",
    "\n",
    "5. **Window Frame**: × ×™×ª×Ÿ ×œ×”×’×“×™×¨ ××¡×’×¨×ª ××“×•×™×§×ª ×™×•×ª×¨ ×‘×××¦×¢×•×ª `rowsBetween()` ××• `rangeBetween()`\n",
    "\n",
    "### ğŸ¯ ×“×•×’×××•×ª ×œ×©×™××•×©:\n",
    "\n",
    "```python\n",
    "# ××¦×™××ª 3 ×”×¢×•×‘×“×™× ×¢× ×”×©×›×¨ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×‘×›×œ ××—×œ×§×”\n",
    "df.withColumn(\"rank\", rank().over(windowSpec)) \\\n",
    "  .where(col(\"rank\") <= 3)\n",
    "\n",
    "# ×—×™×©×•×‘ ×”×¤×¨×© ××©×›×•×¨×ª ××”×¢×•×‘×“ ×”×§×•×“×\n",
    "df.withColumn(\"salary_diff\", \n",
    "              col(\"salary\") - lag(\"salary\", 1).over(windowSpec))\n",
    "\n",
    "# ×—×™×©×•×‘ ×××•×¦×¢ × ×¢ ×©×œ 3 ×©×•×¨×•×ª\n",
    "windowFrame = Window.partitionBy(\"department\") \\\n",
    "                    .orderBy(\"salary\") \\\n",
    "                    .rowsBetween(-1, 1)\n",
    "df.withColumn(\"moving_avg\", avg(\"salary\").over(windowFrame))\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ×§×™×©×•×¨×™× ×•××§×•×¨×•×ª × ×•×¡×¤×™×\n",
    "\n",
    "### ××××¨×™× ×§×©×•×¨×™×:\n",
    "- [PySpark Add New Column with Row Number](https://sparkbyexamples.com/uncategorized/pyspark-add-new-column-with-row-number/)\n",
    "- [Differences between rank(), dense_rank(), and row_number() functions](https://sparkbyexamples.com/pyspark/difference-between-pyspark-rank-dense_rank-and-row_number/)\n",
    "- [Explain PySpark first_value() Function with Examples](https://sparkbyexamples.com/pyspark/explain-pyspark-first_value-function-with-examples/)\n",
    "- [Explain PySpark last_value() Function with Examples](https://sparkbyexamples.com/pyspark/explain-pyspark-last_value-function-with-examples/)\n",
    "- [Extract First and last N rows from PySpark DataFrame](https://sparkbyexamples.com/pyspark/extract-first-and-last-n-rows-from-pyspark-dataframe/)\n",
    "- [PySpark Aggregate Functions with Examples](https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/)\n",
    "- [PySpark JSON Functions with Examples](https://sparkbyexamples.com/pyspark/pyspark-json-functions-with-examples/)\n",
    "\n",
    "### ×§×•×“ ××§×•×¨:\n",
    "- [PySpark Examples GitHub - Window Functions](https://github.com/spark-examples/pyspark-examples/blob/master/pyspark-window-functions.py)\n",
    "\n",
    "### ××§×•×¨ ×”××“×¨×™×š:\n",
    "- [PySpark Window Functions - Spark By Examples](https://sparkbyexamples.com/pyspark/pyspark-window-functions/)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ ×œ××™×“×” ××”× ×”!\n",
    "\n",
    "**Happy Learning!** ğŸš€\n",
    "\n",
    "*××“×¨×™×š ×–×” ×ª×•×¨×’× ×•× ×¢×¨×š ×‘×¢×‘×¨×™×ª ××ª×•×š [SparkByExamples.com](https://sparkbyexamples.com)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
