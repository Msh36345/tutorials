{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "××§×•×¨: [Spark By Examples - Create an Empty DataFrame & RDD](https://sparkbyexamples.com/pyspark/pyspark-create-an-empty-dataframe/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ—‚ï¸ PySpark - ×™×¦×™×¨×ª DataFrame ×•-RDD ×¨×™×§×™×\n",
    "\n",
    "**×ª××¨×™×š:** 27 ×‘××¨×¥, 2024  \n",
    "**×–××Ÿ ×§×¨×™××” ××©×•×¢×¨:** 6 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "×‘××××¨ ×–×”, ××¡×‘×™×¨ ×›×™×¦×“ ×œ×™×¦×•×¨ PySpark DataFrame/RDD ×¨×™×§ ×‘××•×¤×Ÿ ×™×“× ×™ ×¢× ××• ×‘×œ×™ schema (×©××•×ª ×¢××•×“×•×ª) ×‘×“×¨×›×™× ×©×•× ×•×ª.\n",
    "\n",
    "×œ×”×œ×Ÿ ×”×¡×‘×¨×ª×™ ××ª ××—×“ ××”×ª×¨×—×™×©×™× ×”×¨×‘×™× ×©×‘×”× ×× ×• ×¦×¨×™×›×™× ×œ×™×¦×•×¨ DataFrame ×¨×™×§.\n",
    "\n",
    "### ğŸ“‹ ××ª×™ × ×¦×˜×¨×š DataFrame ×¨×™×§?\n",
    "\n",
    "×‘×–××Ÿ ×¢×‘×•×“×” ×¢× ×§×‘×¦×™×, ×œ×¤×¢××™× ×™×™×ª×›×Ÿ ×©×œ× × ×§×‘×œ ×§×•×‘×¥ ×œ×¢×™×‘×•×“, ××•×œ× ×¢×“×™×™×Ÿ × ×¦×˜×¨×š ×œ×™×¦×•×¨ DataFrame ×‘××•×¤×Ÿ ×™×“× ×™ ×¢× ××•×ª×• schema ×©×× ×• ××¦×¤×™× ×œ×•.\n",
    "\n",
    "×× ×œ× × ×™×¦×•×¨ ×¢× ××•×ª×• schema, ×”×¤×¢×•×œ×•×ª/×˜×¨× ×¡×¤×•×¨××¦×™×•×ª ×©×œ× ×• (×›××• `union()`) ×¢×œ DataFrame ×™×›×©×œ×• ×›×™×•×•×Ÿ ×©×”×Ÿ ××ª×™×™×—×¡×•×ª ×œ×¢××•×“×•×ª ×©××•×œ×™ ×œ× ×§×™×™××•×ª.\n",
    "\n",
    "**×œ×˜×™×¤×•×œ ×‘××¦×‘×™× ×“×•××™× ×œ××œ×”**, ×× ×• ×ª××™×“ ×¦×¨×™×›×™× ×œ×™×¦×•×¨ DataFrame ×¢× ××•×ª× ×©××•×ª ×¢××•×“×•×ª ×•×˜×™×¤×•×¡×™ × ×ª×•× ×™×, ×œ×œ× ×§×©×¨ ×× ×”×§×•×‘×¥ ×§×™×™× ××• ×¨×™×§ ×‘×–××Ÿ ×”×¢×™×‘×•×“."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ×™×¦×™×¨×ª RDD ×¨×™×§ ×‘-PySpark\n",
    "\n",
    "×¦×•×¨ RDD ×¨×™×§ ×‘×××¦×¢×•×ª `emptyRDD()` ×©×œ SparkContext, ×œ×“×•×’××” `spark.sparkContext.emptyRDD()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# ×™×¦×™×¨×ª RDD ×¨×™×§\n",
    "emptyRDD = spark.sparkContext.emptyRDD()\n",
    "print(emptyRDD)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "×”×§×•×“ ×œ×¢×™×œ ×™×•×¦×¨ RDD ×¨×™×§ ×œ×—×œ×•×˜×™×Ÿ ×œ×œ× partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”„ ×—×œ×•×¤×”: ×™×¦×™×¨×ª RDD ×¨×™×§ ×¢× parallelize\n",
    "\n",
    "×œ×—×œ×•×¤×™×Ÿ, × ×™×ª×Ÿ ×’× ×œ×§×‘×œ RDD ×¨×™×§ ×‘×××¦×¢×•×ª `spark.sparkContext.parallelize([])`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª RDD ×¨×™×§ ×‘×××¦×¢×•×ª parallelize\n",
    "rdd2 = spark.sparkContext.parallelize([])\n",
    "print(rdd2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**âš ï¸ ×©×™× ×œ×‘:** ×× ×ª× ×¡×” ×œ×‘×¦×¢ ×¤×¢×•×œ×•×ª ×¢×œ RDD ×¨×™×§, ×ª×§×‘×œ ×©×’×™××” `ValueError(\"RDD is empty\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ×™×¦×™×¨×ª DataFrame ×¨×™×§ ×¢× Schema (StructType)\n",
    "\n",
    "×›×“×™ ×œ×™×¦×•×¨ PySpark DataFrame ×¨×™×§ ×‘××•×¤×Ÿ ×™×“× ×™ ×¢× schema (×©××•×ª ×¢××•×“×•×ª ×•×¡×•×’×™ × ×ª×•× ×™×), ×ª×—×™×œ×” **×¦×•×¨ schema ×‘×××¦×¢×•×ª StructType ×•-StructField**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ×©×œ×‘ 1: ×™×¦×™×¨×ª Schema"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª Schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"firstname\", StringType(), True),\n",
    "    StructField(\"middlename\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "- **StructType** - ××’×“×™×¨ ××ª ×”××‘× ×” ×©×œ ×”-DataFrame\n",
    "- **StructField** - ××’×“×™×¨ ×›×œ ×¢××•×“×”: ×©×, ×˜×™×¤×•×¡ × ×ª×•× ×™×, ×•×”×× × ×™×ª×Ÿ ×œ×”×›×™×œ NULL\n",
    "- **StringType()** - ×˜×™×¤×•×¡ × ×ª×•× ×™× ×©×œ ××—×¨×•×–×ª\n",
    "- **True** - ××¦×™×™×Ÿ ×©×”×¢××•×“×” ×™×›×•×œ×” ×œ×”×›×™×œ ×¢×¨×›×™ NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š ×©×œ×‘ 2: ×™×¦×™×¨×ª DataFrame ×¢× ×”-Schema"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×¨×™×§ ××”-RDD ×”×¨×™×§ ×¢× ×”-schema\n",
    "df = spark.createDataFrame(emptyRDD, schema)\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- firstname: string (nullable = true)\n",
    " |-- middlename: string (nullable = true)\n",
    " |-- lastname: string (nullable = true)\n",
    "```\n",
    "\n",
    "×”×§×•×“ ×œ×¢×™×œ ×× ×™×‘ ××ª ×”-schema ×©×œ ×”-DataFrame ×”×¨×™×§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ×”××¨×ª RDD ×¨×™×§ ×œ-DataFrame\n",
    "\n",
    "× ×™×ª×Ÿ ×’× ×œ×™×¦×•×¨ DataFrame ×¨×™×§ ×¢×œ ×™×“×™ ×”××¨×ª RDD ×¨×™×§ ×œ-DataFrame ×‘×××¦×¢×•×ª `toDF()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×ª RDD ×¨×™×§ ×œ-DataFrame\n",
    "df1 = emptyRDD.toDF(schema)\n",
    "df1.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "×”×©×™×˜×” `toDF()` ×××™×¨×” RDD ×œ-DataFrame ×¢× ×”-schema ×©×¦×•×™×Ÿ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ×™×¦×™×¨×ª DataFrame ×¨×™×§ ×¢× Schema ×‘××•×¤×Ÿ ×™×©×™×¨\n",
    "\n",
    "×¢×“ ×›×” ×›×™×¡×™×ª×™ ×™×¦×™×¨×ª DataFrame ×¨×™×§ ×-RDD, ××š ×›××Ÿ × ×™×¦×•×¨ ××•×ª×• ×‘××•×¤×Ÿ ×™×“× ×™ ×¢× schema **×•×œ×œ× RDD**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×¨×™×§ ×‘××•×¤×Ÿ ×™×©×™×¨\n",
    "df2 = spark.createDataFrame([], schema)\n",
    "df2.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "×‘××§×•× ×œ×”×¢×‘×™×¨ RDD, ×× ×• ×¤×©×•×˜ ××¢×‘×™×¨×™× ×¨×©×™××” ×¨×™×§×” `[]` ×™×—×“ ×¢× ×”-schema, ×•×–×” ×™×•×¦×¨ DataFrame ×¨×™×§ ×¢× ×”××‘× ×” ×”××‘×•×§×©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ×™×¦×™×¨×ª DataFrame ×¨×™×§ ×œ×œ× Schema (×œ×œ× ×¢××•×“×•×ª)\n",
    "\n",
    "×›×“×™ ×œ×™×¦×•×¨ DataFrame ×¨×™×§ ×œ×œ× schema (×œ×œ× ×¢××•×“×•×ª), ×¤×©×•×˜ ×¦×•×¨ schema ×¨×™×§ ×•×”×©×ª××© ×‘×• ×‘×–××Ÿ ×™×¦×™×¨×ª PySpark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×¨×™×§ ×œ×œ× schema (×œ×œ× ×¢××•×“×•×ª)\n",
    "df3 = spark.createDataFrame([], StructType([]))\n",
    "df3.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "#root\n",
    "```\n",
    "\n",
    "×–×” ××“×¤×™×¡ schema ×¨×™×§ ×œ×—×œ×•×˜×™×Ÿ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ×¡×™×›×•×\n",
    "\n",
    "×‘××“×¨×™×š ×–×” ×œ××“× ×• ××¡×¤×¨ ×“×¨×›×™× ×œ×™×¦×™×¨×ª DataFrame ×•-RDD ×¨×™×§×™× ×‘-PySpark:\n",
    "\n",
    "### âœ… ×©×™×˜×•×ª ×œ×™×¦×™×¨×ª RDD ×¨×™×§:\n",
    "1. **emptyRDD()** - ×™×¦×™×¨×ª RDD ×¨×™×§ ×œ×—×œ×•×˜×™×Ÿ\n",
    "2. **parallelize([])** - ×™×¦×™×¨×ª RDD ×¨×™×§ ×¢× partitions\n",
    "\n",
    "### âœ… ×©×™×˜×•×ª ×œ×™×¦×™×¨×ª DataFrame ×¨×™×§:\n",
    "1. **×¢× Schema** - ×‘×××¦×¢×•×ª StructType ×•-StructField\n",
    "2. **×”××¨×” ×-RDD** - ×‘×××¦×¢×•×ª toDF()\n",
    "3. **×™×¦×™×¨×” ×™×©×™×¨×”** - ×‘×××¦×¢×•×ª createDataFrame([], schema)\n",
    "4. **×œ×œ× Schema** - DataFrame ×¨×™×§ ×œ×—×œ×•×˜×™×Ÿ ×œ×œ× ×¢××•×“×•×ª\n",
    "\n",
    "### ğŸ¯ × ×§×•×“×•×ª ××¤×ª×—:\n",
    "- ×©×™××•×© ×‘-DataFrame ×¨×™×§ ×¢× schema ×¢×•×–×¨ ×œ×× ×•×¢ ×©×’×™××•×ª ×‘×¤×¢×•×œ×•×ª union ×•-transformations\n",
    "- ×—×©×•×‘ ×œ×”×’×“×™×¨ schema ××—×™×“ ×’× ×›××©×¨ ××™×Ÿ × ×ª×•× ×™×\n",
    "- × ×™×ª×Ÿ ×œ×™×¦×•×¨ DataFrame ×¨×™×§ ×¢× ××• ×‘×œ×™ schema ×‘×”×ª×× ×œ×¦×•×¨×š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **PySpark Replace Empty Value With None/null on DataFrame**\n",
    "- **Create a PySpark DataFrame from Multiple Lists**\n",
    "- **PySpark Create RDD with Examples**\n",
    "- **PySpark SparkContext Explained**\n",
    "- **PySpark Replace Column Values in DataFrame**\n",
    "- **PySpark Retrieve DataType & Column Names of DataFrame**\n",
    "- **PySpark Count of Non null, nan Values in DataFrame**\n",
    "- **PySpark RDD Actions with examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ ×ª×’×™×•×ª (Tags)\n",
    "\n",
    "`EMPTY DATAFRAME` `EMPTYRDD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××§×•×¨×•×ª ×•××™×“×¢ × ×•×¡×£\n",
    "\n",
    "**××§×•×¨ ×”××“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©××™:**\n",
    "- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)\n",
    "- [PySpark SQL Documentation](https://spark.apache.org/docs/latest/api/python/)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™××•×“ PySpark!**\n",
    "\n",
    "**âœ¨ Happy Learning !!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
