{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "×ž×§×•×¨: [Spark By Examples - Column Class | Operators & Functions\n",
    "](https://sparkbyexamples.com/pyspark/pyspark-column-functions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”§ PySpark Column Class - ×¤×•× ×§×¦×™×•×ª ×•××•×¤×¨×˜×•×¨×™×\n",
    "\n",
    "**×ª××¨×™×š:** 27 ×‘×ž×¨×¥, 2024  \n",
    "**×–×ž×Ÿ ×§×¨×™××” ×ž×©×•×¢×¨:** 17 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ ×ž×‘×•×\n",
    "\n",
    "×ž×—×œ×§×” `pyspark.sql.Column` ×ž×¡×¤×§×ª ×ž×¡×¤×¨ ×¤×•× ×§×¦×™×•×ª ×œ×¢×‘×•×“×” ×¢× DataFrame:\n",
    "- ðŸ” ×ž× ×™×¤×•×œ×¦×™×” ×©×œ ×¢×¨×›×™ ×”×¢×ž×•×“×•×ª\n",
    "- ðŸ“Š ×”×¢×¨×›×ª ×‘×™×˜×•×™ ×‘×•×œ×™×× ×™ ×œ×¡×™× ×•×Ÿ ×©×•×¨×•×ª\n",
    "- ðŸ”Ž ××—×–×•×¨ ×¢×¨×š ××• ×—×œ×§ ×ž×¢×¨×š ×ž×¢×ž×•×“×ª ×¨×©×™×ž×”\n",
    "- ðŸ“ ×¢×‘×•×“×” ×¢× list, map ×•×¢×ž×•×“×•×ª struct ×ž×§×•× × ×•×ª\n",
    "\n",
    "×‘×ž××ž×¨ ×–×” ××›×¡×”:\n",
    "1. âœ¨ ××™×š ×œ×™×¦×•×¨ ××•×‘×™×™×§×˜ Column\n",
    "2. âž• PySpark Column Operators\n",
    "3. ðŸ› ï¸ PySpark Column Functions\n",
    "4. ðŸ“š ×“×•×’×ž××•×ª ×ž×¢×©×™×•×ª\n",
    "\n",
    "### ðŸ’¡ × ×§×•×“×•×ª ×ž×¤×ª×—:\n",
    "\n",
    "- **×ž×—×œ×§×ª PySpark Column** ×ž×™×™×¦×’×ª ×¢×ž×•×“×” ×‘×•×“×“×ª ×‘-DataFrame\n",
    "- ×ž×¡×¤×§×ª **×¤×•× ×§×¦×™×•×ª** ×©×ž×©×ž×©×•×ª ×œ×ž× ×™×¤×•×œ×¦×™×” ×©×œ Columns ×•-Rows ×‘-DataFrame\n",
    "- ×—×œ×§ ×ž×¤×•× ×§×¦×™×•×ª Column ×ž×¢×¨×™×›×•×ª **×‘×™×˜×•×™ ×‘×•×œ×™×× ×™** ×©× ×™×ª×Ÿ ×œ×”×©×ª×ž×© ×‘×• ×¢× `filter()` ×œ×¡×™× ×•×Ÿ DataFrame\n",
    "- ×ž×¡×¤×§×ª ×¤×•× ×§×¦×™×•×ª **×œ×§×‘×œ×ª ×¢×¨×š ×ž×¢×ž×•×“×ª list ×œ×¤×™ ××™× ×“×§×¡, map value ×œ×¤×™ key ×•-index**\n",
    "- ×œ×‘×¡×•×£, ×’× ×ž×¡×¤×§×ª **×¤×•× ×§×¦×™×•×ª × ×•×¡×¤×•×ª** ×ž-`pyspark.sql.functions` ×©×ž×§×‘×œ×•×ª ××•×‘×™×™×§×˜ Column ×•×ž×—×–×™×¨×•×ª ×˜×™×¤×•×¡ Column\n",
    "\n",
    "**×©×™× ×œ×‘:** ×¨×•×‘ ×¤×•× ×§×¦×™×•×ª `pyspark.sql.functions` ×ž×—×–×™×¨×•×ª ×˜×™×¤×•×¡ Column, ×œ×›×Ÿ ×—×©×•×‘ ×ž××•×“ ×œ×“×¢×ª ××ª ×”×¤×¢×•×œ×” ×©× ×™×ª×Ÿ ×œ×‘×¦×¢ ×¢× ×˜×™×¤×•×¡ Column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ Column Class\n",
    "\n",
    "××—×ª ×”×“×¨×›×™× ×”×¤×©×•×˜×•×ª ×‘×™×•×ª×¨ ×œ×™×¦×•×¨ ××•×‘×™×™×§×˜ Column Class ×”×™× ×‘××ž×¦×¢×•×ª ×¤×•× ×§×¦×™×” `PySpark lit() SQL`.\n",
    "\n",
    "×–×” ×œ×•×§×— ×¢×¨×š ×œ×™×˜×¨×œ×™ ×•×ž×—×–×™×¨ ××•×‘×™×™×§×˜ Column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Example\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# ×¢×›×©×™×• ××¤×©×¨ ×œ×”×©×ª×ž×© ×‘-lit()\n",
    "colObj = lit(\"sparkbyexamples.com\")\n",
    "print(colObj)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**× ×™×ª×Ÿ ×’× ×œ×’×©×ª ×œ-Column ×ž-DataFrame ×‘×ž×¡×¤×¨ ×“×¨×›×™×:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×“×¨×›×™× ×©×•× ×•×ª ×œ×’×©×ª ×œ×¢×ž×•×“×”\n",
    "data = [(\"James\", 23), (\"Ann\", 40)]\n",
    "df = spark.createDataFrame(data).toDF(\"name.fname\", \"gender\")\n",
    "df.printSchema()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™×ž×•×© ×‘××•×‘×™×™×§×˜ DataFrame (df)\n",
    "df.select(df.gender).show()\n",
    "df.select(df[\"gender\"]).show()\n",
    "\n",
    "# ×’×™×©×” ×œ×©× ×¢×ž×•×“×” ×¢× col. (×¢× backticks)\n",
    "df.select(df[\"`name.fname`\"]).show()\n",
    "\n",
    "# ×©×™×ž×•×© ×‘×¤×•× ×§×¦×™×” col() ×©×œ SQL\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"gender\")).show()\n",
    "\n",
    "# ×’×™×©×” ×œ×©× ×¢×ž×•×“×” ×¢× col ×¢× backticks\n",
    "df.select(col(\"`name.fname`\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”§ ×™×¦×™×¨×ª Column ×ž-Row Class ×‘××ž×¦×¢×•×ª\n",
    "\n",
    "× ×™×ª×Ÿ ×’× ×œ×™×¦×•×¨ ××ª ×–×” ×‘××ž×¦×¢×•×ª ×ž×—×œ×§×ª **PySpark Row**. ×œ×—×œ×•×¤×™×Ÿ, ××ª×” ×™×›×•×œ ×’× ×œ×™×¦×•×¨ ××•×ª×• ×‘××ž×¦×¢×•×ª **PySpark StructType & StructField**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×‘××ž×¦×¢×•×ª Row class\n",
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "    Row(name=\"James\", prop=Row(hair=\"black\", eye=\"blue\")),\n",
    "    Row(name=\"Ann\", prop=Row(hair=\"grey\", eye=\"black\"))\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.printSchema()\n",
    "\n",
    "# ×’×™×©×” ×œ×¢×ž×•×“×ª struct\n",
    "df.select(df.prop.hair).show()\n",
    "df.select(df[\"prop.hair\"]).show()\n",
    "df.select(col(\"prop.hair\")).show()\n",
    "\n",
    "# ×’×™×©×” ×œ×›×œ ×”×¢×ž×•×“×•×ª ×ž-struct\n",
    "df.select(col(\"prop.*\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ PySpark Column Operators\n",
    "\n",
    "PySpark column ×’× ×ž×¡×¤×§ ×“×¨×š ×œ×‘×¦×¢ **×¤×¢×•×œ×•×ª ××¨×™×ª×ž×˜×™×•×ª** ×¢×œ ×¢×ž×•×“×•×ª ×‘××ž×¦×¢×•×ª ××•×¤×¨×˜×•×¨×™×."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×›× ×ª × ×ª×•× ×™×\n",
    "data = [(100, 2, 1), (200, 3, 4), (300, 4, 4)]\n",
    "df = spark.createDataFrame(data).toDF(\"col1\", \"col2\", \"col3\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×¤×¢×•×œ×•×ª ××¨×™×ª×ž×˜×™×•×ª\n",
    "df.select(df.col1 + df.col2).show()\n",
    "df.select(df.col1 - df.col2).show()\n",
    "df.select(df.col1 * df.col2).show()\n",
    "df.select(df.col1 / df.col2).show()\n",
    "df.select(df.col1 % df.col2).show()\n",
    "df.select(df.col2 > df.col3).show()\n",
    "df.select(df.col2 < df.col3).show()\n",
    "df.select(df.col2 == df.col3).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ PySpark Column Functions\n",
    "\n",
    "×‘×•××• × ×¨××” ×—×œ×§ ×ž×”×¤×•× ×§×¦×™×•×ª ×”× ×¤×•×¦×•×ª ×‘×™×•×ª×¨ ×©×œ Column. \n",
    "\n",
    "×‘×˜×‘×œ×” ×œ×ž×˜×”, ×§×™×‘×¦×ª×™ ×¤×•× ×§×¦×™×•×ª ×§×©×•×¨×•×ª ×™×—×“ ×›×“×™ ×œ×”×§×œ, ×œ×—×¥ ×¢×œ ×”×§×™×©×•×¨ ×œ×“×•×’×ž××•×ª.\n",
    "\n",
    "### ðŸ“‹ ×˜×‘×œ×ª ×¤×•× ×§×¦×™×•×ª\n",
    "\n",
    "| ×¤×•× ×§×¦×™×” | ×ª×™××•×¨ |\n",
    "|---------|--------|\n",
    "| **alias(*alias, **kwargs)** | ×ž×¡×¤×§ alias ×œ×¢×ž×•×“×” ××• ×‘×™×˜×•×™×™× |\n",
    "| **name(*alias, **kwargs)** | `name()` ×ž×—×–×™×¨ ××•×ª×• ×“×‘×¨ ×›×ž×• `alias()` |\n",
    "| **asc()** | ×ž×—×–×™×¨ ×¡×“×¨ ×¢×•×œ×” ×©×œ ×”×¢×ž×•×“×” |\n",
    "| **asc_nulls_first()** | `asc_nulls_first()` ×ž×—×–×™×¨ null values ×ª×—×™×œ×” ×•××– non-null values |\n",
    "| **asc_nulls_last()** | `asc_nulls_last()` - ×ž×—×–×™×¨ null values ××—×¨×™ non-null values |\n",
    "| **astype(dataType)** | ×ž×©×ž×© ×œ-cast ×˜×™×¤×•×¡ ×”× ×ª×•× ×™× ×œ×˜×™×¤×•×¡ ××—×¨ |\n",
    "| **cast(dataType)** | `astype()` ×ž×—×–×™×¨ ××•×ª×• ×“×‘×¨ ×›×ž×• `cast()` |\n",
    "| **between(lowerBound, upperBound)** | ×‘×•×“×§ ×× ×¢×¨×›×™ ×”×¢×ž×•×“×•×ª ×‘×™×Ÿ lower ×•-upper bound. ×ž×—×–×™×¨ ×¢×¨×š ×‘×•×œ×™×× ×™ |\n",
    "| **bitwiseAND(other)** | ×—×™×©×•×‘ bitwise AND, OR & XOR ×©×œ ×‘×™×˜×•×™ ×–×” ×¢× ×‘×™×˜×•×™ ××—×¨ ×‘×”×ª××ž×” |\n",
    "| **bitwiseOR(other)** | |\n",
    "| **bitwiseXOR(other)** | |\n",
    "| **contains(other)** | ×‘×•×“×§ ×× String ×ž×›×™×œ string ××—×¨ |\n",
    "| **desc()** | ×ž×—×–×™×¨ ×¡×“×¨ ×™×•×¨×“ ×©×œ ×”×¢×ž×•×“×” |\n",
    "| **desc_nulls_first()** | `desc_nulls_first()` - null values ×ž×•×¤×™×¢×™× ×œ×¤× ×™ non-null values |\n",
    "| **desc_nulls_last()** | `desc_nulls_last()` - null values ×ž×•×¤×™×¢×™× ××—×¨×™ non-null values |\n",
    "| **startswith(other)** | String ×ž×ª×—×™×œ ×‘-. ×ž×—×–×™×¨ ×‘×™×˜×•×™ ×‘×•×œ×™×× ×™ |\n",
    "| **endswith(other)** | String ×ž×¡×ª×™×™× ×‘-. ×ž×—×–×™×¨ ×‘×™×˜×•×™ ×‘×•×œ×™×× ×™ |\n",
    "| **eqNullSafe(other)** | Equality test ×©×‘×˜×•×— ×œ-null values |\n",
    "| **getField(name)** | ×ž×—×–×™×¨ field ×œ×¤×™ ×©× ×‘-StructField ×•×œ×¤×™ key ×‘-Map |\n",
    "| **getItem(key)** | ×ž×—×–×™×¨ values ×ž-Map/Key ×‘×ž×™×§×•× ×©×¡×•×¤×§ |\n",
    "| **isNotNull()** | `isNotNull()` - ×ž×—×–×™×¨ True ×× ×”×‘×™×˜×•×™ ×”× ×•×›×—×™ ×”×•× NOT null |\n",
    "| **isNull()** | `isNull()` - ×ž×—×–×™×¨ True ×× ×”×‘×™×˜×•×™ ×”× ×•×›×—×™ ×”×•× null |\n",
    "| **isin(*cols)** | ×‘×™×˜×•×™ ×‘×•×œ×™×× ×™ ×©×ž×•×¢×¨×š ×œ-true ×× ×”×¢×¨×š ×©×œ ×‘×™×˜×•×™ ×–×” ×›×œ×•×œ ×‘×¢×¨×›×™× ×”×ž×•×¢×¨×›×™× ×©×œ ×”××¨×’×•×ž× ×˜×™× |\n",
    "| **like(other)** | ×“×•×ž×” ×œ×‘×™×˜×•×™ SQL like |\n",
    "| **rlike(other)** | ×“×•×ž×” ×œ×‘×™×˜×•×™ SQL RLIKE (LIKE ×¢× Regex) |\n",
    "| **over(window)** | ×ž×©×ž×© ×¢× window column |\n",
    "| **substr(startPos, length)** | ×ž×—×–×™×¨ Column ×©×”×•× substring ×©×œ ×”×¢×ž×•×“×” |\n",
    "| **when(condition, value)** | ×“×•×ž×” ×œ-SQL CASE WHEN, ×ž×‘×¦×¢ ×¨×©×™×ž×ª ×ª× ××™× ×•×ž×—×–×™×¨ ××—×“ ×ž×ž×¡×¤×¨ ×‘×™×˜×•×™×™ ×ª×•×¦××” ××¤×©×¨×™×™× |\n",
    "| **otherwise(value)** | |\n",
    "| **dropFields(*fieldNames)** | ×ž×©×ž×© ×œ×”×¡×¨×ª fields ×‘-StructType ×œ×¤×™ ×©× |\n",
    "| **withField(fieldName, col)** | ×‘×™×˜×•×™ ×©×ž×•×¡×™×£/×ž×—×œ×™×£ field ×‘-StructType ×œ×¤×™ ×©× |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ×“×•×’×ž××•×ª ×œ×¤×•× ×§×¦×™×•×ª Column ×‘-PySpark\n",
    "\n",
    "×‘×•××• × ×™×¦×•×¨ DataFrame ×¤×©×•×˜ ×œ×¢×‘×•×“×” ×¢× ×“×•×’×ž××•×ª PySpark SQL Column. \n",
    "\n",
    "×œ×¨×•×‘ ×”×“×•×’×ž××•×ª ×œ×ž×˜×”, ××ª×™×™×—×¡ ×œ××•×‘×™×™×§×˜ DataFrame ×‘×©× (df) ×›×“×™ ×œ×§×‘×œ ××ª ×”×¢×ž×•×“×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×›× ×ª DataFrame ×œ×“×•×’×ž××•×ª\n",
    "data = [\n",
    "    (\"James\", \"Bond\", \"100\", None),\n",
    "    (\"Ann\", \"Varsa\", \"200\", \"F\"),\n",
    "    (\"Tom Cruise\", \"XXX\", \"400\", \"\"),\n",
    "    (\"Tom Brand\", None, \"400\", \"M\")\n",
    "]\n",
    "\n",
    "columns = [\"fname\", \"lname\", \"id\", \"gender\"]\n",
    "df = spark.createDataFrame(data, columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 alias() - ×”×’×“×¨×ª ×©× ×œ×¢×ž×•×“×”\n",
    "\n",
    "×‘×“×•×’×ž×” ×œ×ž×˜×”, `df.fname` ×ž×ª×™×™×—×¡ ×œ××•×‘×™×™×§×˜ Column ×•-`alias()` ×”×™× ×¤×•× ×§×¦×™×” ×©×œ ×”-Column ×œ×ª×ª ×©× ×—×œ×•×¤×™.\n",
    "\n",
    "×›××Ÿ, ×¢×ž×•×“×ª `fname` ×”×©×ª× ×ª×” ×œ-`first_name` ×•-`lname` ×œ-`last_name`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# alias - ×©×™× ×•×™ ×©× ×¢×ž×•×“×”\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df.select(\n",
    "    df.fname.alias(\"first_name\"),\n",
    "    df.lname.alias(\"last_name\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×“×•×’×ž×” × ×•×¡×¤×ª:**\n",
    "\n",
    "×‘×“×•×’×ž×” ×”×©× ×™×™×” ×”×©×ª×ž×©×ª×™ ×‘-**PySpark expr() function ×œ×©×¨×©×•×¨ ×¢×ž×•×“×•×ª** ×•×©×ž×ª×™ ×œ×¢×ž×•×“×” ×©× `fullName`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×¨×©×•×¨ ×¢×ž×•×“×•×ª\n",
    "df.select(\n",
    "    expr(\"fname ||','|| lname\").alias(\"fullName\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 asc() & desc() - ×ž×™×•×Ÿ DataFrame\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª `asc`, `desc` ×ž×©×ž×©×•×ª ×œ×ž×™×•×Ÿ DataFrame ×‘×¡×“×¨ ×¢×•×œ×” ×•×™×•×¨×“ ×‘×”×ª××ž×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×ž×™×•×Ÿ ×‘×¡×“×¨ ×¢×•×œ×” ×•×™×•×¨×“\n",
    "df.sort(df.fname.asc()).show()\n",
    "df.sort(df.fname.desc()).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 cast() & astype() - ×”×ž×¨×ª ×˜×™×¤×•×¡ × ×ª×•× ×™×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# cast - ×”×ž×¨×ª ×˜×™×¤×•×¡\n",
    "df.select(df.fname, df.id.cast(\"int\")).printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 between() - ×‘×“×™×§×ª ×˜×•×•×— ×¢×¨×›×™×\n",
    "\n",
    "×ž×—×–×™×¨ ×‘×™×˜×•×™ ×‘×•×œ×™×× ×™ ×›××©×¨ ×¢×¨×š ×¢×ž×•×“×” ×‘×™×Ÿ lower ×•-upper bound."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# between\n",
    "df.filter(df.id.between(100, 300)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 contains()\n",
    "\n",
    "×‘×•×“×§ ×× ×¢×¨×š ×¢×ž×•×“×ª DataFrame ×ž×›×™×œ ×¢×¨×š string ×©×¦×•×™×Ÿ ×‘×¤×•× ×§×¦×™×” ×–×•."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# contains\n",
    "df.filter(df.fname.contains(\"Cruise\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 startswith() & endswith()\n",
    "\n",
    "×‘×•×“×§ ×× ×”×¢×¨×š ×©×œ ×¢×ž×•×“×ª DataFrame ×ž×ª×—×™×œ ×¢× (startsWith) ×•×ž×¡×ª×™×™× ×¢× (endsWith) ×”-String."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# startswith, endswith\n",
    "df.filter(df.fname.startswith(\"T\")).show()\n",
    "df.filter(df.fname.endswith(\"Cruise\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 eqNullSafe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# eqNullSafe - ×‘×“×™×§×” ×‘×˜×•×—×” ×œnull\n",
    "df.filter(df.lname.eqNullSafe(None)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 isNull & isNotNull() - ×‘×“×™×§×ª NULL\n",
    "\n",
    "×‘×•×“×§ ×× ×œ×¢×ž×•×“×ª DataFrame ×™×© NULL ××• ×¢×¨×›×™ non NULL."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# isNull & isNotNull\n",
    "df.filter(df.lname.isNull()).show()\n",
    "df.filter(df.lname.isNotNull()).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 like() & rlike() - ×“×•×ž×” ×œ×‘×™×˜×•×™ SQL LIKE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# like & rlike\n",
    "df.select(\n",
    "    df.fname, df.lname, df.id\n",
    ").filter(df.fname.like(\"%om\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 substr() - ×”×—×–×¨×ª substring\n",
    "\n",
    "×ž×—×–×™×¨ Column ××—×¨×™ ×§×‘×œ×ª sub string ×ž×”-Column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# substr\n",
    "df.select(df.fname.substr(1, 2).alias(\"substr\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.11 when() & otherwise() - CASE WHEN ×‘-SQL\n",
    "\n",
    "×–×” ×“×•×ž×” ×œ-SQL Case When, ×ž×‘×¦×¢ ×¨×¦×£ ×©×œ ×‘×™×˜×•×™×™× ×¢×“ ×©×”×•× ×ª×•×× ×ª× ××™ ×•×ž×—×–×™×¨ ×¢×¨×š ×›××©×¨ ×ª× ××™ ×ª×•××."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# when & otherwise\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df.select(\n",
    "    df.fname,\n",
    "    df.lname,\n",
    "    when(df.gender == \"M\", \"Male\")\n",
    "        .when(df.gender == \"F\", \"Female\")\n",
    "        .when(df.gender == \"\", \"\")\n",
    "        .otherwise(df.gender).alias(\"new_gender\")\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.12 isin() - ×‘×“×™×§×” ×× ×¢×¨×š × ×ž×¦× ×‘×¨×©×™×ž×”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# isin\n",
    "li = [\"100\", \"200\"]\n",
    "df.select(\n",
    "    df.fname, df.lname, df.id\n",
    ").filter(df.id.isin(li)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.13 getField() - ×§×‘×œ×ª ×¢×¨×š ×œ×¤×™ key\n",
    "\n",
    "×œ×§×‘×œ×ª ×”×¢×¨×š ×œ×¤×™ key ×ž-MapType column ×•×œ×¤×™ struct child name ×ž×¢×ž×•×“×ª StructType.\n",
    "\n",
    "×©××¨ ×”×¤×•× ×§×¦×™×•×ª ×œ×ž×˜×” ×¤×•×¢×œ×•×ª ×¢×œ List, Map ×•-Struct data structures.\n",
    "\n",
    "×œ×ž×™×“×¢ × ×•×¡×£ ×”×ª×™×™×¢×¥ ×¢×:\n",
    "- **PySpark ArrayType Column on DataFrame Examples**\n",
    "- **PySpark MapType Examples**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, MapType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"StructArrayMapExample\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    ((\"James\", \"Bond\"), [\"Java\", \"C#\"], {\"hair\": \"black\", \"eye\": \"brown\"}),\n",
    "    ((\"Ann\", \"Varsa\"), [\"Python\", \"Scala\"], {\"hair\": \"red\", \"eye\": \"grey\"}),\n",
    "    ((\"Tom Cruise\", \"\"), [\"Python\", \"Scala\"], {\"hair\": \"red\", \"eye\": \"grey\"}),\n",
    "    ((\"Tom Brand\", None), [\"Java\", \"Ruby\"], {\"hair\": \"black\", \"eye\": \"blue\"})\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"fname\", StringType(), True),\n",
    "        StructField(\"lname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"languages\", ArrayType(StringType()), True),\n",
    "    StructField(\"properties\", MapType(StringType(), StringType()), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×“×•×’×ž×ª getField ×ž-MapType:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# getField ×ž-MapType\n",
    "# df.select(df.properties.getField(\"hair\")).show()\n",
    "\n",
    "# getField ×ž-Struct\n",
    "df.select(df.name.getField(\"fname\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.14 getItem() - ×§×‘×œ×ª ×¢×¨×š ×œ×¤×™ ××™× ×“×§×¡\n",
    "\n",
    "×œ×§×‘×œ×ª ×”×¢×¨×š ×œ×¤×™ ××™× ×“×§×¡ ×ž-MapType ××• ArrayType ×•-any key ×¢×‘×•×¨ MapType column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# getItem() ×ž×©×ž×© ×¢× ArrayType\n",
    "# df.select(df.languages.getItem(1)).show()\n",
    "\n",
    "# getItem() ×ž×©×ž×© ×¢× MapType\n",
    "df.select(df.properties.getItem(\"hair\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.15 dropFields()\n",
    "\n",
    "×ž×©×ž×© ×œ×”×¡×¨×ª fields ×ž-StructType."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# dropFields - ×”×¡×¨×ª ×©×“×•×ª\n",
    "df2 = df.withColumn(\"name\", df.name.dropFields(\"lname\"))\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.16 withField()\n",
    "\n",
    "×ž×©×ž×© ×œ×”×•×¡×¤×ª ××• ×”×—×œ×¤×ª field ×‘-StructType."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# withField - ×”×•×¡×¤×ª/×”×—×œ×¤×ª ×©×“×”\n",
    "#TO-DO getting runtime error"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.17 over() - ×©×™×ž×•×© ×¢× Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# over() - Window Functions\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, size, col\n",
    "\n",
    "# ×—×œ×•×Ÿ ×©×ž×ž×™×™×Ÿ ×œ×¤×™ ×ž×¡×¤×¨ ×”×©×¤×•×ª\n",
    "windowSpec = Window.orderBy(size(col(\"languages\")).desc())\n",
    "\n",
    "df4 = df.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "df4.show(truncate=False) ,row_number().over(windowSpec)\n",
    "df4.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Happy Learning !!** ðŸŽ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ ×¡×™×›×•×\n",
    "\n",
    "×‘×ž××ž×¨ ×–×” ×›×™×¡×™× ×•:\n",
    "\n",
    "### âœ… ×ž×” ×œ×ž×“× ×•:\n",
    "\n",
    "1. **×™×¦×™×¨×ª Column Object** - ×“×¨×›×™× ×©×•× ×•×ª ×œ×™×¦×™×¨×” ×•×’×™×©×”\n",
    "2. **Column Operators** - ×¤×¢×•×œ×•×ª ××¨×™×ª×ž×˜×™×•×ª ×•×”×©×•×•××”\n",
    "3. **Column Functions** - ×ž×’×•×•×Ÿ ×¨×—×‘ ×©×œ ×¤×•× ×§×¦×™×•×ª ×©×™×ž×•×©×™×•×ª\n",
    "4. **×¢×‘×•×“×” ×¢× ×ž×‘× ×™× ×ž×•×¨×›×‘×™×** - Struct, Array, Map\n",
    "\n",
    "### ðŸŽ¯ × ×§×•×“×•×ª ×ž×¤×ª×—:\n",
    "\n",
    "- ×ž×—×œ×§×ª Column ×”×™× ×‘×¡×™×¡ ×œ×¢×‘×•×“×” ×¢× DataFrame\n",
    "- ×¨×•×‘ ×”×¤×•× ×§×¦×™×•×ª ×ž×—×–×™×¨×•×ª Column ×—×“×© (immutable)\n",
    "- × ×™×ª×Ÿ ×œ×©×œ×‘ ×¤×•× ×§×¦×™×•×ª ×•××•×¤×¨×˜×•×¨×™× ×™×—×“\n",
    "- ×—×©×•×‘ ×œ×”×‘×™×Ÿ ××ª ×”×”×‘×“×œ ×‘×™×Ÿ transformation ×œ-action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š ×ž××ž×¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **PySpark JSON Functions with Examples**\n",
    "- **PySpark Where Filter Function | Multiple Conditions**\n",
    "- **PySpark Groupby on Multiple Columns**\n",
    "- **PySpark alias() Column & DataFrame Examples**\n",
    "- **PySpark SparkContext Explained**\n",
    "- **PySpark Check Column Exists in DataFrame**\n",
    "- **PySpark Convert DataFrame Columns to MapType (Dict)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”— ×ž×§×•×¨×•×ª\n",
    "\n",
    "**×ž×§×•×¨ ×”×ž×“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©×ž×™:**\n",
    "- [PySpark Column Class Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/column.html)\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™×ž×•×“ PySpark!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
