{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "××§×•×¨: [Spark By Examples - Convert PySpark RDD to DataFrame\n",
    "](https://sparkbyexamples.com/pyspark/convert-pyspark-rdd-to-dataframe/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”„ ×”××¨×ª PySpark RDD ×œ-DataFrame\n",
    "\n",
    "**×ª××¨×™×š:** 27 ×‘××¨×¥, 2024  \n",
    "**×–××Ÿ ×§×¨×™××” ××©×•×¢×¨:** 6 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "×‘-PySpark, ×¤×•× ×§×¦×™×™×ª `toDF()` ×©×œ ×”-RDD ××©××©×ª ×œ×”××¨×ª RDD ×œ-DataFrame. \n",
    "\n",
    "**×œ××” ×œ×”××™×¨ RDD ×œ-DataFrame?**\n",
    "\n",
    "×× ×• ×¦×¨×™×›×™× ×œ×”××™×¨ RDD ×œ-DataFrame ××›×™×•×•×Ÿ ×©-DataFrame ××¡×¤×§ ×™×•×ª×¨ ×™×ª×¨×•× ×•×ª ×××©×¨ RDD. ×œ×“×•×’××”:\n",
    "\n",
    "- ğŸ“Š **DataFrame** ×”×•× ××•×¡×£ ××‘×•×–×¨ ×©×œ × ×ª×•× ×™× ×××•×¨×’×Ÿ ×œ×¢××•×“×•×ª ×¢× ×©××•×ª\n",
    "- ğŸ—„ï¸ ×“×•××” ×œ×˜×‘×œ××•×ª ×‘××¡×“×™ × ×ª×•× ×™×\n",
    "- âš¡ ××¡×¤×§ ××•×¤×˜×™××™×–×¦×™×” ×•×©×™×¤×•×¨×™ ×‘×™×¦×•×¢×™×\n",
    "- ğŸ› ï¸ API × ×•×— ×™×•×ª×¨ ×œ×¢×‘×•×“×” ×¢× × ×ª×•× ×™× ××•×‘× ×™×\n",
    "\n",
    "### ğŸ“‘ ×ª×•×›×Ÿ ×”×¢× ×™×™× ×™×:\n",
    "\n",
    "1. ×™×¦×™×¨×ª PySpark RDD\n",
    "2. ×”××¨×ª PySpark RDD ×œ-DataFrame\n",
    "   - ×©×™××•×© ×‘-`toDF()`\n",
    "   - ×©×™××•×© ×‘-`createDataFrame()`\n",
    "   - ×©×™××•×© ×‘-`createDataFrame()` ×¢× StructType schema\n",
    "3. ×“×•×’××” ××œ××”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ×™×¦×™×¨×ª PySpark RDD\n",
    "\n",
    "×¨××©×™×ª, ×‘×•××• × ×™×¦×•×¨ RDD ×¢×œ ×™×“×™ ×”×¢×‘×¨×ª ××•×‘×™×™×§×˜ ×¨×©×™××ª Python ×œ×¤×•× ×§×¦×™×” `sparkContext.parallelize()`.\n",
    "\n",
    "× ×¦×˜×¨×š ××ª ××•×‘×™×™×§×˜ ×”-`rdd` ×”×–×” ×œ×›×œ ×”×“×•×’×××•×ª ×©×œ× ×• ×œ×”×œ×Ÿ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ ×”×’×“×¨×ª ×”×¡×‘×™×‘×” ×•×™×¦×™×¨×ª RDD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# ×™×¦×™×¨×ª × ×ª×•× ×™× ×œ×“×•×’××”\n",
    "dept = [(\"Finance\", 10), (\"Marketing\", 20), (\"Sales\", 30), (\"IT\", 40)]\n",
    "\n",
    "# ×™×¦×™×¨×ª RDD\n",
    "rdd = spark.sparkContext.parallelize(dept)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "×‘-PySpark, ×›××©×¨ ×™×© ×œ×š × ×ª×•× ×™× ×‘×¨×©×™××”, ×›×œ×•××¨ ×™×© ×œ×š ××•×¡×£ ×©×œ × ×ª×•× ×™× ×‘×–×™×›×¨×•×Ÿ ×”-driver ×©×œ PySpark, ×›××©×¨ ××ª×” ×™×•×¦×¨ RDD, ×”××•×¡×£ ×”×–×” ×”×•×œ×š ×œ×”×™×•×ª **××§×•×‘×œ** (parallelized).\n",
    "\n",
    "×”××©××¢×•×ª ×”×™× ×©×”× ×ª×•× ×™× ××ª×¤×–×¨×™× ×¢×œ ×¤× ×™ ××¡×¤×¨ workers ×›×“×™ ×œ××¤×©×¨ ×¢×™×‘×•×“ ××§×‘×™×œ×™."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ×”××¨×ª PySpark RDD ×œ-DataFrame\n",
    "\n",
    "×”××¨×ª PySpark RDD ×œ-DataFrame ×™×›×•×œ×” ×œ×”×ª×‘×¦×¢ ×‘×××¦×¢×•×ª `toDF()`, `createDataFrame()`. \n",
    "\n",
    "×‘×—×œ×§ ×–×”, ××¡×‘×™×¨ ××ª ×©×ª×™ ×”×©×™×˜×•×ª ×”××œ×”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ×©×™××•×© ×‘×¤×•× ×§×¦×™×” `rdd.toDF()`\n",
    "\n",
    "PySpark ××¡×¤×§ ×¤×•× ×§×¦×™×” `toDF()` ×‘-RDD ×©× ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×” ×›×“×™ ×œ×”××™×¨ RDD ×œ-DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×” ×¤×©×•×˜×” ×œ-DataFrame\n",
    "df = rdd.toDF()\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- _1: string (nullable = true)\n",
    " |-- _2: long (nullable = true)\n",
    "\n",
    "+----------+---+\n",
    "|_1        |_2 |\n",
    "+----------+---+\n",
    "|Finance   |10 |\n",
    "|Marketing |20 |\n",
    "|Sales     |30 |\n",
    "|IT        |40 |\n",
    "+----------+---+\n",
    "```\n",
    "\n",
    "×›×‘×¨×™×¨×ª ××—×“×œ, ×¤×•× ×§×¦×™×” `toDF()` ×™×•×¦×¨×ª ×©××•×ª ×¢××•×“×•×ª ×›-\"_1\" ×•-\"_2\". ×§×˜×¢ ×”×§×•×“ ×”×–×” ×× ×™×‘ ××ª ×”-schema ×œ×”×œ×Ÿ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ·ï¸ ×”×•×¡×¤×ª ×©××•×ª ×¢××•×“×•×ª ××•×ª×××™×\n",
    "\n",
    "×œ-`toDF()` ×™×© signature × ×•×¡×£ ×©××§×‘×œ ××¨×’×•×× ×˜×™× ×›×“×™ ×œ×”×’×“×™×¨ ×©××•×ª ×¢××•×“×•×ª ×›×¤×™ ×©××•×¦×’ ×œ×”×œ×Ÿ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×” ×œ-DataFrame ×¢× ×©××•×ª ×¢××•×“×•×ª ××•×ª×××™×\n",
    "deptColumns = [\"dept_name\", \"dept_id\"]\n",
    "df2 = rdd.toDF(deptColumns)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- dept_name: string (nullable = true)\n",
    " |-- dept_id: long (nullable = true)\n",
    "\n",
    "+---------+-------+\n",
    "|dept_name|dept_id|\n",
    "+---------+-------+\n",
    "|Finance  |10     |\n",
    "|Marketing|20     |\n",
    "|Sales    |30     |\n",
    "|IT       |40     |\n",
    "+---------+-------+\n",
    "```\n",
    "\n",
    "×–×” ××“×¤×™×¡ ××ª ×”-schema ×œ××˜×”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 ×©×™××•×© ×‘×¤×•× ×§×¦×™×” `createDataFrame()` ×©×œ PySpark\n",
    "\n",
    "××—×œ×§×” `SparkSession` ××¡×¤×§×ª ×©×™×˜×” `createDataFrame()` ×œ×™×¦×™×¨×ª DataFrame ×•×”×™× ××§×‘×œ×ª ××•×‘×™×™×§×˜ `rdd` ×›××¨×’×•×× ×˜."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-createDataFrame\n",
    "deptDF = spark.createDataFrame(rdd, schema=deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "×©×™×˜×” ×–×• ×× ×™×‘×” ××ª ××•×ª×” ×ª×•×¦××” ×›××• ×œ××¢×œ×” - DataFrame ×¢× ×©××•×ª ×”×¢××•×“×•×ª ×©×”×’×“×¨× ×•."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ×©×™××•×© ×‘-`createDataFrame()` ×¢× StructType schema\n",
    "\n",
    "×›××©×¨ ××ª×” ××¡×™×§ ××ª ×”-schema, ×›×‘×¨×™×¨×ª ××—×“×œ ×˜×™×¤×•×¡ ×”× ×ª×•× ×™× ×©×œ ×”×¢××•×“×•×ª × ×’×–×¨ ××”× ×ª×•× ×™× ×•××’×“×™×¨ nullable ×œ-true ×œ×›×œ ×”×¢××•×“×•×ª.\n",
    "\n",
    "×× ×—× ×• ×™×›×•×œ×™× ×œ×©× ×•×ª ××ª ×”×”×ª× ×”×’×•×ª ×”×–×• ×¢×œ ×™×“×™ ××¡×¤×§×ª **schema** ×‘×××¦×¢×•×ª **StructType** â€“ ×©×‘×• ×× ×—× ×• ×™×›×•×œ×™× ×œ×¦×™×™×Ÿ ×©× ×¢××•×“×”, ×˜×™×¤×•×¡ × ×ª×•× ×™× ×•-nullable ×œ×›×œ field/column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ×”×’×“×¨×ª Schema ××¤×•×¨×© ×¢× StructType\n",
    "\n",
    "×× ××ª×” ×¨×•×¦×” ×œ×“×¢×ª ×¢×•×“ ×¢×œ StructType, ×× × ×¢×‘×•×¨ ×“×¨×š **how to use StructType and StructField to define the custom schema** (××“×¨×™×š × ×¤×¨×“)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# ×”×’×“×¨×ª schema ××¤×•×¨×©\n",
    "deptSchema = StructType([\n",
    "    StructField(\"dept_name\", StringType(), True),\n",
    "    StructField(\"dept_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame ×¢× Schema ××¤×•×¨×©\n",
    "deptDF1 = spark.createDataFrame(rdd, schema=deptSchema)\n",
    "deptDF1.printSchema()\n",
    "deptDF1.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×™×ª×¨×•× ×•×ª ×©×™××•×© ×‘-StructType:**\n",
    "\n",
    "- ğŸ¯ **×©×œ×™×˜×” ××œ××”** ×¢×œ ×˜×™×¤×•×¡×™ ×”× ×ª×•× ×™×\n",
    "- âœ… **×”×’×“×¨×ª nullable** ×œ×›×œ ×¢××•×“×”\n",
    "- ğŸ“‹ **×ª×™×¢×•×“ ×‘×¨×•×¨** ×©×œ ××‘× ×” ×”× ×ª×•× ×™×\n",
    "- ğŸ”’ **××›×™×¤×ª ×¡×›×™××”** ××•×§×“××ª\n",
    "\n",
    "×–×” ×’× ×× ×™×‘ ××ª ××•×ª×” ×ª×•×¦××”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ×¡×™×›×•×\n",
    "\n",
    "×‘××××¨ ×–×”, ×œ××“×ª ×›×™×¦×“ ×œ×”××™×¨ PySpark RDD ×œ-DataFrame. \n",
    "\n",
    "× ×¦×˜×¨×š ×–××ª ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×‘×–××Ÿ ×¢×‘×•×“×” ×‘-PySpark ××›×™×•×•×Ÿ ×©××œ×” ××¡×¤×§×™× ××•×¤×˜×™××™×–×¦×™×” ×•×‘×™×¦×•×¢×™× ××¢×œ RDD.\n",
    "\n",
    "### âœ… ×¡×™×›×•× ×”×©×™×˜×•×ª:\n",
    "\n",
    "| ×©×™×˜×” | ×ª×™××•×¨ | ××ª×™ ×œ×”×©×ª××© |\n",
    "|------|-------|------------|\n",
    "| **toDF()** | ×”××¨×” ×¤×©×•×˜×” ×œ×œ× ×©××•×ª | ×œ×‘×“×™×§×•×ª ××”×™×¨×•×ª |\n",
    "| **toDF(columns)** | ×”××¨×” ×¢× ×©××•×ª ×¢××•×“×•×ª | ×›×©×™×© ×©××•×ª ×¤×©×•×˜×™× |\n",
    "| **createDataFrame()** | ×©×™×˜×” ××¤×•×¨×©×ª | ×œ×§×•×“ ×‘×¨×•×¨ ×™×•×ª×¨ |\n",
    "| **createDataFrame() + StructType** | ×©×œ×™×˜×” ××œ××” ×¢×œ Schema | ×œ×™×™×¦×•×¨, ×›×©×¦×¨×™×š ×˜×™×¤×•×¡×™ × ×ª×•× ×™× ××“×•×™×§×™× |\n",
    "\n",
    "### ğŸ¯ ×”××œ×¦×•×ª:\n",
    "\n",
    "- âœ… **×œ×™×™×¦×•×¨**: ×”×©×ª××© ×‘-StructType schema ×œ×”×’×“×¨×” ××¤×•×¨×©×ª\n",
    "- âœ… **×œ×¤×™×ª×•×—**: toDF() ××”×™×¨ ×•× ×•×—\n",
    "- âœ… **×œ×‘×™×¦×•×¢×™×**: DataFrame ×ª××™×“ ×¢×“×™×£ ×¢×œ RDD\n",
    "\n",
    "**Happy Learning !!** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **PySpark â€“ Create DataFrame with Examples**\n",
    "- **PySpark Convert DataFrame to RDD**\n",
    "- **PySpark Create RDD with Examples**\n",
    "- **PySpark RDD Actions with examples**\n",
    "- **PySpark Row using on DataFrame and RDD**\n",
    "- **PySpark â€“ Create an Empty DataFrame & RDD**\n",
    "- **PySpark parallelize() â€“ Create RDD from a list data**\n",
    "- **PySpark Replace Column Values in DataFrame**\n",
    "- **PySpark RDD Actions with examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ ×ª×’×™×•×ª (Tags)\n",
    "\n",
    "`DATAFRAME` `DATASET` `RDD` `SPARK.CREATEDATAFRAME` `TODF()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××§×•×¨×•×ª ×•××™×“×¢ × ×•×¡×£\n",
    "\n",
    "**××§×•×¨ ×”××“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©××™:**\n",
    "- [PySpark RDD Documentation](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html)\n",
    "- [PySpark DataFrame Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html)\n",
    "- [Apache Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)\n",
    "\n",
    "**×§×•×“ ××œ×:**\n",
    "- ×”×§×•×“ ×”××œ× × ×™×ª×Ÿ ×œ×”×•×¨×“×” ×-GitHub (×§×™×©×•×¨ ×‘××§×•×¨)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™××•×“ PySpark!**\n",
    "\n",
    "**âœ¨ Happy Learning !!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
