{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "××§×•×¨: [Spark By Examples - StructType & StructField Explained with Examples\n",
    "](https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ—ï¸ PySpark StructType & StructField - ×”×¡×‘×¨ ×¢× ×“×•×’×××•×ª\n",
    "\n",
    "**×ª××¨×™×š:** 12 ×‘×××™, 2024  \n",
    "**×–××Ÿ ×§×¨×™××” ××©×•×¢×¨:** 18 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "××—×œ×§×•×ª **StructType** ×•-**StructField** ×‘-PySpark ××©××©×•×ª ×œ×¦×™×•×Ÿ:\n",
    "- ğŸ“‹ ×”-schema ×”××•×ª×× ××™×©×™×ª ×œ-DataFrame\n",
    "- ğŸ—ï¸ ×™×¦×™×¨×ª ×¢××•×“×•×ª ××•×¨×›×‘×•×ª ×›××• nested struct, array ×•-map columns\n",
    "\n",
    "**StructType** ×”×•× ××•×¡×£ ×©×œ ××•×‘×™×™×§×˜×™ **StructField** ×©××’×“×™×¨:\n",
    "- ×©× ×¢××•×“×”\n",
    "- ×˜×™×¤×•×¡ × ×ª×•× ×™× ×©×œ ×¢××•×“×”\n",
    "- ×‘×•×œ×™×× ×™ ×œ×¦×™×•×Ÿ ×× ×”×¢××•×“×” ×™×›×•×œ×” ×œ×”×™×•×ª nullable ××• ×œ×\n",
    "- metadata\n",
    "\n",
    "### ğŸ’¡ × ×§×•×“×•×ª ××¤×ª×—:\n",
    "\n",
    "- **StructType** ×”×•× ××•×¡×£ ××• ×¨×©×™××” ×©×œ ××•×‘×™×™×§×˜×™ StructField\n",
    "- **×”×’×“×¨×ª DataFrame Schemas**: StructType ××©××© ×‘×“×¨×š ×›×œ×œ ×œ×”×’×“×¨×ª ×”-schema ×‘×¢×ª ×™×¦×™×¨×ª DataFrame, ×‘××™×•×—×“ ×¢×‘×•×¨ × ×ª×•× ×™× ××•×‘× ×™× ×¢× ×©×“×•×ª ××˜×™×¤×•×¡×™ × ×ª×•× ×™× ×©×•× ×™×\n",
    "- **Nested Structures**: ××ª×” ×™×›×•×œ ×œ×™×¦×•×¨ schemas ××•×¨×›×‘×™× ×¢×œ ×™×“×™ ×§×™× ×•×Ÿ StructType ×‘×ª×•×š ××•×‘×™×™×§×˜×™ StructType ××—×¨×™×, ××” ×©×××¤×©×¨ ×œ×š ×œ×™×™×¦×’ ××‘× ×™ × ×ª×•× ×™× ×”×™×¨×¨×›×™×™× ××• ××¨×•×‘×™ ×¨××•×ª\n",
    "- **Enforcing Data Structure**: ×›××©×¨ ×§×•×¨× × ×ª×•× ×™× ×××§×•×¨×•×ª ×©×•× ×™×, ×¦×™×•×Ÿ StructType ×›-schema ××‘×˜×™×— ×©×”× ×ª×•× ×™× ××ª×¤×¨×©×™× ×•××•×‘× ×™× × ×›×•×Ÿ. ×–×” ×—×©×•×‘ ×‘××™×•×—×“ ×‘×¢×ª ×˜×™×¤×•×œ ×‘× ×ª×•× ×™× ×—×¦×™-××•×‘× ×™× ××• ×—×¡×¨×™ schema ×›××• ×§×‘×¦×™ JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ×ª×•×›×Ÿ ×”×¢× ×™×™× ×™×\n",
    "\n",
    "1. ×©×™××•×© ×‘-PySpark StructType & StructField ×¢× DataFrame\n",
    "2. ×”×’×“×¨×ª Nested StructType object struct\n",
    "3. ×”×•×¡×¤×” ×•×©×™× ×•×™ struct ×©×œ DataFrame\n",
    "4. ×©×™××•×© ×‘-SQL ArrayType ×•-MapType\n",
    "5. ×™×¦×™×¨×ª StructType object struct ××§×•×‘×¥ JSON\n",
    "6. ×™×¦×™×¨×ª StructType object struct ×××—×¨×•×–×ª DDL\n",
    "7. ×‘×“×™×§×ª ×§×™×•× ×©×“×” ×‘-DataFrame\n",
    "8. ×“×•×’××” ××œ××”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ StructType - ×”×’×“×¨×ª ××‘× ×” ×”-DataFrame\n",
    "\n",
    "PySpark ××¡×¤×§ ××—×œ×§×ª `StructType` ×-`pyspark.sql.types` ×›×“×™ ×œ×”×’×“×™×¨ ××ª ××‘× ×” ×”-DataFrame.\n",
    "\n",
    "StructType ××™×™×¦×’ schema, ×©×”×•× ××•×¡×£ ×©×œ ××•×‘×™×™×§×˜×™ **StructField** ×©××’×“×™×¨×™× ×©× ×”×¢××•×“×”, ×˜×™×¤×•×¡ × ×ª×•× ×™× ×©×œ ×”×¢××•×“×”, ×‘×•×œ×™×× ×™ ×œ×¦×™×•×Ÿ ×× ×”×¢××•×“×” ×™×›×•×œ×” ×œ×”×™×•×ª nullable ××• ×œ×, ×•-metadata.\n",
    "\n",
    "### ğŸ“ ××ª×•×“×” printSchema()\n",
    "\n",
    "××ª×•×“×ª `PySpark printSchema()` ×¢×œ DataFrame ××¦×™×’×” ××ª StructType columns ×›-\"struct\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ StructField - ×”×’×“×¨×ª metadata ×©×œ DataFrame column\n",
    "\n",
    "×–×” ××™×™×¦×’ ×©×“×” ×‘-schema, ×”××›×™×œ metadata ×›××•:\n",
    "- ×©× ×”×©×“×”\n",
    "- ×˜×™×¤×•×¡ ×”× ×ª×•× ×™× ×©×œ×•\n",
    "- nullable ×©×œ ×”×©×“×”\n",
    "\n",
    "××—×œ×§×ª StructField ×’× ×—×œ×§ ×-`pyspark.sql.types`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ×©×™××•×© ×‘-PySpark StructType & StructField ×¢× DataFrame\n",
    "\n",
    "×‘×›×œ ×¤×¢× ×©×™×•×¦×¨×™× DataFrame ×‘-PySpark, schema ×©×œ DataFrame ××¡×•×§ ××•×˜×•××˜×™×ª ××”× ×ª×•× ×™× ×•××’×“×™×¨ nullable ×œ-true ×œ×›×œ ×”×¢××•×“×•×ª.\n",
    "\n",
    "×× ×—× ×• ×™×›×•×œ×™× ×œ×©× ×•×ª ××ª ×”×”×ª× ×”×’×•×ª ×”×–×• ×¢×œ ×™×“×™ ××¡×¤×§×ª **schema** ×‘×××¦×¢×•×ª **StructType** â€“ ×©×‘×• ×× ×—× ×• ×™×›×•×œ×™× ×œ×¦×™×™×Ÿ ×©× ×¢××•×“×”, ×˜×™×¤×•×¡ × ×ª×•× ×™× ×•-nullable ×œ×›×œ field/column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"James\", \"\", \"Smith\", \"36636\", \"M\", 3000),\n",
    "    (\"Michael\", \"Rose\", \"\", \"40288\", \"M\", 4000),\n",
    "    (\"Robert\", \"\", \"Williams\", \"42114\", \"M\", 4000),\n",
    "    (\"Maria\", \"Anne\", \"Jones\", \"39192\", \"F\", 4000),\n",
    "    (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"firstname\", StringType(), True),\n",
    "    StructField(\"middlename\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- firstname: string (nullable = true)\n",
    " |-- middlename: string (nullable = true)\n",
    " |-- lastname: string (nullable = true)\n",
    " |-- id: string (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    " |-- salary: integer (nullable = true)\n",
    "\n",
    "+---------+----------+--------+-----+------+------+\n",
    "|firstname|middlename|lastname|id   |gender|salary|\n",
    "+---------+----------+--------+-----+------+------+\n",
    "|James    |          |Smith   |36636|M     |3000  |\n",
    "|Michael  |Rose      |        |40288|M     |4000  |\n",
    "|Robert   |          |Williams|42114|M     |4000  |\n",
    "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
    "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
    "+---------+----------+--------+-----+------+------+\n",
    "```\n",
    "\n",
    "×–×” ××™×™×¦×¨ ××ª ×”-schema ×•×ª×•×¦××ª ×”-DataFrame ×œ××˜×”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ×”×’×“×¨×ª Nested StructType object struct\n",
    "\n",
    "×›×“×™ ×œ×”×’×“×™×¨ nested StructType ×‘-PySpark, ×”×©×ª××© ×‘-StructTypes ×¤× ×™××™×™× ×‘×ª×•×š StructFields.\n",
    "\n",
    "×›×œ nested StructType ×”×•× ××•×¡×£ ×©×œ StructFields, ×™×•×¦×¨ ××‘× ×” ×”×™×¨×¨×›×™ ×”××™×™×¦×’ complex data ×‘×ª×•×š DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ—ï¸ ×™×¦×™×¨×ª Nested Structure\n",
    "\n",
    "×‘×“×•×’××” ×œ××˜×”, ×¢××•×“×ª ×”-**\"name\"** ×”×™× ××¡×•×’ data StructType, ×”××¦×™×™× ×ª ××‘× ×” ××§×•× ×Ÿ.\n",
    "\n",
    "×”××©××¢×•×ª ×”×™× ×©×¢××•×“×ª ×”-\"name\" ×¢×¦××” ××•×¨×›×‘×ª ×××¡×¤×¨ subfields ××• attributes, ×©× ×§×¨××™× multiple subfields."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×’×“×¨×ª schema ×¢× Nested Structure\n",
    "structureData = [\n",
    "    ((\"James\", \"\", \"Smith\"), \"36636\", \"M\", 3000),\n",
    "    ((\"Michael\", \"Rose\", \"\"), \"40288\", \"M\", 4000),\n",
    "    ((\"Robert\", \"\", \"Williams\"), \"42114\", \"M\", 4000),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"39192\", \"F\", 4000),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"F\", -1)\n",
    "]\n",
    "\n",
    "structureSchema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData, schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)  # ×”×¦×’ ××ª ×›×œ ×”×¢××•×“×•×ª"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema ×¦×¤×•×™:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- name: struct (nullable = true)\n",
    " |    |-- firstname: string (nullable = true)\n",
    " |    |-- middlename: string (nullable = true)\n",
    " |    |-- lastname: string (nullable = true)\n",
    " |-- id: string (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    " |-- salary: integer (nullable = true)\n",
    "```\n",
    "\n",
    "×–×” ××™×™×¦×¨ ××ª ×”-schema ×”×‘×. ×× ×ª×©×™× ×œ×‘, ×”×¢××•×“×” `name` ×”×™× ××¡×•×’ struct ×”××›×™×œ×” ××ª ×”×¢××•×“×•×ª firstname, middlename, ×•-lastname."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ×”×•×¡×¤×” ×•×©×™× ×•×™ struct ×©×œ DataFrame\n",
    "\n",
    "×‘×××¦×¢×•×ª **PySpark SQL function struct()**, ×× ×—× ×• ×™×›×•×œ×™× ×œ×©× ×•×ª ××ª ×”-struct ×©×œ ×”-DataFrame ×”×§×™×™× ×•×œ×”×•×¡×™×£ StructType ×—×“×© ××œ×™×•.\n",
    "\n",
    "×”×“×•×’××” ×œ××˜×” ××“×’×™××” ××™×š ×œ×”×¢×ª×™×§ ××ª ×”×¢××•×“×•×ª ×××‘× ×” ××—×“ ×œ××—×¨ ×•×œ×”×•×¡×™×£ ×¢××•×“×” ×—×“×©×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×¢×“×›×•×Ÿ structtype ×§×™×™× ×‘×××¦×¢×•×ª struct\n",
    "from pyspark.sql.functions import col, struct, when\n",
    "\n",
    "updatedDF = df2.withColumn(\"OtherInfo\",\n",
    "    struct(\n",
    "        col(\"id\").alias(\"identifier\"),\n",
    "        col(\"gender\").alias(\"gender\"),\n",
    "        col(\"salary\").alias(\"salary\"),\n",
    "        when(col(\"salary\").cast(IntegerType()) < 2000, \"Low\")\n",
    "            .when(col(\"salary\").cast(IntegerType()) < 4000, \"Medium\")\n",
    "            .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "    )).drop(\"id\", \"gender\", \"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "×›××Ÿ ×–×” ××¢×ª×™×§ ××ª **\"gender\"**, **\"salary\"** ×•-**\"id\"** ×œ-struct ×—×“×© **\"OtherInfo\"** ×•××•×¡×™×£ ×¢××•×“×” ×—×“×©×” **\"Salary_Grade\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ ×©×™××•×© ×‘-SQL ArrayType ×•-MapType\n",
    "\n",
    "SQL StructType ×ª×•××š ×’× ×‘-**ArrayType** ×•-**MapType** ×›×“×™ ×œ×”×’×“×™×¨ ××ª ×¢××•×“×•×ª ×”-DataFrame ×¢×‘×•×¨:\n",
    "- ğŸ“Š ××•×¡×¤×™ array\n",
    "- ğŸ—ºï¸ ××•×¡×¤×™ map\n",
    "\n",
    "×‘×“×•×’××” ×œ××˜×”, ×¢××•×“×ª `hobbies` ××•×’×“×¨×ª ×›-ArrayType(StringType) ×•-`properties` ××•×’×“×¨×ª ×›-MapType(StringType, StringType) - ×›×œ×•××¨ ×©× ×™ key ×•-value ×›-String."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import ArrayType, MapType\n",
    "\n",
    "# ×©×™××•×© ×‘-SQL ArrayType ×•-MapType\n",
    "arrayStructureSchema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"hobbies\", ArrayType(StringType()), True),\n",
    "    StructField(\"properties\", MapType(StringType(), StringType()), True)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨ ×¢×œ ×”×˜×™×¤×•×¡×™×:**\n",
    "\n",
    "- **ArrayType(StringType())** - ××¢×¨×š ×©×œ ××—×¨×•×–×•×ª\n",
    "- **MapType(StringType(), StringType())** - ××™×¤×•×™ ×-String ×œ-String (key-value pairs)\n",
    "\n",
    "×–×” ××™×™×¦×¨ ××ª ×”-schema ×œ××˜×”. ×©×™× ×œ×‘ ×©×”×©×“×” `Hobbies` ×”×•× ××¡×•×’ array ×•-`properties` ×”×•× ××¡×•×’ map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ ×™×¦×™×¨×ª StructType object struct ××§×•×‘×¥ JSON\n",
    "\n",
    "×œ×—×œ×•×¤×™×Ÿ, ××ª×” ×™×›×•×œ ×œ×˜×¢×•×Ÿ ××ª ×”-SQL StructType schema ××§×•×‘×¥ JSON.\n",
    "\n",
    "×›×“×™ ×œ×”×¤×•×š ××ª ×–×” ×œ×¤×©×•×˜, ××§×‘×œ ××ª ×”-schema ×”× ×•×›×—×™ ×©×œ DataFrame ×‘×××¦×¢×•×ª:\n",
    "- `df2.schema.json()`\n",
    "\n",
    "××©××•×¨ ××ª ×–×” ×‘×§×•×‘×¥, ×•××©×ª××© ×‘×• ×›×“×™ ×œ×™×¦×•×¨ schema ××§×•×‘×¥ JSON ×–×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-json() ×œ×˜×¢×™× ×ª StructType\n",
    "print(df2.schema.json())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "×–×” ×× ×™×‘ JSON format schema. ××ª×” ×™×›×•×œ ×œ×©××•×¨ ×–×” ×‘×§×•×‘×¥ ×•×œ×”×©×ª××© ×‘×• ×›×©× ×—×•×¥.\n",
    "\n",
    "×œ×—×œ×•×¤×™×Ÿ, ××ª×” ×™×›×•×œ ×’× ×œ×”×©×ª××© ×‘-`df.schema.simpleString()`, ×–×” ×™×—×–×™×¨ ×¤×•×¨××˜ schema ×¤×©×•×˜ ×™×•×ª×¨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“¥ ×˜×¢×™× ×ª Schema ××§×•×‘×¥ JSON"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×˜×¢×™× ×ª json schema ×œ×™×¦×™×¨×ª DataFrame\n",
    "import json\n",
    "\n",
    "schemaFromJson = StructType.fromJson(json.loads(schema.json()))\n",
    "df3 = spark.createDataFrame(\n",
    "    spark.sparkContext.parallelize(structureData),\n",
    "    schemaFromJson\n",
    ")\n",
    "df3.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ ×™×¦×™×¨×ª StructType object struct ×××—×¨×•×–×ª DDL\n",
    "\n",
    "×›×“×™ ×œ×™×¦×•×¨ ××•×‘×™×™×§×˜ StructType, 'struct', ×-Data Definition Language (DDL) string ×‘-PySpark:\n",
    "\n",
    "×”×©×ª××© ×‘-**'StructType.fromDDL()'**. \n",
    "\n",
    "×©×™×˜×” ×–×• ××¤×¨×¡×¨×ª ××ª ××—×¨×•×–×ª ×”-DDL ×•××™×™×¦×¨×ª ××•×‘×™×™×§×˜ StructType ×©××©×§×£ ××ª ×”-schema ×©×”×•×’×“×¨ ×‘×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª StructType ×-DDL String\n",
    "ddlSchemaStr = \"\"\"\n",
    "    `fullName` STRUCT<`first`: STRING, `last`: STRING, `middle`: STRING>, \n",
    "    `age` INT, \n",
    "    `gender` STRING\n",
    "\"\"\"\n",
    "\n",
    "ddlSchema = StructType.fromDDL(ddlSchemaStr)\n",
    "print(ddlSchema)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "- `StructType.fromDDL()` - ××¤×¢× ×— ××—×¨×•×–×ª DDL ×œ×™×¦×™×¨×ª schema\n",
    "- ×™×¦×™×¨×ª schema ×“×™× ××™ ×-external sources ××• configuration files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ ×‘×“×™×§×ª ×§×™×•× ×¢××•×“×” ×‘-DataFrame\n",
    "\n",
    "×›×“×™ ×œ×‘×“×•×§ ×× ×¢××•×“×” ×§×™×™××ª ×‘-PySpark DataFrame:\n",
    "\n",
    "×”×©×ª××© ×‘×©×™×˜×ª **'contains()'** ×¢×œ attribute ×”-'columns' ×©×œ DataFrame.\n",
    "\n",
    "×œ×“×•×’××”:\n",
    "- `if \"column_name\" in df.columns`\n",
    "\n",
    "×‘×•×“×§ ×× 'column_name' ×§×™×™× ×‘-DataFrame 'df'.\n",
    "\n",
    "×œ×—×œ×•×¤×™×Ÿ, ××ª×” ×™×›×•×œ ×œ×”×©×ª××© ×‘-**'selectExpr()'** ×¢× column name ×•-**'alias()'** ×›×“×™ ×œ×™×¦×•×¨ ×¢××•×“×” ×—×“×©×” ×¢× ×©× ×©×•× ×”, ×•××– ×œ×‘×“×•×§ ×× ×”×¢××•×“×” ×”×—×“×©×” ×§×™×™××ª."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×“×™×§×” ×× ×¢××•×“×” ×§×™×™××ª\n",
    "if \"firstname\" in df.columns:\n",
    "    print(\"Column 'firstname' exists in the DataFrame.\")\n",
    "else:\n",
    "    print(\"Column 'firstname' does not exist in the DataFrame.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×—×œ×•×¤×”:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×“×™×§×ª ×§×™×•× ×¢××•×“×” ×‘×××¦×¢×•×ª contains()\n",
    "print(\"firstname\" in df.schema.fieldNames())\n",
    "print(any(f.name == \"firstname\" and isinstance(f.dataType, StringType) for f in df.schema.fields))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×“×•×’××” ×”×–×• ××—×–×™×¨×” \"true\" ×œ×©× ×™ ×”×ª×¨×—×™×©×™×.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×“×•×’××” ××œ××” ×©×œ PySpark StructType & StructField"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, MapType\n",
    "from pyspark.sql.functions import col, struct, when\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"James\", \"\", \"Smith\", \"36636\", \"M\", 3000),\n",
    "    (\"Michael\", \"Rose\", \"\", \"40288\", \"M\", 4000),\n",
    "    (\"Robert\", \"\", \"Williams\", \"42114\", \"M\", 4000),\n",
    "    (\"Maria\", \"Anne\", \"Jones\", \"39192\", \"F\", 4000),\n",
    "    (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"firstname\", StringType(), True),\n",
    "    StructField(\"middlename\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n=== Nested Structure ===\")\n",
    "structureData = [\n",
    "    ((\"James\", \"\", \"Smith\"), \"36636\", \"M\", 3000),\n",
    "    ((\"Michael\", \"Rose\", \"\"), \"40288\", \"M\", 4000),\n",
    "    ((\"Robert\", \"\", \"Williams\"), \"42114\", \"M\", 4000),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"39192\", \"F\", 4000),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"F\", -1)\n",
    "]\n",
    "\n",
    "structureSchema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData, schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n=== ×¢×“×›×•×Ÿ Structure ===\")\n",
    "updatedDF = df2.withColumn(\"OtherInfo\",\n",
    "    struct(\n",
    "        col(\"id\").alias(\"identifier\"),\n",
    "        col(\"gender\").alias(\"gender\"),\n",
    "        col(\"salary\").alias(\"salary\"),\n",
    "        when(col(\"salary\").cast(IntegerType()) < 2000, \"Low\")\n",
    "            .when(col(\"salary\").cast(IntegerType()) < 4000, \"Medium\")\n",
    "            .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "    )).drop(\"id\", \"gender\", \"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n=== Array & Map ===\")\n",
    "arrayStructureSchema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"hobbies\", ArrayType(StringType()), True),\n",
    "    StructField(\"properties\", MapType(StringType(), StringType()), True)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**××¦× ×“×•×’××” ××œ××” ×‘-GitHub project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ×¡×™×›×•× (Conclusion)\n",
    "\n",
    "×œ×¡×™×›×•×, ××—×œ×§×•×ª **StructType** ×•-**StructField** ×©×œ PySpark ××¦×™×¢×•×ª ×›×œ×™× ×¢×•×¦××ª×™×™× ×œ×”×’×“×¨×” ×•× ×™×”×•×œ schemas ×©×œ DataFrame.\n",
    "\n",
    "**StructType** ××¡×¤×§ ×’×™×©×” ××•×‘× ×™×ª ×œ××¨×’×•×Ÿ × ×ª×•× ×™×, ×××¤×©×¨ ×¦×™×•×Ÿ ××“×•×™×§ ×©×œ:\n",
    "- ×©××•×ª ×¢××•×“×•×ª\n",
    "- ×˜×™×¤×•×¡×™ × ×ª×•× ×™×\n",
    "- nullability\n",
    "\n",
    "**StructField** ×××¤×©×¨ ×©×œ×™×˜×” ×¢×“×™× ×” ×¢×œ ×©×“×•×ª ×‘×•×“×“×™× ×‘×ª×•×š ×”-schema, ×›×•×œ×œ:\n",
    "- ××‘× ×™× ××§×•× × ×™×\n",
    "- ×˜×™×¤×•×¡×™ × ×ª×•× ×™× ××•×¨×›×‘×™×\n",
    "\n",
    "### âœ… ××” ×œ××“× ×•:\n",
    "\n",
    "1. **×™×¦×™×¨×ª Schema ××¤×•×¨×©** - ×©×œ×™×˜×” ××œ××” ×¢×œ ××‘× ×” ×”× ×ª×•× ×™×\n",
    "2. **Nested Structures** - ×™×¦×™×¨×ª ×”×™×¨×¨×›×™×•×ª ××•×¨×›×‘×•×ª\n",
    "3. **Array & Map Types** - ×¢×‘×•×“×” ×¢× ××•×¡×¤×™×\n",
    "4. **Schema ×-JSON/DDL** - ×˜×¢×™× ×” ×“×™× ××™×ª\n",
    "5. **×‘×“×™×§×ª ×§×™×•× ×©×“×•×ª** - validation\n",
    "\n",
    "×¢×œ ×™×“×™ ××™× ×•×£ StructType ×•-StructField, ××©×ª××©×™× ×™×›×•×œ×™×:\n",
    "- âœ… ×œ×‘× ×•×ª ×•×œ×ª×¤×¢×œ DataFrames ×‘×™×¢×™×œ×•×ª\n",
    "- âœ… ×œ×”×‘×˜×™×— ×¢×§×‘×™×•×ª × ×ª×•× ×™×\n",
    "- âœ… ×œ××¤×©×¨ ××™× ×˜×’×¨×¦×™×” ×—×œ×§×” ×¢× ××§×•×¨×•×ª × ×ª×•× ×™× ××’×•×•× ×™×\n",
    "\n",
    "**Happy Learning !!** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **PySpark Select Nested struct Columns**\n",
    "- **PySpark Convert StructType (struct) to Dictionary/MapType (map)**\n",
    "- **PySpark alias() Column & DataFrame Examples**\n",
    "- **PySpark SparkContext Explained**\n",
    "- **PySpark Check Column Exists in DataFrame**\n",
    "- **PySpark Parse JSON from String Column | TEXT File**\n",
    "- **PySpark MapType (Dict) Usage with Examples**\n",
    "- **PySpark Convert DataFrame Columns to MapType (Dict)**\n",
    "- **PySpark Create DataFrame From Dictionary (Dict)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ ×ª×’×™×•×ª (Tags)\n",
    "\n",
    "`DATATYPE` `MAPTYPE` `PYSPARK.SCHEMA` `SCHEMA` `STRUCTFIELD` `STRUCTTYPE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××§×•×¨×•×ª\n",
    "\n",
    "**××§×•×¨ ×”××“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©××™:**\n",
    "- [PySpark StructType Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.StructType.html)\n",
    "- [PySpark StructField Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.StructField.html)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™××•×“ PySpark!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
