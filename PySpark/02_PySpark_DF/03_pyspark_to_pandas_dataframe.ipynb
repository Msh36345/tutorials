{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "××§×•×¨: [Spark By Examples - Convert PySpark DataFrame to Pandas\n",
    "](https://sparkbyexamples.com/pandas/convert-pyspark-dataframe-to-pandas/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¼ ×”××¨×ª PySpark DataFrame ×œ-Pandas DataFrame\n",
    "\n",
    "**×ª××¨×™×š:** 12 ×‘×™×•× ×™, 2025  \n",
    "**×–××Ÿ ×§×¨×™××” ××©×•×¢×¨:** 13 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "(Spark ×¢× Python) PySpark DataFrame × ×™×ª×Ÿ ×œ×”××¨×” ×œ-**Python pandas DataFrame** ×‘×××¦×¢×•×ª ×¤×•× ×§×¦×™×” `toPandas()`.\n",
    "\n",
    "×‘××××¨ ×–×”, ××¡×‘×™×¨ ×›×™×¦×“ ×œ×™×¦×•×¨ Pandas DataFrame ×-PySpark (Spark) DataFrame ×¢× ×“×•×’×××•×ª.\n",
    "\n",
    "### ğŸ”„ ×”×‘×“×œ×™× ×¢×™×§×¨×™×™× ×‘×™×Ÿ Pandas ×œ-PySpark\n",
    "\n",
    "×œ×¤× ×™ ×©× ×ª×—×™×œ, ×‘×•××• × ×‘×™×Ÿ ××ª ×”×”×‘×“×œ×™× ×”×¢×™×§×¨×™×™× ×‘×™×Ÿ Pandas ×œ-PySpark:\n",
    "\n",
    "**×¤×¢×•×œ×•×ª ×¢×œ PySpark ×¨×¦×•×ª ××”×¨ ×™×•×ª×¨ ×-Pandas** ×‘×©×œ:\n",
    "- ğŸŒ **××•×¤×™ ××‘×•×–×¨** - ×¢×™×‘×•×“ ××§×‘×™×œ×™ ×¢×œ ××¡×¤×¨ ×œ×™×‘×•×ª ×•××›×•× ×•×ª\n",
    "- âš¡ **×‘×™×¦×•×¢ ××§×‘×™×œ×™** - ×©×™××•×© ×‘×›×œ ×”××©××‘×™× ×”×–××™× ×™×\n",
    "\n",
    "**×‘××™×œ×™× ××—×¨×•×ª:**\n",
    "- ğŸ’» **pandas** - ×¤×•×¢×œ ×¢×œ mode ×™×—×™×“\n",
    "- ğŸ–¥ï¸ **PySpark** - ×¤×•×¢×œ ×¢×œ ××¡×¤×¨ ××›×•× ×•×ª ×‘××§×‘×™×œ\n",
    "\n",
    "### ğŸ“ ××ª×™ ×œ×”×©×ª××© ×‘××”?\n",
    "\n",
    "×× ××ª×” ×¢×•×‘×“ ×¢×œ **××¤×œ×™×§×¦×™×™×ª Machine Learning** ×©×‘×” ××ª×” ××ª××•×“×“ ×¢× datasets ×’×“×•×œ×™×, PySpark ××¢×‘×“ ×¤×¢×•×œ×•×ª ×”×¨×‘×” ×™×•×ª×¨ ××”×¨ ×-pandas.\n",
    "\n",
    "×¢×™×™×Ÿ ×‘-[Pandas DataFrame Tutorial for beginners guide with examples](https://sparkbyexamples.com/pandas/) ×œ××™×“×¢ × ×•×¡×£ ×¢×œ pandas.\n",
    "\n",
    "### âš™ï¸ ××ª×™ × ×¦×˜×¨×š ×”××¨×”?\n",
    "\n",
    "×œ××—×¨ ×¢×™×‘×•×“ × ×ª×•× ×™× ×‘-PySpark, ×™×™×ª×›×Ÿ ×©× ×¦×˜×¨×š ×œ×”××™×¨ ××•×ª×• ×‘×—×–×¨×” ×œ-Pandas DataFrame ×œ×¢×™×‘×•×“ × ×•×¡×£ ×¢×:\n",
    "- ğŸ¤– ××¤×œ×™×§×¦×™×•×ª Machine Learning\n",
    "- ğŸ ××¤×œ×™×§×¦×™×•×ª Python ××—×¨×•×ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ × ×§×•×“×•×ª ××¤×ª×—\n",
    "\n",
    "### âœ… ×“×‘×¨×™× ×—×©×•×‘×™× ×œ×–×›×•×¨:\n",
    "\n",
    "1. **×©×™××•×© ×‘×©×™×˜×” `toPandas()`** - ×–××™× ×” ×‘××•×‘×™×™×§×˜×™ PySpark DataFrame ×œ×”××¨×ª× ×œ-DataFrames ×©×œ Pandas\n",
    "\n",
    "2. **Pandas DataFrames ×”× ××‘× ×™ × ×ª×•× ×™× in-memory** - ×©×§×•×œ ××’×‘×œ×•×ª ×–×™×›×¨×•×Ÿ ×‘×¢×ª ×”××¨×ª PySpark DataFrames ×’×“×•×œ×™×\n",
    "\n",
    "3. **×”××¨×ª PySpark DataFrames ×œ-Pandas DataFrames** - ×××¤×©×¨×ª ×œ×š ×œ×× ×£ ××ª ×”×¤×•× ×§×¦×™×•× ×œ×™×•×ª ×”× ×¨×—×‘×ª ×©×œ Pandas ×œ×× ×™×¤×•×œ×¦×™×” ×•× ×™×ª×•×— × ×ª×•× ×™×"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×”×›× ×ª PySpark DataFrame\n",
    "\n",
    "×›×“×™ ×œ×”×¡×‘×™×¨ ×¢× ×“×•×’××”, ×‘×•××• ×¨××©×™×ª **× ×™×¦×•×¨ PySpark DataFrame**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# ×™×¦×™×¨×ª × ×ª×•× ×™ ×“×•×’××”\n",
    "data = [\n",
    "    (\"James\", \"\", \"Smith\", \"36636\", \"M\", 60000),\n",
    "    (\"Michael\", \"Rose\", \"\", \"40288\", \"M\", 70000),\n",
    "    (\"Robert\", \"\", \"Williams\", \"42114\", \"M\", 400000),\n",
    "    (\"Maria\", \"Anne\", \"Jones\", \"39192\", \"F\", 500000),\n",
    "    (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\n",
    "]\n",
    "\n",
    "# ×”×’×“×¨×ª ×©××•×ª ×¢××•×“×•×ª\n",
    "columns = [\"first_name\", \"middle_name\", \"last_name\", \"dob\", \"gender\", \"salary\"]\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame\n",
    "pysparkDF = spark.createDataFrame(data=data, schema=columns)\n",
    "pysparkDF.printSchema()\n",
    "pysparkDF.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- first_name: string (nullable = true)\n",
    " |-- middle_name: string (nullable = true)\n",
    " |-- last_name: string (nullable = true)\n",
    " |-- dob: string (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    " |-- salary: long (nullable = true)\n",
    "\n",
    "+----------+-----------+---------+-----+------+------+\n",
    "|first_name|middle_name|last_name|dob  |gender|salary|\n",
    "+----------+-----------+---------+-----+------+------+\n",
    "|James     |           |Smith    |36636|M     |60000 |\n",
    "|Michael   |Rose       |         |40288|M     |70000 |\n",
    "|Robert    |           |Williams |42114|M     |400000|\n",
    "|Maria     |Anne       |Jones    |39192|F     |500000|\n",
    "|Jen       |Mary       |Brown    |     |F     |-1    |\n",
    "+----------+-----------+---------+-----+------+------+\n",
    "```\n",
    "\n",
    "×–×” ×× ×™×‘ ××ª ×”-schema ×•×”×ª×•×¦××” ×©×œ ×”-DataFrame ×œ××˜×”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ×”××¨×ª PySpark DataFrame ×œ-Pandas DataFrame\n",
    "\n",
    "PySpark DataFrame ××¡×¤×§ ×©×™×˜×” `toPandas()` ×œ×”××™×¨ ××•×ª×• ×œ-Python Pandas DataFrame.\n",
    "\n",
    "### âš ï¸ ××–×”×¨×” ×—×©×•×‘×”!\n",
    "\n",
    "`toPandas()` ××‘×™× ×‘×ª×•×¦××” ××ª ××™×¡×•×£ ×›×œ ×”×¨×©×•××•×ª ×‘-PySpark DataFrame ×œ×ª×•×›× ×™×ª ×”-driver ×•**×¦×¨×™×š ×œ×”×ª×‘×¦×¢ ×¨×§ ×¢×œ subset ×§×˜×Ÿ ×©×œ ×”× ×ª×•× ×™×**.\n",
    "\n",
    "×”×¨×¦×” ×¢×œ dataset ×’×“×•×œ ×™×•×ª×¨ ×’×•×¨××ª ×œ×©×’×™××•×ª ×–×™×›×¨×•×Ÿ ×•×§×¨×™×¡×” ×©×œ ×”××¤×œ×™×§×¦×™×”.\n",
    "\n",
    "×›×“×™ ×œ×”×ª××•×“×“ ×¢× dataset ×’×“×•×œ ×™×•×ª×¨, × ×™×ª×Ÿ ×’× ×œ× ×¡×•×ª ×œ×”×’×“×™×œ ××ª ×”×–×™×›×¨×•×Ÿ ×¢×œ ×”-driver."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×” ×œ-Pandas DataFrame\n",
    "pandasDF = pysparkDF.toPandas()\n",
    "print(pandasDF)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "  first_name middle_name last_name    dob gender  salary\n",
    "0      James                 Smith  36636      M   60000\n",
    "1    Michael        Rose            40288      M   70000\n",
    "2     Robert            Williams    42114      M  400000\n",
    "3      Maria        Anne     Jones  39192      F  500000\n",
    "4        Jen        Mary     Brown             F      -1\n",
    "```\n",
    "\n",
    "×–×” ×× ×™×‘ ××ª ×”-DataFrame ×©×œ pandas ×œ××˜×”. ×©×™× ×œ×‘ ×©-pandas ××•×¡×™×£ sequence number ×œ×ª×•×¦××” ×›-**row Index**.\n",
    "\n",
    "××ª×” ×™×›×•×œ **×œ×©× ×•×ª ×©××•×ª ×¢××•×“×•×ª ×©×œ pandas** ×‘×××¦×¢×•×ª ×¤×•× ×§×¦×™×” `rename()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ ×”××¨×ª Spark Nested Struct DataFrame ×œ-Pandas\n",
    "\n",
    "×¨×•×‘ ×”×–××Ÿ × ×ª×•× ×™× ×‘-PySpark DataFrame ×™×”×™×• **×‘×¤×•×¨××˜ ××•×‘× ×” (structured)**, ×›×œ×•××¨ ×¢××•×“×” ××—×ª ××›×™×œ×” ×¢××•×“×•×ª ××—×¨×•×ª.\n",
    "\n",
    "×‘×•××• × ×¨××” ××™×š ×œ×”××™×¨ ××•×ª×• ×œ-Pandas. ×”× ×” ×“×•×’××” ×¢× nested struct ×©×‘×• ×™×© ×œ× ×• `firstname`, `middlename` ×•-`lastname` ×©×”× ×—×œ×§ ××¢××•×“×ª ×”-`name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ×™×¦×™×¨×ª DataFrame ×¢× Nested Structure"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# ×”×’×“×¨×ª × ×ª×•× ×™ Nested Structure\n",
    "dataStruct = [\n",
    "    ((\"James\", \"\", \"Smith\"), \"36636\", \"M\", 3000),\n",
    "    ((\"Michael\", \"Rose\", \"\"), \"40288\", \"M\", 4000),\n",
    "    ((\"Robert\", \"\", \"Williams\"), \"42114\", \"M\", 4000),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"39192\", \"F\", 4000),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"F\", -1)\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×’×“×¨×ª Schema ×¢× StructType\n",
    "schemaStruct = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"dob\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", StringType(), True)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×¢× Nested Structure\n",
    "df = spark.createDataFrame(data=dataStruct, schema=schemaStruct)\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema ×¦×¤×•×™:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- name: struct (nullable = true)\n",
    " |    |-- firstname: string (nullable = true)\n",
    " |    |-- middlename: string (nullable = true)\n",
    " |    |-- lastname: string (nullable = true)\n",
    " |-- dob: string (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    " |-- salary: string (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”„ ×”××¨×ª Nested DataFrame ×œ-Pandas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×” ×œ-Pandas\n",
    "pandasDF2 = df.toPandas()\n",
    "print(pandasDF2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "                    name    dob gender salary\n",
    "0      (James, , Smith)  36636      M   3000\n",
    "1    (Michael, Rose, )  40288      M   4000\n",
    "2  (Robert, , Williams)  42114      M   4000\n",
    "3   (Maria, Anne, Jones)  39192      F   4000\n",
    "4      (Jen, Mary, Brown)             F     -1\n",
    "```\n",
    "\n",
    "×”××¨×ª structured DataFrame ×œ-Pandas DataFrame ××‘×™××” ×‘×ª×•×¦××” ××ª ×”×¤×œ×˜ ×œ××˜×”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ ×©××œ×•×ª × ×¤×•×¦×•×ª (FAQ) - ×”××¨×ª PySpark DataFrame ×œ-Pandas\n",
    "\n",
    "### ğŸ”¹ ××™×š ×× ×™ ×××™×¨ PySpark DataFrame ×œ-Pandas DataFrame?\n",
    "\n",
    "×›×“×™ ×œ×”××™×¨ PySpark DataFrame ×œ-Pandas DataFrame, ×”×©×ª××© ×‘×©×™×˜×” `toPandas()`.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ ×œ××” ×›×“××™ ×œ×”××™×¨ PySpark DataFrame ×œ-pandas DataFrame?\n",
    "\n",
    "×”××¨×ª PySpark DataFrames ×œ-Pandas ×××¤×©×¨×ª ×œ×š:\n",
    "- ğŸ¯ ×œ×× ×£ ××ª ×”×¤×•× ×§×¦×™×•× ×œ×™×•×ª ×”× ×¨×—×‘×ª\n",
    "- ğŸ”§ ×§×œ×•×ª ×”×©×™××•×© ×©×œ ×¡×¤×¨×™×™×ª Pandas\n",
    "- ğŸ“Š ×œ×× ×™×¤×•×œ×¦×™×”, × ×™×ª×•×— ×•×™×–×•××œ×™×–×¦×™×” ×©×œ × ×ª×•× ×™×\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ ×”×× ×™×© ××’×‘×œ×•×ª ××• ×©×™×§×•×œ×™× ×‘×”××¨×ª PySpark DataFrames ×œ-Pandas?\n",
    "\n",
    "**âš ï¸ ×—×©×•×‘ ×œ×©×§×•×œ:**\n",
    "\n",
    "××’×‘×œ×•×ª ×–×™×›×¨×•×Ÿ, ×‘××™×•×—×“ ×›×©×¢×•×¡×§×™× ×¢× datasets ×’×“×•×œ×™×.\n",
    "\n",
    "×”××¨×ª PySpark DataFrames ×’×“×•×œ×™× ×œ-DataFrames ×¢×œ×•×œ×” ×œ×”×•×‘×™×œ ×œ-**out-of-memory errors** ×× ×”× ×ª×•× ×™× ×œ× ×™×›×•×œ×™× ×œ×”×™×›× ×¡ ×‘×–×™×›×¨×•×Ÿ.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ ×”×× ×× ×™ ×™×›×•×œ ×œ×”××™×¨ ×›×œ PySpark DataFrame ×œ-Pandas DataFrame?\n",
    "\n",
    "**âœ… ×›×Ÿ**, × ×™×ª×Ÿ ×œ×”××™×¨ ×›×œ PySpark DataFrame ×œ-Pandas DataFrame ×‘×××¦×¢×•×ª ×©×™×˜×ª `toPandas()`.\n",
    "\n",
    "**âš ï¸ ××•×œ×**, ×©××•×¨ ×¢×œ ×”××©××¢×•×™×•×ª ×”×¤×•×˜× ×¦×™××œ×™×•×ª ×œ×‘×™×¦×•×¢×™× ×•×•×•×“× ×ª××™××•×ª ×‘×™×Ÿ ×˜×™×¤×•×¡×™ × ×ª×•× ×™× ×•××‘× ×™× ×©×œ PySpark ×•-Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ ××™×š ×× ×™ ×™×›×•×œ ×œ×‘×¦×¢ ××•×¤×˜×™××™×–×¦×™×” ×©×œ ×ª×”×œ×™×š ×”×”××¨×” ×-PySpark ×œ-Pandas ×œ×‘×™×¦×•×¢×™× ×˜×•×‘×™× ×™×•×ª×¨?\n",
    "\n",
    "**××•×¤×˜×™××™×–×¦×™×•×ª ×™×›×•×œ×•×ª ×œ×›×œ×•×œ:**\n",
    "\n",
    "1. **×‘×—×™×¨×ª ×¢××•×“×•×ª ×¨×œ×•×•× ×˜×™×•×ª** - ×œ×¤× ×™ ×”×”××¨×”\n",
    "2. **×¡×™× ×•×Ÿ × ×ª×•× ×™× ××™×•×ª×¨×™×** - ×”×•×¦××ª ××™×“×¢ ×©××™× ×• × ×—×•×¥\n",
    "3. **×©×™××•×© ×‘×˜×™×¤×•×¡×™ × ×ª×•× ×™× ××ª××™××™×** - ×œ××–×¢×¨ ×©×™××•×© ×‘×–×™×›×¨×•×Ÿ\n",
    "\n",
    "×‘× ×•×¡×£, ×©×§×•×œ ×©×™××•×© ×‘-**partitioning** ×•-**caching** ×‘-PySpark ×œ××•×¤×˜×™××™×–×¦×™×” ×©×œ ×”×‘×™×¦×•×¢×™× ×œ×¤× ×™ ×”×”××¨×” ×œ-Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ×¡×™×›×•×\n",
    "\n",
    "×‘××××¨ ×¤×©×•×˜ ×–×”, ×œ××“×ª ×œ×”××™×¨ Spark DataFrame ×œ-pandas ×‘×××¦×¢×•×ª ×¤×•× ×§×¦×™×” `toPandas()` ×©×œ Spark DataFrame.\n",
    "\n",
    "×¨××™×ª ×’× ×“×•×’××” ×“×•××” ×¢× **complex nested structure elements**.\n",
    "\n",
    "`toPandas()` ××‘×™× ×‘×ª×•×¦××” ××ª ××™×¡×•×£ ×›×œ ×”×¨×©×•××•×ª ×‘-DataFrame ×œ×ª×•×›× ×™×ª ×”-driver ×•**×¦×¨×™×š ×œ×”×ª×‘×¦×¢ ×¨×§ ×¢×œ subset ×§×˜×Ÿ ×©×œ ×”× ×ª×•× ×™×**.\n",
    "\n",
    "### âœ… ×¡×™×›×•× ××”×™×¨:\n",
    "\n",
    "| × ×•×©× | ×”×¡×‘×¨ |\n",
    "|------|------|\n",
    "| **×©×™×˜×ª ×”××¨×”** | `toPandas()` |\n",
    "| **×©×™××•×© ××•××œ×¥** | datasets ×§×˜× ×™×-×‘×™× ×•× ×™×™× |\n",
    "| **××–×”×¨×”** | ×©××•×¨ ×¢×œ ××’×‘×œ×•×ª ×–×™×›×¨×•×Ÿ |\n",
    "| **×™×ª×¨×•×Ÿ** | ×’×™×©×” ×œ×¤×•× ×§×¦×™×•× ×œ×™×•×ª Pandas |\n",
    "| **×—×™×¡×¨×•×Ÿ** | ××’×‘×™×œ ×œ×–×™×›×¨×•×Ÿ ×”××§×•××™ |\n",
    "\n",
    "### ğŸ¯ ×˜×™×¤×™× ×œ×©×™××•×© × ×›×•×Ÿ:\n",
    "\n",
    "- âœ… ×¡× ×Ÿ × ×ª×•× ×™× ×œ×¤× ×™ ×”××¨×”\n",
    "- âœ… ×‘×—×¨ ×¨×§ ×¢××•×“×•×ª × ×—×•×¦×•×ª\n",
    "- âœ… ×©×§×•×œ ×©×™××•×© ×‘-sample() ×œ×‘×“×™×§×•×ª\n",
    "- âš ï¸ ×”×™×–×”×¨ ×-datasets ×’×“×•×œ×™×\n",
    "\n",
    "**Happy Learning !!** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **What is PySpark DataFrame?**\n",
    "- **How to Pandas to PySpark DataFrame**\n",
    "- **How to Convert Pandas DataFrame to List?**\n",
    "- **Pandas Add Column based on Another Column**\n",
    "- **pandas rolling() Mean, Average, Sum Examples**\n",
    "- **PySpark Get Number of Rows and Columns**\n",
    "- **Set Order of Columns in Pandas DataFrame**\n",
    "- **Pandas vs PySpark DataFrame With Examples**\n",
    "- **Dynamic way of doing ETL through Pyspark**\n",
    "- **Pandas Create New DataFrame By Selecting Specific Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ ×ª×’×™×•×ª (Tags)\n",
    "\n",
    "`TOPANDAS()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××§×•×¨×•×ª ×•××™×“×¢ × ×•×¡×£\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©××™:**\n",
    "- [PySpark toPandas() Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.spark.frame.html)\n",
    "\n",
    "**××§×•×¨ ×”××“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**××“×¨×™×›×™× × ×•×¡×¤×™×:**\n",
    "- [Python Pandas Tutorial with Examples](https://sparkbyexamples.com/pandas/)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™××•×“ PySpark ×•-Pandas!**\n",
    "\n",
    "**âœ¨ Happy Learning !!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
