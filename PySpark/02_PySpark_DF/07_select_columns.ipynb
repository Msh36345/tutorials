{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "××§×•×¨: [Spark By Examples - Select Columns From DataFrame\n",
    "](https://sparkbyexamples.com/pyspark/select-columns-from-pyspark-dataframe/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ PySpark - ×‘×—×™×¨×ª ×¢××•×“×•×ª ×-DataFrame\n",
    "\n",
    "**×ª××¨×™×š:** 12 ×‘×××™, 2024  \n",
    "**×–××Ÿ ×§×¨×™××” ××©×•×¢×¨:** 10 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "×‘-PySpark, ×¤×•× ×§×¦×™×™×ª `select()` ××©××©×ª ×œ×‘×—×™×¨×ª:\n",
    "- ×¢××•×“×” ×‘×•×“×“×ª\n",
    "- ××¡×¤×¨ ×¢××•×“×•×ª\n",
    "- ×¢××•×“×” ×œ×¤×™ ××™× ×“×§×¡\n",
    "- ×›×œ ×”×¢××•×“×•×ª ××¨×©×™××”\n",
    "- ×¢××•×“×•×ª ××§×•× × ×•×ª ×-DataFrame\n",
    "\n",
    "PySpark `select()` ×”×™× **×¤×•× ×§×¦×™×™×ª ×˜×¨× ×¡×¤×•×¨××¦×™×”** ×•×œ×›×Ÿ ×”×™× ××—×–×™×¨×” DataFrame ×—×“×© ×¢× ×”×¢××•×“×•×ª ×©× ×‘×—×¨×•.\n",
    "\n",
    "### ğŸ“‹ ×ª×•×›×Ÿ ×”×¢× ×™×™× ×™×:\n",
    "\n",
    "1. ×‘×—×™×¨×ª ×¢××•×“×” ×™×—×™×“×” ×•××¨×•×‘×” ×-PySpark\n",
    "2. ×‘×—×™×¨×ª ×›×œ ×”×¢××•×“×•×ª ××¨×©×™××”\n",
    "3. ×‘×—×™×¨×ª ×¢××•×“×•×ª ×œ×¤×™ ××™× ×“×§×¡\n",
    "4. ×‘×—×™×¨×ª ×¢××•×“×•×ª Nested Struct ×-PySpark\n",
    "5. ×“×¨×›×™× × ×•×¡×¤×•×ª ×œ×‘×—×™×¨×ª ×¢××•×“×•×ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×”×›× ×ª DataFrame ×œ×“×•×’××”\n",
    "\n",
    "×¨××©×™×ª, ×‘×•××• × ×™×¦×•×¨ DataFrame ×œ×“×•×’××”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# × ×ª×•× ×™ ×“×•×’××”\n",
    "data = [\n",
    "    (\"James\", \"Smith\", \"USA\", \"CA\"),\n",
    "    (\"Michael\", \"Rose\", \"USA\", \"NY\"),\n",
    "    (\"Robert\", \"Williams\", \"USA\", \"CA\"),\n",
    "    (\"Maria\", \"Jones\", \"USA\", \"FL\")\n",
    "]\n",
    "\n",
    "# ×©××•×ª ×¢××•×“×•×ª\n",
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\"]\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××” ×¦×¤×•×™×”:**\n",
    "\n",
    "```\n",
    "+---------+--------+-------+-----+\n",
    "|firstname|lastname|country|state|\n",
    "+---------+--------+-------+-----+\n",
    "|James    |Smith   |USA    |CA   |\n",
    "|Michael  |Rose    |USA    |NY   |\n",
    "|Robert   |Williams|USA    |CA   |\n",
    "|Maria    |Jones   |USA    |FL   |\n",
    "+---------+--------+-------+-----+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ×‘×—×™×¨×ª ×¢××•×“×” ×‘×•×“×“×ª ×•××¡×¤×¨ ×¢××•×“×•×ª ×-PySpark\n",
    "\n",
    "× ×™×ª×Ÿ ×œ×‘×—×•×¨ ×¢××•×“×” ×‘×•×“×“×ª ××• ××¡×¤×¨ ×¢××•×“×•×ª ×©×œ ×”-DataFrame ×¢×œ ×™×“×™ ×”×¢×‘×¨×ª ×©××•×ª ×”×¢××•×“×•×ª ×©×¨×•×¦×™× ×œ×‘×—×•×¨ ×œ×¤×•× ×§×¦×™×” `select()`.\n",
    "\n",
    "××›×™×•×•×Ÿ ×©-DataFrame ×”×•× immutable, ×–×” ×™×•×¦×¨ DataFrame ×—×“×© ×¢× ×”×¢××•×“×•×ª ×©× ×‘×—×¨×•. \n",
    "\n",
    "×¤×•× ×§×¦×™×” `show()` ××©××©×ª ×œ×”×¦×’×ª ×ª×•×›×Ÿ ×”-DataFrame.\n",
    "\n",
    "×œ×”×œ×Ÿ ×”×“×¨×›×™× ×œ×‘×—×™×¨×ª ×¢××•×“×” ×‘×•×“×“×ª, ××¡×¤×¨ ××• ×›×œ ×”×¢××•×“×•×ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ ×‘×—×™×¨×ª ×¢××•×“×•×ª ×‘×“×¨×›×™× ×©×•× ×•×ª"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×¢××•×“×•×ª ×‘×“×¨×›×™× ×©×•× ×•×ª\n",
    "df.select(\"firstname\", \"lastname\").show()\n",
    "df.select(df.firstname, df.lastname).show()\n",
    "df.select(df[\"firstname\"], df[\"lastname\"]).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ ×©×™××•×© ×‘×¤×•× ×§×¦×™×” col()\n",
    "\n",
    "× ×™×ª×Ÿ ×’× ×œ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `col()` ×-`pyspark.sql.functions`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘×¤×•× ×§×¦×™×” col()\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select(col(\"firstname\"), col(\"lastname\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ ×‘×—×™×¨×ª ×¢××•×“×•×ª ×¢× ×‘×™×˜×•×™ ×¨×’×•×œ×¨×™\n",
    "\n",
    "× ×™×ª×Ÿ ×œ×‘×—×•×¨ ×¢××•×“×•×ª ×‘×××¦×¢×•×ª ×‘×™×˜×•×™ ×¨×’×•×œ×¨×™:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×¢××•×“×•×ª ×¢× ×‘×™×˜×•×™ ×¨×’×•×œ×¨×™\n",
    "df.select(df.colRegex(\"`^.*name$`\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "\n",
    "- `^.*name$` - ×‘×•×—×¨ ×›×œ ×¢××•×“×” ×©××¡×ª×™×™××ª ×‘-\"name\"\n",
    "- ×‘××§×¨×” ×©×œ× ×•, ×–×” ×™×‘×—×¨ ××ª `firstname` ×•-`lastname`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ×‘×—×™×¨×ª ×›×œ ×”×¢××•×“×•×ª ××¨×©×™××”\n",
    "\n",
    "×œ×¤×¢××™× ×™×™×ª×›×Ÿ ×©×ª×¦×˜×¨×š ×œ×‘×—×•×¨ ××ª ×›×œ ×¢××•×“×•×ª ×”-DataFrame ××¨×©×™××ª Python. \n",
    "\n",
    "×‘×“×•×’××” ×œ××˜×”, ×™×© ×œ× ×• ××ª ×›×œ ×”×¢××•×“×•×ª ×‘××•×‘×™×™×§×˜ ×”×¨×©×™××” `columns`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×›×œ ×”×¢××•×“×•×ª ××¨×©×™××”\n",
    "df.select(*columns).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×›×œ ×”×¢××•×“×•×ª - ×—×œ×•×¤×”\n",
    "df.select([col for col in df.columns]).show()\n",
    "df.select(\"*\").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ×‘×—×™×¨×ª ×¢××•×“×•×ª ×œ×¤×™ ××™× ×“×§×¡\n",
    "\n",
    "×‘×××¦×¢×•×ª ×ª×›×•× ×•×ª ×¨×©×™××ª Python, × ×™×ª×Ÿ ×œ×‘×—×•×¨ ××ª ×”×¢××•×“×•×ª ×œ×¤×™ ××™× ×“×§×¡."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×•×—×¨ 3 ×¢××•×“×•×ª ×¨××©×•× ×•×ª ×•-3 ×©×•×¨×•×ª ×¢×œ×™×•× ×•×ª\n",
    "df.select(df.columns[:3]).show(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×•×—×¨ ×¢××•×“×•×ª 2 ×¢×“ 4 ×•-3 ×©×•×¨×•×ª ×¢×œ×™×•× ×•×ª\n",
    "df.select(df.columns[2:4]).show(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ×‘×—×™×¨×ª ×¢××•×“×•×ª Nested Struct ×-PySpark\n",
    "\n",
    "×× ×™×© ×œ×š ×¢××•×“×ª struct ××§×•× × ×ª (StructType) ×‘-PySpark DataFrame, ×¢×œ×™×š ×œ×”×©×ª××© ×‘-**explicit column qualifier** ×›×“×™ ×œ×‘×—×•×¨.\n",
    "\n",
    "×× ××ª×” ×—×“×© ×‘-PySpark ×•×œ× ×œ××“×ª StructType ×¢×“×™×™×Ÿ, ×× ×™ ×××œ×™×¥ ×œ×“×œ×’ ×¢×œ ×”×—×œ×§ ×”×–×” ××• ×œ×œ××•×“ ×ª×—×™×œ×” **Understand PySpark StructType**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ×™×¦×™×¨×ª DataFrame ×¢× Nested Structure"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×¢× ×¢××•×“×•×ª ××§×•× × ×•×ª\n",
    "data = [\n",
    "    ((\"James\", None, \"Smith\"), \"OH\", \"M\"),\n",
    "    ((\"Anna\", \"Rose\", \"\"), \"NY\", \"F\"),\n",
    "    ((\"Julia\", \"\", \"Williams\"), \"OH\", \"F\"),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"NY\", \"M\"),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"M\"),\n",
    "    ((\"Mike\", \"Mary\", \"Williams\"), \"OH\", \"M\")\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "df2 = spark.createDataFrame(data=data, schema=schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)  # ×”×¦×’ ××ª ×›×œ ×”×¢××•×“×•×ª"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema ×¦×¤×•×™:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- name: struct (nullable = true)\n",
    " |    |-- firstname: string (nullable = true)\n",
    " |    |-- middlename: string (nullable = true)\n",
    " |    |-- lastname: string (nullable = true)\n",
    " |-- state: string (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    "```\n",
    "\n",
    "×–×” ××™×™×¦×¨ ××ª ×”-schema ×”×‘×. ×× ×ª×©×™× ×œ×‘, ×”×¢××•×“×” `name` ×”×™× ××¡×•×’ struct, ×”××›×™×œ×” ××ª ×”×¢××•×“×•×ª firstname, middlename, ×•-lastname."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” ×‘×—×™×¨×ª ×¢××•×“×ª ×”-Struct\n",
    "\n",
    "×›×“×™ ×œ×‘×—×•×¨ ××ª ×¢××•×“×ª ×”-struct, ×¤×©×•×˜ ×¦×™×™×Ÿ ××ª ×©× ×”×¢××•×“×” ×‘-`select()`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×¢××•×“×ª struct\n",
    "df2.select(\"name\").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "×–×” ××—×–×™×¨ ××ª ×¢××•×“×ª ×”-struct `name` ×›××•×ª ×©×”×™×."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ ×‘×—×™×¨×ª ×¢××•×“×•×ª ×™×œ×“ (Child Columns)\n",
    "\n",
    "×›×“×™ ×œ×‘×—×•×¨ ×¢××•×“×” ×¡×¤×¦×™×¤×™×ª ×××‘× ×” ××§×•× ×Ÿ, ×¢×œ×™×š ×œ×¦×™×™×Ÿ ×‘××¤×•×¨×© ××ª ×©× ×”×¢××•×“×ª ×”××§×•× × ×ª:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×¢××•×“×•×ª ×™×œ×“\n",
    "df2.select(\"name.firstname\", \"name.lastname\").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "×–×” ××—×–×™×¨ ××ª `firstname` ×•-`lastname` ×›×©×ª×™ ×¢××•×“×•×ª × ×¤×¨×“×•×ª ××¢××•×“×ª ×”-name struct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“¦ ×‘×—×™×¨×ª ×›×œ ×¢××•×“×•×ª ×”×™×œ×“ ××”-Struct\n",
    "\n",
    "×›×“×™ ×œ×§×‘×œ ××ª ×›×œ ×”×¢××•×“×•×ª ××¢××•×“×ª ×”-struct, ×¦×™×™×Ÿ `name.*`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×—×™×¨×ª ×›×œ ×¢××•×“×•×ª ×”×™×œ×“\n",
    "df2.select(\"name.*\").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "+---------+----------+--------+\n",
    "|firstname|middlename|lastname|\n",
    "+---------+----------+--------+\n",
    "|James    |null      |Smith   |\n",
    "|Anna     |Rose      |        |\n",
    "|Julia    |          |Williams|\n",
    "|Maria    |Anne      |Jones   |\n",
    "|Jen      |Mary      |Brown   |\n",
    "|Mike     |Mary      |Williams|\n",
    "+---------+----------+--------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ×“×•×’××” ××œ××” - ×§×•×“ ×©×œ×"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"James\", \"Smith\", \"USA\", \"CA\"),\n",
    "    (\"Michael\", \"Rose\", \"USA\", \"NY\"),\n",
    "    (\"Robert\", \"Williams\", \"USA\", \"CA\"),\n",
    "    (\"Maria\", \"Jones\", \"USA\", \"FL\")\n",
    "]\n",
    "\n",
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.show(truncate=False)\n",
    "\n",
    "print(\"=== ×‘×—×™×¨×ª ×¢××•×“×•×ª ×‘×•×“×“×•×ª ===\")\n",
    "df.select(\"firstname\").show()\n",
    "\n",
    "df.select(\"firstname\", \"lastname\").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== ×©×™××•×© ×‘×©× DataFrame ===\")\n",
    "df.select(df.firstname, df.lastname).show()\n",
    "\n",
    "print(\"=== ×©×™××•×© ×‘-col() ===\")\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\"), col(\"lastname\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== ×“×•×’××” ×¢× Nested Struct ===\")\n",
    "data = [\n",
    "    ((\"James\", None, \"Smith\"), \"OH\", \"M\"),\n",
    "    ((\"Anna\", \"Rose\", \"\"), \"NY\", \"F\"),\n",
    "    ((\"Julia\", \"\", \"Williams\"), \"OH\", \"F\"),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"NY\", \"M\"),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"M\"),\n",
    "    ((\"Mike\", \"Mary\", \"Williams\"), \"OH\", \"M\")\n",
    "]\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"firstname\", StringType(), True),\n",
    "        StructField(\"middlename\", StringType(), True),\n",
    "        StructField(\"lastname\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "df2 = spark.createDataFrame(data=data, schema=schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "df2.select(\"name\").show(truncate=False)\n",
    "df2.select(\"name.firstname\", \"name.lastname\").show(truncate=False)\n",
    "df2.select(\"name.*\").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ×¡×™×›×•×\n",
    "\n",
    "×‘××××¨ ×–×”, ×œ××“×ª ×©-`select()` ×”×™× ×¤×•× ×§×¦×™×™×ª ×˜×¨× ×¡×¤×•×¨××¦×™×” ×©×œ ×”-DataFrame ×•××©××©×ª ×œ×‘×—×™×¨×ª:\n",
    "- ×¢××•×“×” ×‘×•×“×“×ª\n",
    "- ××¡×¤×¨ ×¢××•×“×•×ª\n",
    "- ×‘×—×™×¨×ª ×›×œ ×”×¢××•×“×•×ª ××¨×©×™××”\n",
    "- ×‘×—×™×¨×” ×œ×¤×™ ××™× ×“×§×¡\n",
    "- ×‘×—×™×¨×ª ×¢××•×“×•×ª struct ××§×•× × ×•×ª\n",
    "\n",
    "### âœ… ×©×™×˜×•×ª ×¢×™×§×¨×™×•×ª:\n",
    "\n",
    "| ×©×™×˜×” | ×“×•×’××” | ×©×™××•×© |\n",
    "|------|-------|-------|\n",
    "| **×©××•×ª ×¢××•×“×•×ª ×™×©×™×¨×•×ª** | `df.select(\"col1\", \"col2\")` | ×”×¤×©×•×˜×” ×‘×™×•×ª×¨ |\n",
    "| **col()** | `df.select(col(\"col1\"))` | ×’××™×©×” ×™×•×ª×¨ |\n",
    "| **DataFrame accessor** | `df.select(df.col1)` | × ×•×—×” ×œ×©×™××•×© |\n",
    "| **Regex** | `df.colRegex(\"pattern\")` | ×œ×‘×—×™×¨×ª ×“×™× ××™×ª |\n",
    "| **×¨×©×™××”** | `df.select(*columns)` | ××¨×©×™××ª ×©××•×ª |\n",
    "| **××™× ×“×§×¡** | `df.select(df.columns[:3])` | ×œ×¤×™ ××™×§×•× |\n",
    "| **Nested** | `df.select(\"name.firstname\")` | ××‘× ×™× ××§×•× × ×™× |\n",
    "\n",
    "×œ××“×ª ×’× ××™×š ×œ×‘×—×•×¨ ××œ×× ×˜×™× ××§×•× × ×™× ××”-DataFrame.\n",
    "\n",
    "**Happy Learning !!** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **How to Replace Column Values in PySpark DataFrame**\n",
    "- **How to Retrieve DataType & Column Names of PySpark DataFrame**\n",
    "- **Pyspark Select Distinct Rows**\n",
    "- **PySpark Select Top N Rows From Each Group**\n",
    "- **PySpark Replace Empty Value With None/null on DataFrame**\n",
    "- **PySpark Groupby on Multiple Columns**\n",
    "- **PySpark alias() Column & DataFrame Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ ×ª×’×™×•×ª (Tags)\n",
    "\n",
    "`SELECT()` `STRUCT` `STRUCTTYPE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××§×•×¨×•×ª ×•××™×“×¢ × ×•×¡×£\n",
    "\n",
    "**××§×•×¨ ×”××“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©××™:**\n",
    "- [PySpark DataFrame.select() Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.select.html)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™××•×“ PySpark!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
