{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "××§×•×¨: [Spark By Examples - show() Display DataFrame Contents in Table\n",
    "](https://sparkbyexamples.com/pyspark/pyspark-show-display-dataframe-contents-in-table/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“º PySpark show() - ×”×¦×’×ª ×ª×•×›×Ÿ DataFrame ×‘×˜×‘×œ×”\n",
    "\n",
    "**×ª××¨×™×š:** 27 ×‘××¨×¥, 2024  \n",
    "**×–××Ÿ ×§×¨×™××” ××©×•×¢×¨:** 6 ×“×§×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "PySpark DataFrame `show()` ××©××© ×œ×”×¦×’×ª ×ª×•×›×Ÿ ×”-DataFrame **×‘×¤×•×¨××˜ ×˜×‘×œ×” ×©×œ ×©×•×¨×•×ª ×•×¢××•×“×•×ª**.\n",
    "\n",
    "×›×‘×¨×™×¨×ª ××—×“×œ, ×”×™× ××¦×™×’×” ×¨×§ **20 ×©×•×¨×•×ª**, ×•×¢×¨×›×™ ×”×¢××•×“×•×ª × ×—×ª×›×™× ×‘-**20 ×ª×•×•×™×**.\n",
    "\n",
    "### ğŸ“‹ ××” × ×œ××“:\n",
    "\n",
    "1. ×“×•×’××” ××”×™×¨×” ×©×œ `show()`\n",
    "2. Syntax ×©×œ `show()`\n",
    "3. PySpark show() ×œ×”×¦×’×ª ×ª×•×›×Ÿ\n",
    "4. Show() ×¢× Truncate ×©×œ ×¢×¨×›×™ ×¢××•×“×•×ª\n",
    "5. ×”×¦×’×ª ×ª×•×›×Ÿ ×× ×›×™×ª (Vertically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ×“×•×’××” ××”×™×¨×” ×©×œ show()\n",
    "\n",
    "×œ×”×œ×Ÿ ×“×•×’×××•×ª ××”×™×¨×•×ª ×©×œ ××™×š ×œ×”×¦×™×’ ××ª ×ª×•×›×Ÿ ×”-DataFrame:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# ×™×¦×™×¨×ª × ×ª×•× ×™ ×“×•×’××”\n",
    "data = [\n",
    "    (\"James\", \"\", \"Smith\", \"36636\", \"M\", 60000),\n",
    "    (\"Michael\", \"Rose\", \"\", \"40288\", \"M\", 70000),\n",
    "    (\"Robert\", \"\", \"Williams\", \"42114\", \"M\", 400000),\n",
    "    (\"Maria\", \"Anne\", \"Jones\", \"39192\", \"F\", 500000),\n",
    "    (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\n",
    "]\n",
    "\n",
    "# ×”×’×“×¨×ª ×©××•×ª ×¢××•×“×•×ª\n",
    "columns = [\"first_name\", \"middle_name\", \"last_name\", \"dob\", \"gender\", \"salary\"]\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame\n",
    "df = spark.createDataFrame(data=data, schema=columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×‘×¨×™×¨×ª ××—×“×œ - ××¦×™×’ 20 ×©×•×¨×•×ª ×•-20 ×ª×•×•×™× ××¢×¨×š ×”×¢××•×“×”\n",
    "df.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª ×ª×•×›×Ÿ ×¢××•×“×” ××œ×\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª 2 ×©×•×¨×•×ª ×•×ª×•×›×Ÿ ×¢××•×“×” ××œ×\n",
    "df.show(2, truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª 2 ×©×•×¨×•×ª ×•×¢×¨×›×™ ×¢××•×“×” ×©×œ 25 ×ª×•×•×™×\n",
    "df.show(2, truncate=25)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª ×©×•×¨×•×ª ×•×¢××•×“×•×ª ×©×œ DataFrame ×× ×›×™×ª\n",
    "df.show(n=3, truncate=25, vertical=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Syntax ×©×œ show()\n",
    "\n",
    "×œ×”×œ×Ÿ ×”-syntax ×©×œ ×¤×•× ×§×¦×™×” `show()`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Syntax\n",
    "# def show(self, n=20, truncate=True, vertical=False):"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×¤×¨××˜×¨×™×:**\n",
    "\n",
    "- **n** (int, optional) - ××¡×¤×¨ ×”×©×•×¨×•×ª ×œ×”×¦×’×” (×‘×¨×™×¨×ª ××—×“×œ: 20)\n",
    "- **truncate** (bool or int, optional) - \n",
    "  - `True` - ×—×•×ª×š ×‘-20 ×ª×•×•×™×\n",
    "  - `False` - ××¦×™×’ ××ª ×›×œ ×”×ª×•×›×Ÿ\n",
    "  - ××¡×¤×¨ - ×—×•×ª×š ×‘××¡×¤×¨ ×ª×•×•×™× ×©×¦×•×™×Ÿ\n",
    "- **vertical** (bool, optional) - ×× `True`, ××“×¤×™×¡ ×›×œ ×¨×©×•××” ×× ×›×™×ª (×‘×¨×™×¨×ª ××—×“×œ: False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ PySpark show() ×œ×”×¦×’×ª ×ª×•×›×Ÿ\n",
    "\n",
    "×”×©×ª××© ×‘×©×™×˜×” `show()` ×©×œ PySpark ×›×“×™ ×œ×”×¦×™×’ ××ª ×ª×•×›×Ÿ ×”-DataFrame ×•×”×©×ª××© ×‘×©×™×˜×” `pyspark printSchema()` ×œ×”×“×¤×™×¡ ××ª ×”-schema.\n",
    "\n",
    "×©×™×˜×ª `show()` ×›×‘×¨×™×¨×ª ××—×“×œ ××¦×™×’×” ×¨×§ **20 ×©×•×¨×•×ª/×¨×©×•××•×ª** ××”-DataFrame ×•×—×•×ª×›×ª ××ª ×¢×¨×›×™ ×”×¢××•×“×•×ª ×‘-**20 ×ª×•×•×™×**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ×”×›× ×ª DataFrame ×œ×“×•×’××”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "columns = [\"Seqno\", \"Quote\"]\n",
    "data = [\n",
    "    (\"1\", \"Be the change that you wish to see in the world\"),\n",
    "    (\"2\", \"Everyone thinks of changing the world, but no one thinks of changing himself.\"),\n",
    "    (\"3\", \"The purpose of our lives is to be happy.\"),\n",
    "    (\"4\", \"Be cool\")\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "+-----+--------------------+\n",
    "|Seqno|               Quote|\n",
    "+-----+--------------------+\n",
    "|    1|Be the change tha...|\n",
    "|    2|Everyone thinks o...|\n",
    "|    3|The purpose of ou...|\n",
    "|    4|            Be cool.|\n",
    "+-----+--------------------+\n",
    "```\n",
    "\n",
    "×›×¤×™ ×©××ª×” ×¨×•××” ×œ××¢×œ×”, ×¢×¨×›×™× ×‘×¢××•×“×” `Quote` × ×—×ª×›×™× ×‘-20 ×ª×•×•×™×. ×‘×•××• × ×¨××” ××™×š ×œ×”×¦×™×’ ××ª ×ª×•×›×Ÿ ×”×¢××•×“×” ×”××œ×."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Show() ×¢× Truncate ×©×œ ×¢×¨×›×™ ×¢××•×“×•×ª\n",
    "\n",
    "### ğŸ”¸ ×”×¦×’×ª ×ª×•×›×Ÿ ×¢××•×“×” ××œ×\n",
    "\n",
    "× ×™×ª×Ÿ ×’× ×œ×—×ª×•×š ××ª ×¢×¨×š ×”×¢××•×“×” ×‘××•×¨×š ×”×¨×¦×•×™. \n",
    "\n",
    "×›×‘×¨×™×¨×ª ××—×“×œ ×–×” ×—×•×ª×š ×‘-20 ×ª×•×•×™×, ××•×œ× ××ª×” ×™×›×•×œ ×œ×”×¦×™×’ ××ª ×›×œ ×”×ª×•×›×Ÿ ×‘×××¦×¢×•×ª `truncate=False`.\n",
    "\n",
    "×× ×¨×¦×™×ª ×œ×—×ª×•×š ×‘××•×¨×š ×¡×¤×¦×™×¤×™ ×”×©×ª××© `truncate=n`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª ×ª×•×›×Ÿ ×¢××•×“×” ××œ×\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "+-----+-----------------------------------------------------------------------------+\n",
    "|Seqno|Quote                                                                        |\n",
    "+-----+-----------------------------------------------------------------------------+\n",
    "|1    |Be the change that you wish to see in the world                             |\n",
    "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
    "|3    |The purpose of our lives is to be happy.                                     |\n",
    "|4    |Be cool                                                                      |\n",
    "+-----+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¸ ×©×™×˜×ª show() ×©×œ PySpark ××¦×™×’×” ×¨×§ 20 ×©×•×¨×•×ª ×-DataFrame\n",
    "\n",
    "×”-DataFrame ×©×œ× ×• ×œ××˜×” ×™×© ×¨×§ 4 ×©×•×¨×•×ª ×•×œ×›×Ÿ ×œ× ××•×›×œ ×œ×”×“×’×™× ×¢× ×™×•×ª×¨ ×-4 ×©×•×¨×•×ª.\n",
    "\n",
    "×× ×™×© ×œ×š DataFrame ×¢× ××œ×¤×™ ×©×•×¨×•×ª ×× ×¡×” ×œ×©× ×•×ª ×”×¢×¨×š ×-2 ×œ-100 ×›×“×™ ×œ×”×¦×™×’ ×™×•×ª×¨ ×-20 ×©×•×¨×•×ª."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª 2 ×©×•×¨×•×ª ×•×ª×•×›×Ÿ ×¢××•×“×” ××œ×\n",
    "df.show(2, truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "+-----+-----------------------------------------------------------------------------+\n",
    "|Seqno|Quote                                                                        |\n",
    "+-----+-----------------------------------------------------------------------------+\n",
    "|1    |Be the change that you wish to see in the world                             |\n",
    "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
    "+-----+-----------------------------------------------------------------------------+\n",
    "only showing top 2 rows\n",
    "```\n",
    "\n",
    "×›×‘×¨×™×¨×ª ××—×“×œ ×©×™×˜×ª `show()` ××¦×™×’×” ×¨×§ 20 ×©×•×¨×•×ª ×-PySpark DataFrame.\n",
    "\n",
    "×”×“×•×’××” ×”×‘××” ××’×‘×™×œ×” ××ª ×”×©×•×¨×•×ª ×œ-2 ×•×ª×•×›×Ÿ ×¢××•×“×” ××œ×. \n",
    "\n",
    "×”-DataFrame ×©×œ× ×• ×œ××˜×” ×™×© ×¨×§ 4 ×©×•×¨×•×ª ×›×š ×©×œ× ××•×›×œ ×œ×”×“×’×™× ×¢× ×™×•×ª×¨ ×-4 ×©×•×¨×•×ª.\n",
    "\n",
    "×× ×™×© ×œ×š DataFrame ×¢× ××œ×¤×™ ×©×•×¨×•×ª × ×¡×” ×œ×©× ×•×ª ××ª ×”×¢×¨×š ×-2 ×œ-100 ×›×“×™ ×œ×”×¦×™×’ ×™×•×ª×¨ ×-20 ×©×•×¨×•×ª."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª 2 ×©×•×¨×•×ª ×•×¢×¨×›×™ ×¢××•×“×” 25 ×ª×•×•×™×\n",
    "df.show(2, truncate=25)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "+-----+-------------------------+\n",
    "|Seqno|                    Quote|\n",
    "+-----+-------------------------+\n",
    "|    1|Be the change that you...|\n",
    "|    2|Everyone thinks of cha...|\n",
    "+-----+-------------------------+\n",
    "only showing top 2 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ×”×¦×’×ª ×ª×•×›×Ÿ ×× ×›×™×ª (Vertically)\n",
    "\n",
    "×œ×‘×¡×•×£, ×‘×•××• × ×¨××” ××™×š ×œ×”×¦×™×’ ××ª ×”-DataFrame ×× ×›×™×ª ×¨×©×•××” ××—×¨ ×¨×©×•××”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×¦×’×ª DataFrame ×©×•×¨×•×ª ×•×¢××•×“×•×ª ×× ×›×™×ª\n",
    "df.show(n=3, truncate=25, vertical=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×ª×•×¦××”:**\n",
    "\n",
    "```\n",
    "-RECORD 0--------------------------\n",
    " Seqno | 1                         \n",
    " Quote | Be the change that you... \n",
    "-RECORD 1--------------------------\n",
    " Seqno | 2                         \n",
    " Quote | Everyone thinks of cha... \n",
    "-RECORD 2--------------------------\n",
    " Seqno | 3                         \n",
    " Quote | The purpose of our liv... \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ ×¡×™×›×•× (Conclusion)\n",
    "\n",
    "×‘××××¨ ×–×”, ×œ××“×ª ××™×š ×œ×”×¦×™×’ ××ª ×ª×•×›×Ÿ PySpark DataFrame ×œ-console ×•×œ××“×ª ×œ×”×©×ª××© ×‘×¤×¨××˜×¨×™× ×›×“×™ ×œ×”×’×‘×™×œ ××ª ×”×©×•×¨×•×ª ×•×œ×—×ª×•×š ××• ×œ×”×¦×™×’ ××ª ×ª×•×›×Ÿ ×”×¢××•×“×•×ª.\n",
    "\n",
    "### âœ… ××” ×œ××“× ×•:\n",
    "\n",
    "| ×¤×¨××˜×¨ | ×ª×™××•×¨ | ×‘×¨×™×¨×ª ××—×“×œ |\n",
    "|-------|-------|------------|\n",
    "| **n** | ××¡×¤×¨ ×©×•×¨×•×ª ×œ×”×¦×’×” | 20 |\n",
    "| **truncate** | ×—×™×ª×•×š ×¢×¨×›×™ ×¢××•×“×•×ª | True (20 ×ª×•×•×™×) |\n",
    "| **vertical** | ×”×¦×’×” ×× ×›×™×ª | False |\n",
    "\n",
    "### ğŸ¯ ×˜×™×¤×™×:\n",
    "\n",
    "- âœ… ×”×©×ª××© ×‘-`truncate=False` ×œ×¨××•×ª ××ª ×›×œ ×”×ª×•×›×Ÿ\n",
    "- âœ… ×”×©×ª××© ×‘-`vertical=True` ×œ-DataFrames ×¢× ×”×¨×‘×” ×¢××•×“×•×ª\n",
    "- âœ… ×”×’×‘×œ ××ª ××¡×¤×¨ ×”×©×•×¨×•×ª ×›×“×™ ×œ×—×¡×•×š ×–××Ÿ ×¢× datasets ×’×“×•×œ×™×\n",
    "- âš ï¸ ×–×›×•×¨ ×©-`show()` ××¤×¢×™×œ ×—×™×©×•×‘ (action), ×œ× transformation\n",
    "\n",
    "**Happy Learning !!** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- **PySpark Select First Row of Each Group?**\n",
    "- **PySpark Select Nested struct Columns**\n",
    "- **PySpark Select Columns From DataFrame**\n",
    "- **Dynamic way of doing ETL through Pyspark**\n",
    "- **Pyspark Select Distinct Rows**\n",
    "- **PySpark Get Number of Rows and Columns**\n",
    "- **PySpark count() â€“ Different Methods Explained**\n",
    "- **PySpark SQL Self Join With Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××§×•×¨×•×ª ×•××™×“×¢ × ×•×¡×£\n",
    "\n",
    "**××§×•×¨ ×”××“×¨×™×š:**\n",
    "- SparkByExamples.com\n",
    "\n",
    "**×ª×™×¢×•×“ ×¨×©××™:**\n",
    "- [PySpark DataFrame.show() Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.show.html)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’» ×‘×”×¦×œ×—×” ×‘×œ×™××•×“ PySpark!**\n",
    "\n",
    "**âœ¨ Happy Learning !!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
