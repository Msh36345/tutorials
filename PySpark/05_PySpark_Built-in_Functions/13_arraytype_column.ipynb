{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸ¨ PySpark ArrayType - ×¢××•×“×” ×¢× ×“×•×’×××•×ª\n",
    "[PySpark ArrayType Column With Examples](https://sparkbyexamples.com/pyspark/pyspark-arraytype-column-with-examples/#array_contains)\n",
    "## ğŸ“‹ ××‘×•×\n",
    "\n",
    "PySpark `pyspark.sql.types.ArrayType` (ArrayType ××¨×—×™×‘ ××ª ××—×œ×§×ª DataType) ××©××© ×œ×”×’×“×¨×ª ×¢××•×“×ª ×¡×•×’ × ×ª×•× ×™ ××¢×¨×š ×‘-DataFrame ×”××›×™×œ×” ××ª ××•×ª×• ×¡×•×’ ×©×œ ××œ×× ×˜×™×.\n",
    "\n",
    "×‘××××¨ ×–×”, ××¡×‘×™×¨ ×›×™×¦×“ ×œ×™×¦×•×¨ DataFrame ×¢× ×¢××•×“×ª ArrayType ×‘×××¦×¢×•×ª ×¡×•×’×™ pyspark.sql, ×•×œ×™×™×©× ×›××” ×¤×•× ×§×¦×™×•×ª SQL ×‘×¢××•×“×•×ª ×”××¢×¨×š ×¢× ×“×•×’×××•×ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ××”×• PySpark ArrayType?\n",
    "\n",
    "PySpark ArrayType ×”×•× ×¡×•×’ × ×ª×•× ×™ ××•×¡×£ ×”××¨×—×™×‘ ××ª ××—×œ×§×ª DataType, ×”××©××© ×œ××—×¡×•×Ÿ ××ª ××•×ª×• ×¡×•×’ ×©×œ ××œ×× ×˜×™×.\n",
    "\n",
    "×›×œ ×”××œ×× ×˜×™× ×©×œ ArrayType ×¦×¨×™×›×™× ×œ×”×™×•×ª ×××•×ª×• ×¡×•×’ ×©×œ ××œ×× ×˜×™×. ArrayType ××¨×—×™×‘ ××ª ××—×œ×§×ª DataType ×©×”×™× ×¡×•×¤×¨-×§×œ××¡ ×©×œ ×›×œ ×”×˜×™×¤×•×¡×™× ×‘-PySpark ×•×œ×•×§×— ××¨×’×•×× ×˜×™× ×©× ×™ ×—×•×‘×”:\n",
    "\n",
    "- `valueType` - ×¡×•×’ ×”× ×ª×•× ×™× ×©×™×›×•×œ ×œ×”×™×•×ª ×›×œ ×¡×•×’ ×©××¨×—×™×‘ ××ª DataType.\n",
    "- `valueContainsNull` - ×–×”×• ×‘×•×œ×™××Ÿ (True/False), ×”××¦×™×™×Ÿ ×× ×¢×¨×š ×™×›×•×œ ×œ×§×‘×œ null/None.\n",
    "\n",
    "×›×‘×¨×™×¨×ª ××—×“×œ, ×›×œ ×¢××•×“×ª Array ××›×™×œ×” null/None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ×™×¦×™×¨×ª PySpark ArrayType\n",
    "\n",
    "×¢×œ ×× ×ª ×œ×”×©×ª××© ×‘×¡×•×’ ×”× ×ª×•× ×™× ArrayType ×ª×—×™×œ×”, ×¢×œ×™×š ×œ×™×™×‘× ××•×ª×• ×-`pyspark.sql.types.ArrayType` ×•×œ×”×©×ª××© ×‘×§×•× ×¡×˜×¨×§×˜×•×¨ `ArrayType()` ×œ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ ××¢×¨×š."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import StringType, ArrayType\n",
    "\n",
    "arrayCol = ArrayType(StringType(), False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "×”×“×•×’××” ×œ×¢×™×œ ×™×•×¦×¨×ª ××¢×¨×š ××—×¨×•×–×•×ª ×•××™× ×” ××§×‘×œ×ª ×¢×¨×›×™ null/None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ×™×¦×™×¨×ª DataFrame ×¢× ArrayType ×‘×××¦×¢×•×ª StructType\n",
    "\n",
    "×‘×•××• × ×™×¦×•×¨ DataFrame ×¢× ×›××” ×¢××•×“×•×ª ××¢×¨×š ×‘×××¦×¢×•×ª ×©×™××•×© ×‘××—×œ×§×•×ª PySpark StructType & StructField. StructType ×œ×•×§×— ×¨×©×™××ª StructField, StructField ×œ×•×§×— ×©× ×©×“×” ×•×¡×•×’."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = [\n",
    " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
    " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
    " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"languagesAtSchool\", ArrayType(StringType()), True),\n",
    "    StructField(\"languagesAtWork\", ArrayType(StringType()), True),\n",
    "    StructField(\"currentState\", StringType(), True),\n",
    "    StructField(\"previousState\", StringType(), True)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "×¤×•× ×§×¦×™×•×ª `printSchema()` ×•-`show()` ××œ×¢×™×œ ××¦×™×’×•×ª ××ª ×”×¡×›××” ×•×”×¤×œ×˜ ×©×œ ×”-DataFrame ×©×œ×¢×™×œ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” ×¤×•× ×§×¦×™×•×ª PySpark ArrayType (Array)\n",
    "\n",
    "PySpark SQL ××¡×¤×§ ××¡×¤×¨ ×¤×•× ×§×¦×™×•×ª Array ×œ×¢×‘×•×“×” ×¢× ×¢××•×“×ª ArrayType. ×‘×¡×¢×™×£ ×–×”, × ×¨××” ×›××” ××”×¤×•× ×§×¦×™×•×ª ×”× ×¤×•×¦×•×ª ×‘×™×•×ª×¨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¥ explode()\n",
    "\n",
    "×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `explode()` ×›×“×™ ×œ×™×¦×•×¨ ×©×•×¨×” ×—×“×©×” ×¢×‘×•×¨ ×›×œ ××œ×× ×˜ ×‘×¢××•×“×ª ×”××¢×¨×š ×”× ×ª×•× ×”. ×™×©× ×Ÿ ××¡×¤×¨ ×¤×•× ×§×¦×™×•×ª explode ×©×œ PySpark SQL ×–××™× ×•×ª ×œ×¢×‘×•×“×” ×¢× ×¢××•×“×•×ª Array."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df.select(df.name, explode(df.languagesAtSchool)).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ‚ï¸ split()\n",
    "\n",
    "×¤×•× ×§×¦×™×™×ª SQL `split()` ××—×–×™×¨×” ×¡×•×’ ××¢×¨×š ×œ××—×¨ ×¤×™×¦×•×œ ×¢××•×“×ª ×”××—×¨×•×–×ª ×œ×¤×™ ××¤×¨×™×“."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "df.select(df.name, split(df.name, \",\").alias(\"nameAsArray\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "×”×“×•×’××” ×œ×¢×™×œ ××¤×¦×œ×ª ××ª ×¢××•×“×ª ×”×©× ×œ×¤×™ ×¤×¡×™×§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”— array()\n",
    "\n",
    "×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `array()` ×›×“×™ ×œ×™×¦×•×¨ ×¢××•×“×ª ××¢×¨×š ×—×“×©×” ×¢×œ-×™×“×™ ××™×–×•×’ ×”× ×ª×•× ×™× ×××¡×¤×¨ ×¢××•×“×•×ª.\n",
    "\n",
    "×›×œ ×¢××•×“×•×ª ×”×§×œ×˜ ×—×™×™×‘×•×ª ×œ×”×™×•×ª ×××•×ª×• ×¡×•×’ × ×ª×•× ×™×. ×”×“×•×’××” ×©×œ××˜×” ××©×œ×‘×ª ××ª ×”× ×ª×•× ×™× ×-`currentState` ×•-`previousState` ×•×™×•×¦×¨×ª ×¢××•×“×” ×—×“×©×” `states`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import array\n",
    "\n",
    "df.select(df.name, array(df.currentState, df.previousState).alias(\"States\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” array_contains()\n",
    "\n",
    "×¤×•× ×§×¦×™×™×ª SQL `array_contains()` ××©××©×ª ×œ×‘×“×™×§×” ×× ×¢××•×“×ª ××¢×¨×š ××›×™×œ×” ×¢×¨×š.\n",
    "\n",
    "××—×–×™×¨×” `null` ×× ×”××¢×¨×š ×”×•× `null`, `true` ×× ×”××¢×¨×š ××›×™×œ ××ª ×”-`value`, ×•-`false` ××—×¨×ª."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "\n",
    "df.select(df.name, array_contains(df.languagesAtSchool, \"Java\") \\\n",
    "         .alias(\"array_contains\")).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×¡×™×›×•×\n",
    "\n",
    "×œ××“×ª ×©-PySpark ArrayType ×”×•× ×¡×•×’ ××•×¡×£ ×“×•××” ×œ××¢×¨×š ×‘×©×¤×•×ª ××—×¨×•×ª ×”×××—×¡×Ÿ ××ª ××•×ª×• ×¡×•×’ ×©×œ ××œ×× ×˜×™×.\n",
    "\n",
    "ArrayType ××¨×—×™×‘ ××ª ××—×œ×§×ª DataType (×¡×•×¤×¨-×§×œ××¡ ×©×œ ×›×œ ×”×¡×•×’×™× ×‘-PySpark) ×•×œ×•×§×— ×©× ×™ ××¨×’×•×× ×˜×™× ×—×•×‘×”:\n",
    "- `valueType`\n",
    "- `valueContainsNull`\n",
    "\n",
    "×›××• ×›×Ÿ, ×œ××“×ª ×›×™×¦×“ ×œ×”×©×ª××© ×‘×¤×•× ×§×¦×™×•×ª explode ×©×œ PySpark SQL ×–××™× ×•×ª ×œ×¢×‘×•×“×” ×¢× ×¢××•×“×•×ª Array.\n",
    "\n",
    "**×œ×™××•×“ ××”× ×”!!** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- PySpark Convert String to Array Column\n",
    "- PySpark â€“ Convert array column to a String\n",
    "- PySpark â€“ explode nested array into rows\n",
    "- PySpark Explode Array and Map Columns to Rows\n",
    "- PySpark Get Number of Rows and Columns\n",
    "- PySpark NOT isin() or IS NOT IN Operator\n",
    "- PySpark isin() & SQL IN Operator\n",
    "- PySpark printSchema() Example\n",
    "- Explain PySpark element_at() with Examples\n",
    "- Iterate over Elements of Array in PySpark DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
