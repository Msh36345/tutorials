{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# â° PySpark: ×”××¨×ª ××—×¨×•×–×ª ×œ-Timestamp (to_timestamp)\n",
    "[PySpark to_timestamp() â€“ Convert String to Timestamp type](https://sparkbyexamples.com/spark/pyspark-to-timestamp-convert-string-to-timestamp-type/)\n",
    "## ×ª×•×›×Ÿ ×¢× ×™×™× ×™×\n",
    "1. [××‘×•× ×•×ª×—×‘×™×¨ ×”×¤×•× ×§×¦×™×”](#section1)\n",
    "2. [×”××¨×ª ××—×¨×•×–×ª ×œ-Timestamp](#section2)\n",
    "3. [×”××¨×” ×¢× ×¤×•×¨××˜ ××•×ª×× ××™×©×™×ª](#section3)\n",
    "4. [×“×•×’××” ×¢× SQL](#section4)\n",
    "5. [×“×•×’××” ××œ××”](#section5)\n",
    "6. [×©××œ×•×ª × ×¤×•×¦×•×ª](#section6)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `to_timestamp()` ×›×“×™ ×œ×”××™×¨ ××—×¨×•×–×ª ×œ-Timestamp (TimestampType) ×‘-PySpark.\n",
    "\n",
    "×”×–××Ÿ ×©×”×•××¨ ×™×”×™×” ×‘×¤×•×¨××˜ ×‘×¨×™×¨×ª ×”××—×“×œ ×©×œ `MM-dd-yyyy HH:mm:ss.SSS`. \n",
    "\n",
    "×¤×•× ×§×¦×™×” ×–×• × ×¤×•×¦×” ×‘×©×™××•×© ×›××©×¨ ×™×© ×œ×š DataFrame ×¢× ×¢××•×“×” ×”××›×™×œ×” ×ª××¨×™×š ××• timestamp ×‘×¤×•×¨××˜ ××—×¨×•×–×ª, ×•××ª×” ×¨×•×¦×” ×œ×”××™×¨ ××•×ª× ×œ×¡×•×’ × ×ª×•× ×™× ××ª××™× ×™×•×ª×¨ ×©×œ timestamp ××• ×ª××¨×™×š ×œ×¦×•×¨×š × ×™×ª×•×— ××• ×¤×¢×•×œ×•×ª × ×•×¡×¤×•×ª.\n",
    "\n",
    "### âš ï¸ ×—×©×•×‘!\n",
    "×”×§×¤×“ ×œ×”×ª××™× ××ª ×”-`timestamp_format` ×œ×”×ª××™× ×œ×¤×•×¨××˜ ×©×œ ××—×¨×•×–×•×ª ×”-timestamp ×‘× ×ª×•× ×™× ×©×œ×š. ×”×¤×•×¨××˜ ×¦×¨×™×š ×œ×¢×§×•×‘ ××—×¨ ×ª×‘× ×™×ª SimpleDateFormat ×¢×‘×•×¨ ×ª×‘× ×™×•×ª ×ª××¨×™×š ×•×–××Ÿ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## 1ï¸âƒ£ ×ª×—×‘×™×¨ ×”×¤×•× ×§×¦×™×” to_timestamp()\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×œ×¤×•× ×§×¦×™×” ×–×• ×™×© ×©× ×™ ×—×ª×™××•×ª (signatures) ×”××•×’×“×¨×•×ª ×‘-**PySpark SQL Date & Timestamp Functions**:\n",
    "\n",
    "```\n",
    "Syntax: to_timestamp(timestampString:Column)\n",
    "Syntax: to_timestamp(timestampString:Column, format:String)\n",
    "```\n",
    "\n",
    "**×”×—×ª×™××” ×”×¨××©×•× ×”:**\n",
    "- ××§×‘×œ×ª ×¨×§ ××¨×’×•×× ×˜ ××—×“\n",
    "- ×”×¤×•×¨××˜ ×¦×¨×™×š ×œ×”×™×•×ª ×‘×¤×•×¨××˜ Timestamp ×©×œ `'MM-dd-yyyy HH:mm:ss.SSS'`\n",
    "- ×›××©×¨ ×”×¤×•×¨××˜ ××™× ×• ×‘×¤×•×¨××˜ ×–×”, ×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” null\n",
    "\n",
    "**×”×—×ª×™××” ×”×©× ×™×™×”:**\n",
    "- ××§×‘×œ×ª ××¨×’×•×× ×˜ ××—×¨×•×–×ª × ×•×¡×£ ×œ×¦×™×•×Ÿ ×”×¤×•×¨××˜ ×©×œ ×”-Timestamp ×”×§×œ×˜\n",
    "- ×ª×•××›×ª ×‘×¤×•×¨××˜×™× ×”××•×’×“×¨×™× ×‘-SimpleDateFormat\n",
    "- ×‘×××¦×¢×•×ª ××¨×’×•×× ×˜ × ×•×¡×£ ×–×”, × ×™×ª×Ÿ ×œ×”××™×¨ (cast) ××—×¨×•×–×ª ××›×œ ×¤×•×¨××˜ ×œ×¡×•×’ Timestamp ×‘-PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## 2ï¸âƒ£ ×”××¨×ª ××—×¨×•×–×ª ×œ-Timestamp ×‘-PySpark\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×‘×“×•×’××” ×”×‘××”, × ××™×¨ ××ª ×ª×‘× ×™×ª ×”××—×¨×•×–×ª ×©× ××¦××ª ×‘×¤×•×¨××˜ ×‘×¨×™×¨×ª ×”××—×“×œ ×©×œ PySpark ×œ×¡×•×’ Timestamp.\n",
    "\n",
    "××›×™×•×•×Ÿ ×©×¢××•×“×ª ×”×§×œ×˜ ×©×œ DataFrame × ××¦××ª ×‘×¤×•×¨××˜ Timestamp ×‘×¨×™×¨×ª ××—×“×œ, ×× ×• ××©×ª××©×™× ×‘×—×ª×™××” ×”×¨××©×•× ×” ×œ×”××¨×”. ×•×”×“×•×’××” ×”×©× ×™×™×” ××©×ª××©×ª ×‘×¤×•× ×§×¦×™×” `cast()` ×›×“×™ ×œ×¢×©×•×ª ××ª ××•×ª×• ×”×“×‘×¨."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×™×‘×•× ×”×¡×¤×¨×™×•×ª ×”× ×“×¨×©×•×ª\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"stringoperations\").getOrCreate()\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame ×œ×“×•×’××”\n",
    "df = spark.createDataFrame(\n",
    "    data=[('1', '2019-06-24 12:01:19.000')],\n",
    "    schema=[\"id\", \"input_timestamp\"]\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×ª ××—×¨×•×–×ª Timestamp ×œ-DateType\n",
    "df2 = df.withColumn(\n",
    "    'timestamp', \n",
    "    to_timestamp('input_timestamp')\n",
    ")\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-Cast ×œ×”××¨×” ×œ- TimestampType\n",
    "df3 = df.withColumn(\n",
    "    'timestamp',\n",
    "    col('input_timestamp').cast('timestamp')\n",
    ")\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "## 3ï¸âƒ£ ×”××¨×” ×¢× ×¤×•×¨××˜ ××—×¨×•×–×ª ××•×ª×× ××™×©×™×ª ×œ×¡×•×’ Timestamp\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×“×•×’××” ×–×• ×××™×¨×” ××ª ××—×¨×•×–×ª timestamp ×”×§×œ×˜ ××¤×•×¨××˜ ××•×ª×× ××™×©×™×ª ×œ×¡×•×’ PySpark Timestamp.\n",
    "\n",
    "×œ×©× ×›×š, ×× ×• ××©×ª××©×™× ×‘×ª×—×‘×™×¨ ×”×©× ×™ ×©×‘×• ×”×•× ×œ×•×§×— ××¨×’×•×× ×˜ × ×•×¡×£ ×œ×¦×™×•×Ÿ ×ª×‘× ×™×•×ª ××•×’×“×¨×•×ª ×¢×œ ×™×“×™ ×”××©×ª××© ×œ×¢×™×¦×•×‘ ×ª××¨×™×š-×–××Ÿ.\n",
    "\n",
    "### âš ï¸ ×”×¢×¨×” ×—×©×•×‘×”!\n",
    "**×›××©×¨ ×”×ª××¨×™×›×™× ××™× × ×‘×¤×•×¨××˜ TimestampType ×©×œ Spark `'yyyy-MM-dd HH:mm:ss.SSS'`:**\n",
    "\n",
    "××– ×›××©×¨ ×”×ª××¨×™×›×™× ××™× × ×‘×¤×•×¨××˜ Timestamp ×©×œ Spark, ×›×œ ×¤×•× ×§×¦×™×•×ª Spark ××—×–×™×¨×•×ª null. ×œ×›×Ÿ, ×¦×¨×™×š ×ª×—×™×œ×” ×œ×”××™×¨ ××ª ×ª××¨×™×š ×”×§×œ×˜ ×œ×¡×•×’ DateType ×‘×××¦×¢×•×ª ×”×¤×•× ×§×¦×™×” `to_timestamp()` ×•××– ×œ×—×©×‘ ××ª ×”×”×‘×“×œ×™×."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×›××©×¨ ×”×ª××¨×™×›×™× ××™× × ×‘×¤×•×¨××˜ TimestampType ×©×œ Spark 'yyyy-MM-dd HH:mm:ss.SSS'.\n",
    "# ××– ×›××©×¨ ×”×ª××¨×™×›×™× ××™× × ×‘×¤×•×¨××˜ Timestamp ×©×œ Spark, ×›×œ ×¤×•× ×§×¦×™×•×ª Spark ××—×–×™×¨×•×ª null\n",
    "# ×œ×›×Ÿ, ×¦×¨×™×š ×ª×—×™×œ×” ×œ×”××™×¨ ××ª ×ª××¨×™×š ×”×§×œ×˜ ×œ×¡×•×’ Spark DateType ×‘×××¦×¢×•×ª ×¤×•× ×§×¦×™×™×ª to_timestamp\n",
    "\n",
    "df.select(\n",
    "    to_timestamp(\n",
    "        lit('06-24-2019 12:01:19.000'),\n",
    "        'MM-dd-yyyy HH:mm:ss.SSS'\n",
    "    )\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "## 4ï¸âƒ£ ×“×•×’××” ×œ-SQL\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×œ×”×œ×Ÿ ×“×•×’×××•×ª ×“×•××•×ª ×‘×××¦×¢×•×ª PySpark SQL. ×× ××ª×” ××¨×§×¢ SQL, ×”×“×•×’×××•×ª ×”××œ×” ×™×”×™×• ×©×™××•×©×™×•×ª ×¢×‘×•×¨×š.\n",
    "\n",
    "×›××Ÿ, ××©×ª××©×™× ×‘-`spark.sql()` ×›×“×™ ×œ×”×¨×™×¥ ×©××™×œ×ª×•×ª SQL ×‘×××¦×¢×•×ª ×”×¤×•× ×§×¦×™×•×ª ×©×”×¡×‘×¨× ×• ×œ××¢×œ×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - ××—×¨×•×–×ª ×œ-TimestampType\n",
    "spark.sql(\n",
    "    \"select to_timestamp('2019-06-24 12:01:19.000') as timestamp\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - CAST ××—×¨×•×–×ª timestamp ×œ-TimestampType\n",
    "spark.sql(\n",
    "    \"select timestamp('2019-06-24 12:01:19.000') as timestamp\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - ×¤×•×¨××˜ ××—×¨×•×–×ª ××•×ª×× ××™×©×™×ª ×œ-TimestampType\n",
    "spark.sql(\n",
    "    \"select to_timestamp('06-24-2019 12:01:19.000', 'MM-dd-yyyy HH:mm:ss.SSS') as timestamp\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section5\"></a>\n",
    "## 5ï¸âƒ£ ×“×•×’××” ××œ××” - ×§×•×“ ×©×œ× ×œ×”×¤× ×™×” ××”×™×¨×”\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×œ×”×œ×Ÿ ×”×§×•×“ ×”××œ× ×”×›×•×œ×œ ××ª ×›×œ ×”×“×•×’×××•×ª ×©×œ××“× ×• ×‘××“×¨×™×š ×–×”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×§×•×“ ××œ× - ×›×œ ×”×“×•×’×××•×ª ×‘×™×—×“\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    data=[('1', '2019-06-24 12:01:19.000')],\n",
    "    schema=[\"id\", \"input_timestamp\"]\n",
    ")\n",
    "\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Timestamp String ×œ-DateType\n",
    "df.withColumn(\n",
    "    'timestamp', \n",
    "    to_timestamp('input_timestamp')\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-Cast ×œ×”××¨×ª TimestampType ×œ-DateType\n",
    "df.withColumn(\n",
    "    'timestamp', \n",
    "    to_timestamp('input_timestamp').cast('string')\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.select(\n",
    "    to_timestamp(\n",
    "        lit('06-24-2019 12:01:19.000'),\n",
    "        'MM-dd-yyyy HH:mm:ss.SSS'\n",
    "    )\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - ××—×¨×•×–×ª ×œ-TimestampType\n",
    "spark.sql(\n",
    "    \"select to_timestamp('2019-06-24 12:01:19.000') as timestamp\"\n",
    ").show()\n",
    "\n",
    "# SQL - CAST ××—×¨×•×–×ª timestamp ×œ-TimestampType\n",
    "spark.sql(\n",
    "    \"select timestamp('2019-06-24 12:01:19.000') as timestamp\"\n",
    ").show()\n",
    "\n",
    "# SQL - ×¤×•×¨××˜ ××—×¨×•×–×ª ××•×ª×× ××™×©×™×ª ×œ-TimestampType\n",
    "spark.sql(\n",
    "    \"select to_timestamp('06-24-2019 12:01:19.000', 'MM-dd-yyyy HH:mm:ss.SSS') as timestamp\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section6\"></a>\n",
    "## 6ï¸âƒ£ ×©××œ×•×ª × ×¤×•×¦×•×ª ×¢×œ to_timestamp()\n",
    "\n",
    "### â“ ×›×™×¦×“ ×œ×˜×¤×œ ×‘××™×“×¢ ××–×•×¨ ×–××Ÿ ×¢× to_timestamp() ×‘-PySpark?\n",
    "\n",
    "× ×™×ª×Ÿ ×œ×¦×™×™×Ÿ ××–×•×¨ ×–××Ÿ ×‘×¢×ª ×”××¨×ª timestamps. ×œ×“×•×’××”, × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘-`to_timestamp` ×¢× `timestamp_format` ×•-`timezone` functions ×œ×˜×™×¤×•×œ ×‘××–×•×¨×™ ×–××Ÿ.\n",
    "\n",
    "### â“ ××” ×§×•×¨×” ×× ×”×¤×•×¨××˜ ×©×¦×•×™×Ÿ ×‘-to_timestamp() ×œ× ×ª×•×× ××ª ×¤×•×¨××˜ ××—×¨×•×–×ª ×”×§×œ×˜?\n",
    "\n",
    "×× ×”×¤×•×¨××˜ ×œ× ×ª×•××, ×”×¤×•× ×§×¦×™×” ×¢×œ×•×œ×” ×œ×”×¢×œ×•×ª ×©×’×™××” ××• ×œ×™×™×¦×¨ ×ª×•×¦××•×ª ×©×’×•×™×•×ª. ×—×™×•× ×™ ×œ×¡×¤×§ ××ª ×”×¤×•×¨××˜ ×”× ×›×•×Ÿ ×œ×”××¨×” ××“×•×™×§×ª.\n",
    "\n",
    "### â“ ×”×× to_timestamp() case-sensitive ×‘×¢×ª ×”×ª×××ª ××œ×× ×˜×™ ×¤×•×¨××˜?\n",
    "\n",
    "×›×Ÿ, `to_timestamp()` ×”×•× case-sensitive ×œ××œ×× ×˜×™ ×¤×•×¨××˜. ××œ×× ×˜×™ ×¤×•×¨××˜ ×›××• \"yyyy\", \"MM\", ×•-\"dd\" ×—×™×™×‘×™× ×œ×”×ª××™× ×œ-case ×‘×ª×‘× ×™×ª ×”×§×œ×˜.\n",
    "\n",
    "### â“ ××” ×”×•× ×¡×•×’ × ×ª×•× ×™ ×”×ª×•×¦××” ×‘×¢×ª ×©×™××•×© ×‘-to_timestamp() ×‘-PySpark?\n",
    "\n",
    "×”×ª×•×¦××” ×©×œ ×©×™××•×© ×‘-`to_timestamp()` ×”×™× ×¢××•×“×” ×”××›×™×œ×” timestamps ××• ×ª××¨×™×›×™×, ×ª×œ×•×™ ×‘×¤×•×¨××˜ ×©×¦×•×™×Ÿ, ×¢× ×”-`TimestampType` ××• `DateType` ×›×¡×•×’ ×”× ×ª×•× ×™×, ×‘×”×ª×××”.\n",
    "\n",
    "**ğŸ‰ ×œ××™×“×” ××”× ×”!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- [PySpark SQL â€“ How to Get Current Date & Timestamp](https://sparkbyexamples.com/pyspark/pyspark-sql-how-to-get-current-date-timestamp/)\n",
    "- [PySpark Timestamp Difference (seconds, minutes, hours)](https://sparkbyexamples.com/pyspark/pyspark-timestamp-difference/)\n",
    "- [PySpark SQL â€“ Working with Unix Time](https://sparkbyexamples.com/pyspark/pyspark-sql-unix-timestamp/)\n",
    "- [PySpark SQL â€“ Date and Timestamp Functions](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/)\n",
    "- [PySpark SQL â€“ Convert Date to String Format](https://sparkbyexamples.com/pyspark/pyspark-sql-convert-date-to-string-format/)\n",
    "- [PySpark SQL â€“ Convert String to Date Format](https://sparkbyexamples.com/pyspark/pyspark-sql-convert-string-to-date-format/)\n",
    "- [PySpark SQL â€“ Convert Timestamp to Date](https://sparkbyexamples.com/pyspark/pyspark-to-date-convert-timestamp-to-date/)\n",
    "- [PySpark SQL â€“ Working with Unix Time | Timestamp](https://sparkbyexamples.com/pyspark/pyspark-sql-unix-timestamp/)\n",
    "- [PySpark SQL expr() (Expression) Function](https://sparkbyexamples.com/pyspark/pyspark-sql-expr-expression-function/)\n",
    "- [PySpark SQL Date and Timestamp Functions](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/)\n",
    "\n",
    "---\n",
    "\n",
    "**Â© SparkByExamples.com - All rights reserved**\n",
    "\n",
    "*××“×¨×™×š ×–×” ×ª×•×¨×’× ×•×¢×•×‘×“ ×œ×¢×‘×¨×™×ª ×œ××˜×¨×•×ª ×œ×™××•×“*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
