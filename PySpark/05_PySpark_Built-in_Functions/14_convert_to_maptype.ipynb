{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸ—ºï¸ PySpark - ×”××¨×ª ×¢××•×“×•×ª DataFrame ×œ-MapType (Dict)\n",
    "[PySpark Convert DataFrame Columns to MapType (Dict)](https://sparkbyexamples.com/pyspark/pyspark-convert-dataframe-columns-to-maptype-dict/)\n",
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "×›×“×™ ×œ×”××™×¨ ×¢××•×“×•×ª DataFrame ×œ-`MapType` (××™×œ×•×Ÿ/dictionary) ×‘-PySpark, ×ª×•×›×œ ×œ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `create_map` ×××•×“×•×œ `pyspark.sql.functions`.\n",
    "\n",
    "×¤×•× ×§×¦×™×” ×–×• ×××¤×©×¨×ª ×œ×š ×œ×™×¦×•×¨ ××¢×¨×›×ª ××–×•×’×•×ª ××¤×ª×—-×¢×¨×š, ×›××©×¨ ×”××¤×ª×—×•×ª ×•×”×¢×¨×›×™× ×”× ×¢××•×“×•×ª ××”-DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ×™×¦×™×¨×ª DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:02:48.516635Z",
     "start_time": "2025-11-12T14:02:48.507838Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:07:30.285265Z",
     "start_time": "2025-11-12T14:07:30.036816Z"
    }
   },
   "source": [
    "data = [\n",
    "    (\"36636\", \"Finance\", 3000, \"USA\"),\n",
    "    (\"40288\", \"Finance\", 5000, \"IND\"),\n",
    "    (\"42114\", \"Sales\", 3900, \"USA\"),\n",
    "    (\"39192\", \"Marketing\", 2500, \"CAN\"),\n",
    "    (\"34534\", \"Sales\", 6500, \"USA\")\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('dept', StringType(), True),\n",
    "    StructField('salary', IntegerType(), True),\n",
    "    StructField('location', StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n",
      "+-----+---------+------+--------+\n",
      "|id   |dept     |salary|location|\n",
      "+-----+---------+------+--------+\n",
      "|36636|Finance  |3000  |USA     |\n",
      "|40288|Finance  |5000  |IND     |\n",
      "|42114|Sales    |3900  |USA     |\n",
      "|39192|Marketing|2500  |CAN     |\n",
      "|34534|Sales    |6500  |USA     |\n",
      "+-----+---------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ×”××¨×ª ×¢××•×“×•×ª DataFrame ×œ-MapType\n",
    "\n",
    "×›×¢×ª, ×‘×•××• × ×©×ª××© ×‘×¤×•× ×§×¦×™×” SQL `create_map()` ×›×“×™ ×œ×”××™×¨ ×¢××•×“×•×ª DataFrame **salary** ×•-**location** ×œ-MapType."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:07:32.402626Z",
     "start_time": "2025-11-12T14:07:32.189192Z"
    }
   },
   "source": [
    "# Convert columns to Map\n",
    "from pyspark.sql.functions import col, lit, create_map\n",
    "\n",
    "df = df.withColumn(\"propertiesMap\", create_map(\n",
    "    lit(\"salary\"), col(\"salary\").cast(\"string\"),\n",
    "    lit(\"location\"), col(\"location\").cast(\"string\")\n",
    "))\n",
    "df = df.drop(\"salary\", \"location\")\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- propertiesMap: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+-----+---------+---------------------------------+\n",
      "|id   |dept     |propertiesMap                    |\n",
      "+-----+---------+---------------------------------+\n",
      "|36636|Finance  |{salary -> 3000, location -> USA}|\n",
      "|40288|Finance  |{salary -> 5000, location -> IND}|\n",
      "|42114|Sales    |{salary -> 3900, location -> USA}|\n",
      "|39192|Marketing|{salary -> 2500, location -> CAN}|\n",
      "|34534|Sales    |{salary -> 6500, location -> USA}|\n",
      "+-----+---------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×œ××™×“×” ××”× ×”!!** ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- PySpark Convert StructType (struct) to Dictionary/MapType (map)\n",
    "- PySpark StructType & StructField Explained with Examples\n",
    "- PySpark Create DataFrame From Dictionary (Dict)\n",
    "- PySpark Convert Dictionary/Map to Multiple Columns\n",
    "- PySpark Explode Array and Map Columns to Rows\n",
    "- PySpark mapPartitions() Examples\n",
    "- PySpark MapType (Dict) Usage with Examples\n",
    "- PySpark flatMap() Transformation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
