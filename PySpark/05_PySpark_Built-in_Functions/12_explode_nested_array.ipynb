{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸš€ PySpark - Explode ××¢×¨×š ××§×•× ×Ÿ ×œ×©×•×¨×•×ª\n",
    "[PySpark â€“ explode nested array into rows](https://sparkbyexamples.com/pyspark/pyspark-explode-nested-array-into-rows/)\n",
    "## ğŸ“‹ ×¡×§×™×¨×” ×›×œ×œ×™×ª\n",
    "\n",
    "**×‘×¢×™×”:** ×›×™×¦×“ ×œ×”×¤×•×š ×•×œ×©×˜×— ××¢×¨×š ××§×•× ×Ÿ (Array of Array) ×©×œ ×¢××•×“×•×ª DataFrame ×œ×©×•×¨×•×ª ×‘×××¦×¢×•×ª PySpark?\n",
    "\n",
    "**×¤×ª×¨×•×Ÿ:** × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `explode()` ×©×œ PySpark ×›×“×™ ×œ×”×¤×•×š Array of Array (××¢×¨×š ××§×•× ×Ÿ) ×œ×©×•×¨×•×ª ×‘-DataFrame ×‘×××¦×¢×•×ª ×“×•×’××ª Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ××” ×–×” explode?\n",
    "\n",
    "×¤×•× ×§×¦×™×™×ª `explode()` ×™×›×•×œ×” ×œ×©××© ×œ×”×¤×™×›×ª ××¢×¨×š ××§×•× ×Ÿ ×œ×©×•×¨×•×ª. ×œ×¤× ×™ ×©× ×ª×—×™×œ, ×‘×•××• × ×™×¦×•×¨ DataFrame ×¢× ×¢××•×“×ª ××¢×¨×š ××§×•× ×Ÿ.\n",
    "\n",
    "××”×“×•×’××” ×”×‘××”, ×¢××•×“×ª **\"subjects\"** ×”×™× ××¢×¨×š ×©×œ ArrayType ××©×¨ ××›×™×œ ××¢×¨×š ××§×•× ×Ÿ ×©×œ ×¨×›×™×‘×™ ××—×¨×•×–×ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ×™×¦×™×¨×ª DataFrame ×œ×“×•×’××”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "arrayArrayData = [\n",
    "    (\"James\", [[\"Java\", \"Scala\", \"C++\"], [\"Spark\", \"Java\"]]),\n",
    "    (\"Michael\", [[\"Spark\", \"Java\", \"C++\"], [\"Spark\", \"Java\"]]),\n",
    "    (\"Robert\", [[\"CSharp\", \"VB\"], [\"Spark\", \"Python\"]])\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data=arrayArrayData, schema=['name', 'subjects'])\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ×©×™××•×© ×‘-explode() ×œ×”×¤×™×›×ª ××¢×¨×š ××§×•× ×Ÿ ×œ×©×•×¨×•×ª\n",
    "\n",
    "×›×¢×ª, ×‘×•××• × ×¤×•×¦×¥ ××ª ×¢××•×“×ª ×”××¢×¨×š **\"subjects\"** ×œ××¢×¨×š ×©×•×¨×•×ª. ×œ××—×¨ ×”×¤×™×¦×•×¥, ×–×” ×™×•×¦×¨ ×¢××•×“×” ×—×“×©×” **'col'** ×¢× ×©×•×¨×•×ª ××™×™×¦×’×•×ª ××¢×¨×š."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df.select(df.name, explode(df.subjects)).show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” ×©×™××•×© ×‘-flatten() ×œ×©×˜×•×— ×”××¢×¨×š\n",
    "\n",
    "×× ×‘×¨×¦×•× ×š ×œ×©×˜×— ××ª ×”××¢×¨×›×™×, ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” `flatten()`, ×”×××™×¨×” ××¢×¨×š ×©×œ ××¢×¨×›×™× ×œ××¢×¨×š ×‘×•×“×“ ×‘-DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import flatten\n",
    "\n",
    "df.select(df.name, flatten(df.subjects)).show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×¡×™×›×•×\n",
    "\n",
    "×œ××“×ª ×©-PySpark ArrayType (××¢×¨×š ××§×•× ×Ÿ) ×™×›×•×œ ×œ×”×™×¤×•×š ×œ×©×•×¨×•×ª ×¢×œ-×™×“×™ ×©×™××•×© ×‘×¤×•× ×§×¦×™×” `explode()` ×©×œ PySpark ×‘-DataFrame.\n",
    "\n",
    "**×œ×™××•×“ ××”× ×”!!** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- PySpark Explode Array and Map Columns to Rows\n",
    "- PySpark ArrayType Column With Example\n",
    "- PySpark Convert Dictionary/Map to Multiple Columns\n",
    "- PySpark â€“ Convert array column to a String\n",
    "- PySpark Check Column Exists in DataFrame\n",
    "- PySpark Select Nested struct Columns\n",
    "- PySpark Get Number of Rows and Columns\n",
    "- PySpark Find Maximum Row per Group in DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
