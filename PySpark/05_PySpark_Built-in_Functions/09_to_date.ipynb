{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸ“… PySpark: ×”××¨×ª Timestamp ×œ-Date (to_date)\n",
    "[PySpark to_date() â€“ Convert Timestamp to Date](https://sparkbyexamples.com/pyspark/pyspark-to-date-convert-timestamp-to-date/)\n",
    "## ×ª×•×›×Ÿ ×¢× ×™×™× ×™×\n",
    "1. [××‘×•× ×•×ª×—×‘×™×¨ ×”×¤×•× ×§×¦×™×”](#section1)\n",
    "2. [×©×™××•×© ×‘-to_date() - ×”××¨×ª Timestamp String ×œ-Date](#section2)\n",
    "3. [×”××¨×ª TimestampType ×œ-DateType](#section3)\n",
    "4. [×©×™××•×© ×‘×¤×•× ×§×¦×™×” cast()](#section4)\n",
    "5. [PySpark SQL - ×”××¨×ª Timestamp ×œ-Date](#section5)\n",
    "6. [×§×•×“ ××œ×](#section6)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ××‘×•×\n",
    "\n",
    "×¤×•× ×§×¦×™×•×ª PySpark ××¡×¤×§×•×ª ××ª ×”×¤×•× ×§×¦×™×” `to_date()` ×œ×”××¨×ª timestamp ×œ×ª××¨×™×š (DateType).\n",
    "\n",
    "×–×” ××•×©×’ ×‘××•×¤×Ÿ ××™×“×™××œ×™ ×¢×œ ×™×“×™ **×§×™×¦×•×¥** (truncating) ×—×œ×§ ×”×–××Ÿ ××¢××•×“×ª ×”-Timestamp.\n",
    "\n",
    "×‘××“×¨×™×š ×–×”, ××¨××” ×œ×š ×“×•×’××ª PySpark ×›×™×¦×“ ×œ×”××™×¨ timestamp ×œ×ª××¨×™×š (date) ×‘-DataFrame ×•-SQL.\n",
    "\n",
    "### ğŸ’¡ ×œ×™×“×¢\n",
    "×”×¤×•× ×§×¦×™×” `to_date()` ××‘×¦×¢×ª ×§×™×¦×•×¥ ×©×œ ×—×œ×§ ×”×–××Ÿ ×•××©××™×¨×” ×¨×§ ××ª ×”×ª××¨×™×š ×‘×¤×•×¨××˜ DateType."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## 1ï¸âƒ£ ×ª×—×‘×™×¨ ×”×¤×•× ×§×¦×™×” to_date()\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "```python\n",
    "Syntax: to_date(timestamp_column)\n",
    "Syntax: to_date(timestamp_column, format)\n",
    "```\n",
    "\n",
    "**PySpark timestamp (TimestampType)** ××•×¨×›×‘ ××¢×¨×š ×‘×¤×•×¨××˜ `yyyy-MM-dd HH:mm:ss.SSS` \n",
    "\n",
    "×•-**Date (DateType)** ×‘×¤×•×¨××˜ `yyyy-MM-dd`.\n",
    "\n",
    "×”×©×ª××© ×‘-`to_date()` ×›×“×™ ×œ×§×¦×¥ ×–××Ÿ ×-Timestamp ××• ×œ×”××™×¨ ××ª ×”-timestamp ×œ×ª××¨×™×š ×¢×œ ×¢××•×“×ª DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ ×”×›× ×ª ×”×¡×‘×™×‘×” ×•×˜×¢×™× ×ª × ×ª×•× ×™×\n",
    "\n",
    "×¨××©×™×ª, × ×™×¦×•×¨ DataFrame ×¢× ×¢××•×“×ª timestamp ×©× ×©×ª××© ×‘×” ×œ×›×œ ×”×“×•×’×××•×ª:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×¦×™×¨×ª DataFrame ×œ×“×•×’××”\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    data=[('1', '2019-06-24 12:01:19.000')],\n",
    "    schema=[\"id\", \"input_timestamp\"]\n",
    ")\n",
    "\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## 2ï¸âƒ£ ×©×™××•×© ×‘-to_date() - ×”××¨×ª Timestamp String ×œ-Date\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×‘×“×•×’××” ×–×•, × ×©×ª××© ×‘×¤×•× ×§×¦×™×” `to_date()` ×›×“×™ ×œ×”××™×¨ ×¢××•×“×ª `TimestampType` (××• string) ×œ-`DateType` column.\n",
    "\n",
    "×”×§×œ×˜ ×œ×¤×•× ×§×¦×™×” ×–×• ×¦×¨×™×š ×œ×”×™×•×ª ×¢××•×“×ª timestamp ××• string ×‘×¤×•×¨××˜ TimestampType, ×•×”×™× ××—×–×™×¨×” ×¨×§ ×¢××•×“×” ×‘×¤×•×¨××˜ DateType."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”××¨×ª Timestamp String ×œ-Date Type\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df2 = df.withColumn(\n",
    "    'date_type', \n",
    "    to_date('input_timestamp')\n",
    ")\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "## 3ï¸âƒ£ ×”××¨×ª TimestampType (timestamp) ×œ-DateType (date)\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×“×•×’××” ×–×• ×××™×¨×” ××ª ×¢××•×“×ª PySpark TimestampType ×œ-DateType."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Timestamp type ×œ-DateType\n",
    "df3 = df.withColumn(\n",
    "    'ts', \n",
    "    to_timestamp(col('input_timestamp'))\n",
    ").withColumn(\n",
    "    'datetype', \n",
    "    to_date(col('ts'))\n",
    ")\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "## 4ï¸âƒ£ ×©×™××•×© ×‘×¤×•× ×§×¦×™×™×ª cast() ×œ×”××¨×ª Timestamp ×œ-Date\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×”× ×” ×“×¨×š × ×•×¡×¤×ª ×œ×”××™×¨ Timestamp string ×œ-DateType ×‘×××¦×¢×•×ª ×¤×•× ×§×¦×™×™×ª `cast()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-Cast ×œ×”××¨×ª Timestamp String ×œ-DateType\n",
    "df4 = df.withColumn(\n",
    "    'date_type', \n",
    "    col('input_timestamp').cast('date')\n",
    ")\n",
    "df4.printSchema()\n",
    "df4.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-Cast ×œ×”××¨×ª TimestampType ×œ-DateType\n",
    "df5 = df.withColumn(\n",
    "    'date_type', \n",
    "    to_timestamp('input_timestamp').cast('date')\n",
    ")\n",
    "df5.printSchema()\n",
    "df5.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section5\"></a>\n",
    "## 5ï¸âƒ£ PySpark SQL - ×”××¨×ª Timestamp ×œ-Date\n",
    "\n",
    "### ğŸ“ ×”×¡×‘×¨\n",
    "\n",
    "×œ×”×œ×Ÿ ×“×•×’×××•×ª ×“×•××•×ª ×‘×××¦×¢×•×ª PySpark SQL. ×× ××ª×” ××¨×§×¢ SQL, ×”×“×•×’×××•×ª ×”××œ×” ×™×”×™×• ×©×™××•×©×™×•×ª."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - TimestampType ×œ-DateType\n",
    "spark.sql(\n",
    "    \"select to_date(current_timestamp) as date_type\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - CAST TimestampType ×œ-DateType\n",
    "spark.sql(\n",
    "    \"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - CAST timestamp string ×œ-DateType\n",
    "spark.sql(\n",
    "    \"select date('2019-06-24 12:01:19.000') as date_type\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - Timestamp String (×¤×•×¨××˜ ×‘×¨×™×¨×ª ××—×“×œ) ×œ-DateType\n",
    "spark.sql(\n",
    "    \"select to_date('2019-06-24 12:01:19.000') as date_type\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - ×¤×•×¨××˜ Timestamp ××•×ª×× ××™×©×™×ª ×œ-DateType\n",
    "spark.sql(\n",
    "    \"select to_date('06-24-2019 12:01:19.000', 'MM-dd-yyyy HH:mm:ss.SSS') as date_type\"\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section6\"></a>\n",
    "## 6ï¸âƒ£ ×§×•×“ ××œ×\n",
    "\n",
    "### ğŸ“ ×“×•×’××” ××œ××”\n",
    "\n",
    "×œ×”×œ×Ÿ ×”×§×•×“ ×”××œ× ×¢× ×›×œ ×”×“×•×’×××•×ª:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×§×•×“ ××œ× - ×›×œ ×”×“×•×’×××•×ª\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    data=[('1', '2019-06-24 12:01:19.000')],\n",
    "    schema=[\"id\", \"input_timestamp\"]\n",
    ")\n",
    "\n",
    "df.printSchema()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# ×©×™××•×© ×‘-Cast ×œ×”××¨×ª Timestamp String ×œ-DateType\n",
    "df.withColumn(\n",
    "    'date_type', \n",
    "    col('input_timestamp').cast('date')\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-Cast ×œ×”××¨×ª TimestampType ×œ-DateType\n",
    "df.withColumn(\n",
    "    'date_type', \n",
    "    to_timestamp('input_timestamp').cast('date')\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.select(\n",
    "    to_date(\n",
    "        lit('06-24-2019 12:01:19.000'),\n",
    "        'MM-dd-yyyy HH:mm:ss.SSS'\n",
    "    )\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×¤×•×¨××˜ Timestamp ××•×ª×× ××™×©×™×ª ×œ-DateType\n",
    "df.select(\n",
    "    to_date(\n",
    "        lit('06-24-2019 12:01:19.000'),\n",
    "        'MM-dd-yyyy HH:mm:ss.SSS'\n",
    "    )\n",
    ").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Timestamp String ×œ-DateType\n",
    "df.withColumn(\n",
    "    'date_type', \n",
    "    to_date('input_timestamp')\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Timestamp Type ×œ-DateType\n",
    "df.withColumn(\n",
    "    'date_type', \n",
    "    to_date(current_timestamp())\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.withColumn(\n",
    "    'ts', \n",
    "    to_timestamp(col('input_timestamp'))\n",
    ").withColumn(\n",
    "    'datetype', \n",
    "    to_date(col('ts'))\n",
    ").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SQL - TimestampType ×œ-DateType\n",
    "spark.sql(\"select to_date(current_timestamp) as date_type\").show()\n",
    "\n",
    "# SQL - CAST TimestampType ×œ-DateType\n",
    "spark.sql(\"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\").show()\n",
    "\n",
    "# SQL - CAST timestamp string ×œ-DateType\n",
    "spark.sql(\"select date('2019-06-24 12:01:19.000') as date_type\").show()\n",
    "\n",
    "# SQL - Timestamp String (×¤×•×¨××˜ ×‘×¨×™×¨×ª ××—×“×œ) ×œ-DateType\n",
    "spark.sql(\"select to_date('2019-06-24 12:01:19.000') as date_type\").show()\n",
    "\n",
    "# SQL - ×¤×•×¨××˜ Timestamp ××•×ª×× ××™×©×™×ª ×œ-DateType\n",
    "spark.sql(\"select to_date('06-24-2019 12:01:19.000', 'MM-dd-yyyy HH:mm:ss.SSS') as date_type\").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ ×¡×™×›×•×\n",
    "\n",
    "×‘××“×¨×™×š ×–×” ×œ××“×ª ×›×™×¦×“ ×œ×”××™×¨ timestamp ×œ×ª××¨×™×š ×‘×××¦×¢×•×ª:\n",
    "- âœ… ×¤×•× ×§×¦×™×•×ª `to_date()` ×•-`cast()`\n",
    "- âœ… ×“×•×’×××•×ª DataFrame ×•-SQL\n",
    "\n",
    "**ğŸ‰ ×œ××™×“×” ××”× ×”!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "\n",
    "- [PySpark SQL â€“ How to Get Current Date & Timestamp](https://sparkbyexamples.com/pyspark/pyspark-sql-how-to-get-current-date-timestamp/)\n",
    "- [PySpark SQL â€“ Date and Timestamp Functions](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/)\n",
    "- [PySpark SQL â€“ Convert Date to String Format](https://sparkbyexamples.com/pyspark/pyspark-sql-convert-date-to-string-format/)\n",
    "- [PySpark SQL â€“ Convert String to Date Format](https://sparkbyexamples.com/pyspark/pyspark-sql-convert-string-to-date-format/)\n",
    "- [PySpark â€“ Difference between two dates (days, months, years)](https://sparkbyexamples.com/pyspark/pyspark-difference-between-two-dates/)\n",
    "- [PySpark Timestamp Difference (seconds, minutes, hours)](https://sparkbyexamples.com/pyspark/pyspark-timestamp-difference/)\n",
    "- [PySpark â€“ How to Get Current Date & Timestamp](https://sparkbyexamples.com/pyspark/pyspark-sql-how-to-get-current-date-timestamp/)\n",
    "- [How to Create a PySpark DataFrame with a Timestamp Column for a Date Range?](https://sparkbyexamples.com/pyspark/pyspark-create-dataframe-timestamp-column-date-range/)\n",
    "- [Pyspark to_date() vs date_format()](https://sparkbyexamples.com/pyspark/pyspark-to-date-vs-date-format/)\n",
    "\n",
    "---\n",
    "\n",
    "**Â© SparkByExamples.com - All rights reserved**\n",
    "\n",
    "*××“×¨×™×š ×–×” ×ª×•×¨×’× ×•×¢×•×‘×“ ×œ×¢×‘×¨×™×ª ×œ××˜×¨×•×ª ×œ×™××•×“*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
