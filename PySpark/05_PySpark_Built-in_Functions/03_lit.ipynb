{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸ”¢ PySpark - lit() - ×”×•×¡×¤×ª ×¢×¨×›×™× ×§×‘×•×¢×™× ×œ-DataFrame\n",
    "[PySpark lit() â€“ Add Literal or Constant to DataFrame](https://sparkbyexamples.com/pyspark/pyspark-lit-add-literal-constant/)\n",
    "## ×ª×•×›×Ÿ ×¢× ×™×™× ×™×\n",
    "1. [×”×§×“××”](#introduction)\n",
    "2. [×”×‘×“×œ ×‘×™×Ÿ lit() ×œ-typedLit()](#difference)\n",
    "3. [×“×•×’××” 1: ×©×™××•×© ×‘×¡×™×¡×™ ×‘-lit()](#example1)\n",
    "4. [×“×•×’××” 2: lit() ×¢× withColumn()](#example2)\n",
    "5. [×“×•×’××” ××œ××”](#complete-example)\n",
    "6. [×©××œ×•×ª × ×¤×•×¦×•×ª](#faq)\n",
    "7. [××§×•×¨×•×ª](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ×”×§×“××” <a id='introduction'></a>\n",
    "\n",
    "**PySpark SQL** ××¡×¤×§×ª ×©×ª×™ ×¤×•× ×§×¦×™×•×ª - `lit()` ×•-`typedLit()` - ×”××©××©×•×ª ×œ×”×•×¡×¤×ª ×¢××•×“×” ×¢× ×¢×¨×š ×§×‘×•×¢ (literal ××• constant) ×œ-DataFrame.\n",
    "\n",
    "×©×ª×™ ×”×¤×•× ×§×¦×™×•×ª ××—×–×™×¨×•×ª ××•×‘×™×™×§×˜ ××¡×•×’ `Column`. ×”×¤×•× ×§×¦×™×” `typedLit()` ××˜×¤×œ×ª ×’× ×‘×¡×•×’×™ ×§×•×œ×§×¦×™×•×ª (××¢×¨×›×™×, ××™×œ×•× ×™× ×•×›×•').\n",
    "\n",
    "×©×ª×™×”×Ÿ ×–××™× ×•×ª ×‘-PySpark ×¢×œ ×™×“×™ ×™×™×‘×•× `pyspark.sql.functions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ×™×™×‘×•× ×¡×¤×¨×™×•×ª ×•×”×›× ×ª × ×ª×•× ×™×\n",
    "\n",
    "×¨××©×™×ª, × ×™×™×‘× ××ª ×”×¡×¤×¨×™×•×ª ×”× ×“×¨×©×•×ª ×•× ×™×¦×•×¨ DataFrame ×œ×“×•×’××”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame\n",
    "data = [(\"111\", 50000), (\"222\", 60000), (\"333\", 40000)]\n",
    "columns = [\"EmpId\", \"Salary\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ×”×‘×“×œ ×‘×™×Ÿ lit() ×œ-typedLit() <a id='difference'></a>\n",
    "\n",
    "### lit() Function\n",
    "**××˜×¨×”:** ×™×•×¦×¨×ª `[[Column]]` ×©×œ ×¢×¨×š literal.\n",
    "\n",
    "×”××•×‘×™×™×§×˜ ×©××•×¢×‘×¨ ××•××¨ ×™×©×™×¨×•×ª ×× ×”×•× ×›×‘×¨ `[[Column]]`. ×× ×”××•×‘×™×™×§×˜ ×”×•× Scala Symbol, ×”×•× ××•××¨ ×œ-`[[Column]]` ×’× ×›×Ÿ. ××—×¨×ª, `[[Column]]` ×—×“×© × ×•×¦×¨ ×›×“×™ ×œ×™×™×¦×’ ××ª ×”×¢×¨×š ×”×œ×™×˜×¨×œ.\n",
    "\n",
    "### typedLit() Function\n",
    "**×”×‘×“×œ:** ×”-`typedLit()` ×™×›×•×œ ×œ×˜×¤×œ ×‘×¡×•×’×™ ×§×•×œ×§×¦×™×” ×›××• Array, Dictionary(map), ×•×›×•'. \n",
    "\n",
    "×œ×“×•×’××”:\n",
    "```python\n",
    "df4 = df.withColumn(\"lit_value3\", typedLit((\"flag\", StringType())))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ ×“×•×’××” 1: ×©×™××•×© ×‘×¡×™×¡×™ ×‘-lit() <a id='example1'></a>\n",
    "\n",
    "×‘×“×•×’××” ×”×‘××”, ×× ×—× ×• ××©×ª××©×™× ×‘-`lit()` ×©×œ Spark SQL ×›×“×™ ×œ×”×•×¡×™×£ ×¢××•×“×” ×¢× ×¢×¨×š ×§×‘×•×¢ '1' ×œ-PySpark DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# ×”×•×¡×¤×ª ×¢××•×“×” ×§×‘×•×¢×”\n",
    "df2 = df.select(col(\"EmpId\"), col(\"Salary\"), lit(\"1\").alias(\"lit_value1\"))\n",
    "df2.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‹ ×”×¡×‘×¨ ×”×¤×œ×˜:\n",
    "×”×§×•×“ ×œ××¢×œ×” ××•×¡×™×£ ×¢××•×“×” ×—×“×©×” `lit_value1` ×¢× ×”×¢×¨×š ×”×§×‘×•×¢ '1' ×œ×›×œ ×”×©×•×¨×•×ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¨ ×“×•×’××” 2: lit() ×¢× withColumn() <a id='example2'></a>\n",
    "\n",
    "×”×“×•×’××” ×”×‘××” ××¨××” ××™×š ×œ×”×©×ª××© ×‘-`lit()` ×¢× `withColumn()` ×›×“×™ ×œ×™×¦×•×¨ ×¢××•×“×” ×—×“×©×” ×¢×œ ×‘×¡×™×¡ ×ª× ××™:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import when, lit, col\n",
    "\n",
    "# ×©×™××•×© ×‘-lit() ×¢× ×ª× ××™ when\n",
    "df3 = (df\n",
    "       .withColumn(\"lit_value2\",\n",
    "                   when((col(\"Salary\") >=40000) & (col(\"Salary\") <= 50000),\n",
    "                        lit(\"100\")).otherwise(lit(\"200\"))))\n",
    "\n",
    "df3.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×“×•×’××” ××œ××” <a id='complete-example'></a>\n",
    "\n",
    "×”× ×” ×“×•×’××” ××§×™×¤×” ×”××©×œ×‘×ª ××ª ×›×œ ××” ×©×œ××“× ×•:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "data = [(\"111\", 50000), (\"222\", 60000), (\"333\", 40000)]\n",
    "columns = [\"EmpId\", \"Salary\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "# ×©×™××•×© ×‘-lit() ×‘×¡×™×¡×™\n",
    "from pyspark.sql.functions import col, lit\n",
    "df2 = df.select(col(\"EmpId\"), col(\"Salary\"), lit(\"1\").alias(\"lit_value1\"))\n",
    "df2.show(truncate=False)\n",
    "\n",
    "# ×©×™××•×© ×‘-lit() ×¢× when\n",
    "from pyspark.sql.functions import when\n",
    "df3 = df2.withColumn(\n",
    "    \"lit_value2\",\n",
    "    when((col(\"Salary\") >= 40000) & (col(\"Salary\") <= 50000),lit(\"100\")).otherwise(lit(\"200\")))\n",
    "\n",
    "df3.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ ×©××œ×•×ª × ×¤×•×¦×•×ª (FAQ) <a id='faq'></a>\n",
    "\n",
    "### ×”×× × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘-lit() ×¢× ×¡×•×’×™× ×©×•× ×™× ×©×œ ×¢×¨×›×™× ×§×‘×•×¢×™×?\n",
    "\n",
    "**×ª×©×•×‘×”:** ×›×Ÿ! `lit()` ×™×›×•×œ ×œ×©××© ×¢× ×¡×•×’×™ ×¢×¨×›×™× ×©×•× ×™×, ×›×•×œ×œ ××—×¨×•×–×•×ª, ××¡×¤×¨×™× ×©×œ××™×, ×¦×¤×™× ×•-booleans.\n",
    "\n",
    "### ××” ×”×”×‘×“×œ ×‘×™×Ÿ lit() ×œ-expr() ×‘-PySpark?\n",
    "\n",
    "**×ª×©×•×‘×”:** `lit()` ××©××© ×œ×™×¦×™×¨×ª ×¢××•×“×” ×¢× ×¢×¨×š literal ×§×‘×•×¢, ×‘×¢×•×“ `expr()` ×”×•× ×¨×‘-×ª×›×œ×™×ª×™ ×™×•×ª×¨ ×•×™×›×•×œ ×œ×‘×˜× ×˜×¨× ×¡×¤×•×¨××¦×™×•×ª ×•×—×™×©×•×‘×™× ××•×¨×›×‘×™× ×”×›×•×œ×œ×™× ×‘×™×˜×•×™×™× ×©×œ ×¢××•×“×•×ª.\n",
    "\n",
    "### ×”×× × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘-lit() ×›×“×™ ×œ×™×¦×•×¨ ×¢××•×“×ª ××™× ×“×™×§×˜×•×¨ ×‘×™× ××¨×™?\n",
    "\n",
    "**×ª×©×•×‘×”:** ×›×Ÿ! `lit()` ××©××© ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×œ×™×¦×™×¨×ª ×¢××•×“×•×ª ××™× ×“×™×§×˜×•×¨ ×‘×™× ×¨×™×•×ª ×¢×œ ×™×“×™ ×”×§×¦××ª ×¢×¨×š ×§×‘×•×¢ ×©×œ 1 ××• 0.\n",
    "\n",
    "×œ×“×•×’××”:\n",
    "```python\n",
    "df = df.withColumn(\"is_active\", lit(1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ¨ ×¡×™×›×•×\n",
    "\n",
    "×œ××“×ª ××¡×¤×¨ ×“×¨×›×™× ×œ×”×•×¡×™×£ ×¢×¨×š literal ×§×‘×•×¢ ×œ-DataFrame ×‘×××¦×¢×•×ª ×¤×•× ×§×¦×™×•×ª `lit()` ×•-`typedLit()` ×©×œ PySpark.\n",
    "\n",
    "**× ×§×•×“×•×ª ××¤×ª×—:**\n",
    "- âœ… `lit()` - ×œ×¢×¨×›×™× ×¤×©×•×˜×™× (××—×¨×•×–×•×ª, ××¡×¤×¨×™×, ×‘×•×œ×™×× ×™×)\n",
    "- âœ… `typedLit()` - ×œ×§×•×œ×§×¦×™×•×ª (××¢×¨×›×™×, ××™×œ×•× ×™×)\n",
    "- âœ… ×©×™××•×© ×¢× `withColumn()` ×•-`select()`\n",
    "- âœ… ×©×™×œ×•×‘ ×¢× `when()` ×œ×ª× ××™×\n",
    "\n",
    "×›××©×¨ ××¤×©×¨, ××•××œ×¥ ×œ×”×©×ª××© ×‘×¤×•× ×§×¦×™×•×ª PySpark ××•×’×“×¨×•×ª ××¨××© ××›×™×•×•×Ÿ ×©×”×Ÿ ×‘×˜×•×—×•×ª ×™×•×ª×¨ ×‘×–××Ÿ ×§×•××¤×™×œ×¦×™×” ×•××‘×¦×¢×•×ª ×‘×™×¦×•×¢×™× ×˜×•×‘×™× ×™×•×ª×¨ ×œ×¢×•××ª ×¤×•× ×§×¦×™×•×ª UDF ××•×ª×××•×ª ××™×©×™×ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ××§×•×¨×•×ª <a id='references'></a>\n",
    "\n",
    "- [PySpark SQL Functions Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)\n",
    "- [SparkByExamples - PySpark lit() Function](https://sparkbyexamples.com/pyspark/pyspark-lit-add-literal-constant/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
