{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    body, * {\n",
    "        direction: rtl !important;\n",
    "        text-align: right !important;\n",
    "    }\n",
    "</style>\n",
    "# ğŸ”¢ Count Distinct ×‘-PySpark DataFrame\n",
    "[PySpark Count Distinct from DataFrame](https://sparkbyexamples.com/pyspark/pyspark-count-distinct-from-dataframe/)\n",
    "## ğŸ“š ××‘×•×\n",
    "\n",
    "×‘-PySpark, ××¤×©×¨ ×œ×”×©×ª××© ×‘-`distinct().count()` ×©×œ DataFrame ××• ×‘-`countDistinct()` ×©×œ ×¤×•× ×§×¦×™×•×ª SQL ×›×“×™ ×œ×§×‘×œ ××ª ×¡×¤×™×¨×ª ×”-distinct.\n",
    "\n",
    "×‘××××¨ ×–×” × ×œ××“:\n",
    "1. ××™×š ×œ×§×‘×œ count distinct ××›×œ ×”×¢××•×“×•×ª\n",
    "2. ××™×š ×œ×§×‘×œ count distinct ××¢××•×“×•×ª ××¨×•×‘×•×ª × ×‘×—×¨×•×ª\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ×”×›× ×ª ×”×¡×‘×™×‘×” ×•×”× ×ª×•× ×™×\n",
    "\n",
    "×œ×¤× ×™ ×©× ×ª×—×™×œ, × ×™×¦×•×¨ DataFrame ×©×œ PySpark ×¢× ×›××” ×©×•×¨×•×ª ×›×¤×•×œ×•×ª ×•×›××” ×¢×¨×›×™× ×›×¤×•×œ×™× ×‘×¢××•×“×”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×™×‘×•× ×¡×¤×¨×™×•×ª\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ×™×¦×™×¨×ª Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# ×”×’×“×¨×ª × ×ª×•× ×™ ×“×•×’××”\n",
    "data = [\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "]\n",
    "\n",
    "# ×”×’×“×¨×ª ×©××•×ª ×”×¢××•×“×•×ª\n",
    "columns = [\"Name\", \"Dept\", \"Salary\"]\n",
    "\n",
    "# ×™×¦×™×¨×ª DataFrame\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "# ×”×¦×’×ª ×”× ×ª×•× ×™×\n",
    "df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¢×¨×”:** ×‘-DataFrame ×–×” ×™×© ×œ× ×•:\n",
    "- ×©×•×¨×” ×›×¤×•×œ×” ×©×œ××” (James, Sales, 3000)\n",
    "- ×¢×¨×›×™ Salary ×›×¤×•×œ×™×\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ×©×™××•×© ×‘-distinct().count()\n",
    "\n",
    "×¢×œ ×”-DataFrame ×©×œ××¢×œ×”, ×™×© ×œ× ×• ×¡×š ×©×œ 10 ×©×•×¨×•×ª ×•×©×•×¨×” ××—×ª ×¢× ×›×œ ×”×¢×¨×›×™× ×›×¤×•×œ×™×.\n",
    "\n",
    "×‘×™×¦×•×¢ `distinct().count()` ×¢×œ DataFrame ×–×” ×××•×¨ ×œ×ª×ª ×œ× ×• 9 ×œ××—×¨ ×©×”×¡×¨× ×• ×©×•×¨×” ××—×ª ×›×¤×•×œ×”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×”×—×œ×ª distinct() ×•-count()\n",
    "df1 = df.distinct()\n",
    "print(df1.count())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ×§×‘×œ×ª Distinct Values ××¢××•×“×” ××—×ª\n",
    "\n",
    "×‘×“×•×’××” ×œ××˜×” × ×§×‘×œ distinct ×•××– × ×—×™×œ count ×¢×œ ×©× ×”×¢××•×“×”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×§×‘×œ×ª distinct count ××¢××•×“×” ××—×ª\n",
    "df2 = df.select(\"Name\").distinct()\n",
    "print(df2.count())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¡×‘×¨:**\n",
    "- `select(\"Name\")` - ×‘×•×—×¨ ×¨×§ ××ª ×¢××•×“×ª Name\n",
    "- `distinct()` - ××¡×™×¨ ×›×¤×™×œ×•×™×•×ª\n",
    "- `count()` - ×¡×•×¤×¨ ××ª ×”××¡×¤×¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ×©×™××•×© ×‘-countDistinct() SQL Function\n",
    "\n",
    "×”-DataFrame `distinct()` ××—×–×™×¨ DataFrame ×—×“×© ×œ××—×¨ ×”×¡×¨×ª ×©×•×¨×•×ª ×›×¤×•×œ×•×ª (×”×ª×××” ×œ×›×œ ×”×¢××•×“×•×ª ×©×œ Row).\n",
    "\n",
    "×× ×¨×•×¦×™× ×œ×§×‘×œ distinct count ×¢×œ ××¡×¤×¨ ×¢××•×“×•×ª × ×‘×—×¨×•×ª, ××©×ª××©×™× ×‘×¤×•× ×§×¦×™×™×ª PySpark SQL `countDistinct()`.\n",
    "\n",
    "×”×¤×•× ×§×¦×™×” ×”×–×• ××—×–×™×¨×” ××ª ××¡×¤×¨ ×”××œ×× ×˜×™× ×”-distinct ×‘×§×‘×•×¦×”.\n",
    "\n",
    "×›×“×™ ×œ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” ×”×–×•, ×¦×¨×™×š ×œ×™×™×‘× ××•×ª×” ×ª×—×™×œ×”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-countDistinct()\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df2 = df.select(countDistinct(\"Dept\", \"Salary\"))\n",
    "df2.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**×”×¢×¨×”:** ×”×¤×•× ×§×¦×™×” `countDistinct()` ××—×–×™×¨×” ×¢×¨×š ×‘×¢××•×“×” ×‘×¢×œ×ª Column type, ×•×œ×›×Ÿ ×¦×¨×™×š ×œ×”×©×ª××© ×‘-`collect()` ×›×“×™ ×œ×§×‘×œ ××ª ×”×¢×¨×š ××”-DataFrame.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ×”×—×œ×ª collect() ×œ××—×¨ countDistinct()\n",
    "\n",
    "×©×™× ×œ×‘ ×©-`countDistinct()` ××—×–×™×¨ ×¢×¨×š ×‘-Column type, ×•×œ×›×Ÿ ×¦×¨×™×š ×œ××¡×•×£ ××•×ª×• ×›×“×™ ×œ×§×‘×œ ××ª ×”×¢×¨×š ××”-DataFrame.\n",
    "\n",
    "×¤×•× ×§×¦×™×” ×–×• ×™×›×•×œ×” ×œ×©××© ×›×“×™ ×œ×§×‘×œ distinct count ×©×œ ×›×œ ××¡×¤×¨ ×©×œ ×¢××•×“×•×ª × ×‘×—×¨×•×ª ××• ××›×œ ×”×¢××•×“×•×ª:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-collect() ×œ××—×¨ countDistinct()\n",
    "print(\"Distinct Count of Department & Salary: \" +\n",
    "      str(df2.collect()[0][0]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ×©×™××•×© ×‘-SQL ×›×“×™ ×œ×§×‘×œ Count Distinct\n",
    "\n",
    "×œ×—×œ×•×¤×™×Ÿ, ××¤×©×¨ ×’× ×œ×”×©×ª××© ×‘-SQL ×›×“×™ ×œ×”×©×™×’ ××ª ××•×ª×” ×ª×•×¦××”:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×©×™××•×© ×‘-SQL\n",
    "df.createOrReplaceTempView(\"EMP\")\n",
    "\n",
    "spark.sql(\"select distinct(count(*)) from EMP\").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "××•:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×’×¨×¡×” ××—×¨×ª ×©×œ SQL\n",
    "spark.sql(\"select count(distinct(*)) from EMP\").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**×”×¢×¨×”:** ×©×™××•×© ×‘-SQL ××¡×¤×§ ×ª×—×‘×™×¨ ××•×›×¨ ×œ××™ ×©××›×™×¨ SQL ××¡×•×¨×ª×™.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ×§×•×“ ××œ× - ×“×•×’××” ××§×™×¤×”\n",
    "\n",
    "×œ×”×œ×Ÿ ×”×§×•×“ ×”××œ× ×”××©×œ×‘ ××ª ×›×œ ×”×“×•×’×××•×ª:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ×§×•×“ ××œ×\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "]\n",
    "\n",
    "columns = [\"Name\", \"Dept\", \"Salary\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.show(truncate=False)\n",
    "\n",
    "# ×©×™××•×© ×‘-distinct().count()\n",
    "df1 = df.distinct()\n",
    "print(\"Distinct Count: \" + str(df1.count()))\n",
    "\n",
    "# ×©×™××•×© ×‘-countDistinct()\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df2 = df.select(countDistinct(\"Dept\", \"Salary\"))\n",
    "df2.show()\n",
    "\n",
    "print(\"Distinct Count of Department & Salary: \" + \n",
    "      str(df2.collect()[0][0]))\n",
    "\n",
    "# ×©×™××•×© ×‘-SQL\n",
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select count(distinct(Dept, Salary)) from EMP\").show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ ×¡×™×›×•×\n",
    "\n",
    "×‘××××¨ ×–×”, ×œ××“×ª ×›×™×¦×“ ×œ×§×‘×œ count distinct ××›×œ ×”×¢××•×“×•×ª ××• ××¢××•×“×•×ª ××¨×•×‘×•×ª × ×‘×—×¨×•×ª ×¢×œ PySpark DataFrame.\n",
    "\n",
    "**×œ×¡×™×›×•× ×”××•×©×’×™× ×©×œ××“× ×•:**\n",
    "\n",
    "âœ… **distinct()** - ××¡×™×¨ ×©×•×¨×•×ª ×›×¤×•×œ×•×ª ×-DataFrame\n",
    "\n",
    "âœ… **count()** - ×¡×•×¤×¨ ××ª ××¡×¤×¨ ×”×©×•×¨×•×ª\n",
    "\n",
    "âœ… **countDistinct()** - ×¤×•× ×§×¦×™×™×ª SQL ×©××—×–×™×¨×” count distinct ×©×œ ×¢××•×“×•×ª × ×‘×—×¨×•×ª\n",
    "\n",
    "âœ… **collect()** - ××•×¡×£ ××ª ×”×ª×•×¦××” ××”-DataFrame\n",
    "\n",
    "### ğŸ“Š ×”×©×•×•××ª ×©×™×˜×•×ª\n",
    "\n",
    "| ×©×™×˜×” | ×©×™××•×© | ×™×ª×¨×•× ×•×ª |\n",
    "|------|-------|----------|\n",
    "| `distinct().count()` | Count distinct ×¢×œ ×›×œ ×”×¢××•×“×•×ª | ×¤×©×•×˜ ×•×‘×¨×•×¨ |\n",
    "| `countDistinct()` | Count distinct ×¢×œ ×¢××•×“×•×ª ×¡×¤×¦×™×¤×™×•×ª | ×’××™×© ×™×•×ª×¨ |\n",
    "| SQL | ×‘×™×˜×•×™×™ SQL | ××•×›×¨ ×œ××©×ª××©×™ SQL |\n",
    "\n",
    "### ğŸ“š ××××¨×™× ×§×©×•×¨×™×\n",
    "- [PySpark count() â€“ Different Methods Explained](https://sparkbyexamples.com/pyspark/pyspark-count/)\n",
    "- [PySpark Distinct to Drop Duplicate Rows](https://sparkbyexamples.com/pyspark/pyspark-distinct-to-drop-duplicate-rows/)\n",
    "- [PySpark Count of Non null, nan Values in DataFrame](https://sparkbyexamples.com/pyspark/pyspark-count-of-non-null-nan-values-in-dataframe/)\n",
    "- [PySpark Groupby Count Distinct](https://sparkbyexamples.com/pyspark/pyspark-groupby-count-distinct/)\n",
    "- [PySpark GroupBy Count â€“ Explained](https://sparkbyexamples.com/pyspark/pyspark-groupby-count/)\n",
    "- [PySpark â€“ Find Count of null, None, NaN Values](https://sparkbyexamples.com/pyspark/pyspark-find-count-of-null-none-nan-values/)\n",
    "- [Pyspark Select Distinct Rows](https://sparkbyexamples.com/pyspark/pyspark-select-distinct-rows/)\n",
    "- [PySpark Get Number of Rows and Columns](https://sparkbyexamples.com/pyspark/pyspark-get-number-of-rows-and-columns/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
